{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "toc-pro-adv",
      "metadata": {
        "id": "toc-pro-adv"
      },
      "source": [
        "# A Guide to Production-Grade RAG: From Theory to Autonomous Agents\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "**Part 1: Setting the Stage - Foundations and Our Core Challenge**\n",
        "* [1.1. Introduction: The Limits of \"Shallow\" RAG](#part1-1-intro-pro)\n",
        "* [1.2. Environment Setup: API Keys, Imports, and Configuration](#part1-2-env-pro-adv)\n",
        "* [1.3. The Dataset: Preparing Our Knowledge Base](#part1-3-data-pro)\n",
        "* [1.4. The Upgraded Challenge: A Multi-Source, Multi-Hop Query](#part1-4-challenge-pro-adv)\n",
        "\n",
        "**Part 2: The Baseline - Building and Breaking a \"Vanilla\" RAG Pipeline**\n",
        "* [2.1. Code Dependency: Document Loading and Naive Chunking](#part2-1-dep-pro)\n",
        "* [2.2. Code Dependency: Creating the Vector Store](#part2-2-dep-pro)\n",
        "* [2.3. Code Dependency: Assembling the Simple RAG Chain](#part2-3-dep-pro)\n",
        "* [2.4. The Critical Failure Case: Demonstrating the Need for Advanced Techniques](#part2-4-fail-pro-adv)\n",
        "* [2.5. Diagnosis: Why Did It Fail?](#part2-5-diag-pro-adv)\n",
        "\n",
        "**Part 3: The \"Deep Thinking\" Upgrade: Engineering an Autonomous Reasoning Engine**\n",
        "* [3.1. Code Dependency: Defining the `RAGState`](#part3-1-state-pro-adv)\n",
        "* [3.2. Component 1: Dynamic Planning and Query Formulation](#part3-2-planner-pro-adv)\n",
        "    * [3.2.1. The Tool-Aware Planner Agent](#part3-2-1-planner-pro-adv)\n",
        "    * [3.2.2. Query Rewriting and Expansion](#part3-2-2-rewriter-pro)\n",
        "    * [3.2.3. Entity and Constraint Extraction](#part3-2-3-metadata-pro)\n",
        "* [3.3. Component 2: The Multi-Stage, Adaptive Retrieval Funnel](#part3-3-retrieval-pro-adv)\n",
        "    * [3.3.1. NEW: The Retrieval Supervisor Agent](#part3-3-1-supervisor-pro)\n",
        "    * [3.3.2. Implementing the Retrieval Strategies](#part3-3-2-strategies-pro)\n",
        "    * [3.3.3. Stage 2 (High Precision): Cross-Encoder Reranker](#part3-3-3-reranker-pro)\n",
        "    * [3.3.4. Stage 3 (Contextual Distillation)](#part3-3-4-distill-pro)\n",
        "* [3.4. Component 3: Tool Augmentation with Web Search](#part3-4-tool-pro)\n",
        "* [3.5. Component 4: The Self-Critique and Control Flow Policy](#part3-5-critique-pro)\n",
        "    * [3.5.1. The \"Update and Reflect\" Step](#part3-5-1-reflect-pro)\n",
        "    * [3.5.2. Policy Implementation (LLM-as-a-Judge)](#part3-5-2-policy-pro)\n",
        "    * [3.5.3. Defining Robust Stopping Criteria](#part3-5-3-stopping-pro)\n",
        "\n",
        "**Part 4: Assembly with LangGraph - Orchestrating the Reasoning Loop**\n",
        "* [4.1. Code Dependency: Defining the Graph Nodes](#part4-1-nodes-pro-adv)\n",
        "* [4.2. Code Dependency: Defining the Conditional Edges](#part4-2-edges-pro-adv)\n",
        "* [4.3. Building the `StateGraph`](#part4-3-build-pro-adv)\n",
        "* [4.4. Compiling and Visualizing the Workflow](#part4-4-viz-pro-adv)\n",
        "\n",
        "**Part 5: Redemption - Running the Advanced Agent**\n",
        "* [5.1. Invoking the Graph: A Step-by-Step Trace](#part5-1-invoke-pro-adv)\n",
        "* [5.2. Analyzing the Final High-Quality Output](#part5-2-analyze-pro-adv)\n",
        "* [5.3. Side-by-Side Comparison: Vanilla vs. Deep Thinking RAG](#part5-3-compare-pro-adv)\n",
        "\n",
        "**Part 6: A Production-Grade Evaluation Framework**\n",
        "* [6.1. Evaluation Metrics Overview](#part6-metrics-pro)\n",
        "* [6.2. Code Dependency: Implementing Evaluation with RAGAs](#part6-4-ragas-code-pro-adv)\n",
        "* [6.3. Interpreting the Evaluation Scores](#part6-5-interpret-pro-adv)\n",
        "\n",
        "**Part 7: Optimizations and Production Considerations**\n",
        "* [7.1. Optimization: Caching](#part7-1-cache-pro)\n",
        "* [7.2. Feature: Provenance and Citations](#part7-2-provenance-pro)\n",
        "* [7.3. Discussion: The Next Level - MDPs and Learned Policies](#part7-3-discussion-pro)\n",
        "* [7.4. Handling Failure: Graceful Exits and Fallbacks](#part7-4-failure-pro)\n",
        "\n",
        "**Part 8: Conclusion and Key Takeaways**\n",
        "* [8.1. Summary of Our Journey](#part8-conclusion-pro)\n",
        "* [8.2. Key Architectural Principles of Advanced RAG Systems](#part8-2-principles-pro-adv)\n",
        "* [8.3. Future Directions](#part8-3-future-pro-adv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part1-intro-rag-pro",
      "metadata": {
        "id": "part1-intro-rag-pro"
      },
      "source": [
        "## Part 1: Setting the Stage - Foundations and Our Core Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part1-1-intro-pro",
      "metadata": {
        "id": "part1-1-intro-pro"
      },
      "source": [
        "### 1.1. Introduction: The Limits of \"Shallow\" RAG\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) has become the dominant paradigm for creating knowledge-intensive AI systems. The standard approach—a linear, three-step pipeline of **Retrieve -> Augment -> Generate**—is remarkably effective for simple, fact-based queries. However, this \"shallow\" RAG architecture reveals critical weaknesses when faced with complex questions that demand synthesis, comparison, and multi-step reasoning across a large and varied knowledge base.\n",
        "\n",
        "The next frontier in RAG is not about bigger models or larger context windows, but about greater **autonomy and intelligence** in the retrieval and reasoning process. The industry is moving from static chains to dynamic, agentic systems that can emulate a human researcher's workflow. These systems can decompose complex problems, select appropriate tools, dynamically adapt their retrieval strategies, and critique their own progress.\n",
        "\n",
        "In this comprehensive guide, we will build a powerful, **standalone** implementation of a **Deep Thinking RAG Pipeline**. We will meticulously engineer every component, from a sophisticated multi-stage, adaptive retrieval funnel to a tool-augmented, self-critiquing policy engine. We will begin by exposing the failure of a vanilla RAG system on a challenging query, and then, step-by-step, construct our advanced agent using **LangGraph** to orchestrate its complex, cyclical reasoning. By the end, you will have a production-grade framework and a deep, architectural understanding of how to build RAG systems that can truly *think*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part1-2-env-pro-adv",
      "metadata": {
        "id": "part1-2-env-pro-adv"
      },
      "source": [
        "### 1.2. Environment Setup: API Keys, Imports, and Configuration\n",
        "\n",
        "We begin by setting up our foundational components. This includes securely managing API keys, importing all necessary libraries, and defining a global configuration dictionary. We will use **LangSmith** for tracing, which is an indispensable tool for visualizing and debugging the complex, non-linear execution paths of our reasoning agent. For our new web search capability, we will also add the **Tavily AI** API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "part1-2-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part1-2-code-pro-adv",
        "outputId": "e26144df-c1ec-4f20-9743-1e3048996b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment and configuration set up successfully.\n",
            "{'azure_api_version': '2025-01-01-preview',\n",
            " 'azure_deployment_name': 'chatbottest01-llm-gpt-4o-mini',\n",
            " 'azure_endpoint': 'https://manju-mh8ukqqk-eastus2.cognitiveservices.azure.com/openai/deployments/chatbottest01-llm-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview',\n",
            " 'data_dir': './data',\n",
            " 'embedding_model': 'text-embedding-3-small',\n",
            " 'fast_llm': 'gpt-3.5-turbo-0125',\n",
            " 'llm_provider': 'azure_openai',\n",
            " 'max_reasoning_iterations': 7,\n",
            " 'reasoning_llm': 'gpt-3.5-turbo-0125',\n",
            " 'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
            " 'top_k_retrieval': 10,\n",
            " 'top_n_rerank': 3,\n",
            " 'vector_store_dir': './vector_store'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from getpass import getpass\n",
        "from pprint import pprint\n",
        "import uuid\n",
        "from typing import List, Dict, TypedDict, Literal, Optional\n",
        "\n",
        "# Securely set API keys\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass(f\"Enter your {var}: \")\n",
        "\n",
        "#_set_env(\"OPENAI_API_KEY\")\n",
        "#_set_env(\"LANGSMITH_API_KEY\")\n",
        "#_set_env(\"TAVILY_API_KEY\")\n",
        "\n",
        "\n",
        "# Optional: For accessing SEC filings programmatically\n",
        "# _set_env(\"SEC_API_KEY\")\n",
        "\n",
        "# Configure LangSmith tracing\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"Advanced-Deep-Thinking-RAG-v2\"\n",
        "\n",
        "# Load API keys from environment variables or .env file\n",
        "# Never hardcode API keys in notebooks! Use .env file or environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # Load from .env file if it exists\n",
        "\n",
        "# Set API keys from environment (already loaded from .env or system env)\n",
        "# If not set, use getpass to prompt securely\n",
        "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
        "    _set_env(\"LANGSMITH_API_KEY\")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    _set_env(\"TAVILY_API_KEY\")\n",
        "\n",
        "# Set Azure OpenAI specific environment variables\n",
        "# Load from .env file or prompt if not set\n",
        "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
        "    _set_env(\"AZURE_OPENAI_API_KEY\")\n",
        "if not os.environ.get(\"AZURE_OPENAI_ENDPOINT\"):\n",
        "    endpoint = input(\"Enter AZURE_OPENAI_ENDPOINT (or set in .env): \").strip()\n",
        "    if endpoint:\n",
        "        os.environ[\"AZURE_OPENAI_ENDPOINT\"] = endpoint\n",
        "if not os.environ.get(\"AZURE_OPENAI_API_VERSION\"):\n",
        "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2025-01-01-preview\"\n",
        "if not os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"):\n",
        "    deployment = input(\"Enter AZURE_OPENAI_DEPLOYMENT_NAME (or set in .env): \").strip()\n",
        "    if deployment:\n",
        "        os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = deployment\n",
        "\n",
        "\n",
        "# Central Configuration Dictionary\n",
        "config = {\n",
        "    \"data_dir\": \"./data\",\n",
        "    \"vector_store_dir\": \"./vector_store\",\n",
        "    \"llm_provider\": \"azure_openai\",\n",
        "    \"reasoning_llm\": \"gpt-3.5-turbo-0125\", # Changed to a different LLM to avoid rate limits\n",
        "    \"fast_llm\": \"gpt-3.5-turbo-0125\",\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"reranker_model\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    \"max_reasoning_iterations\": 7, # Maximum loops for the reasoning agent\n",
        "    \"top_k_retrieval\": 10,       # Number of documents for initial broad recall\n",
        "    \"top_n_rerank\": 3,\n",
        "    \"azure_deployment_name\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
        "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    \"azure_api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
        "}\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(config[\"data_dir\"], exist_ok=True)\n",
        "os.makedirs(config[\"vector_store_dir\"], exist_ok=True)\n",
        "\n",
        "print(\"Environment and configuration set up successfully.\")\n",
        "pprint(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part1-3-data-pro",
      "metadata": {
        "id": "part1-3-data-pro"
      },
      "source": [
        "### 1.3. The Dataset: Preparing Our Knowledge Base from Complex Documents\n",
        "\n",
        "Our knowledge base will be the full text of NVIDIA's 2023 10-K filing. Instead of a dummy file, we will programmatically download the actual filing from the SEC's EDGAR database. This document is a dense, 100+ page report detailing their business, financials, and risks. This is a perfect test case because answering sophisticated questions requires connecting information spread across disparate sections like 'Business Overview', 'Risk Factors', and 'Management's Discussion and Analysis' (MD&A)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "part1-3-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part1-3-code-pro",
        "outputId": "68ff790f-2768-43cf-af3f-330d20c8c02f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Loading documents from data folder...\n",
            "============================================================\n",
            "Loading documents from: /Users/pradeepkumar/Development/coding/agentic-ai-deep-rag/notebooks/data\n",
            "Found 1 PDF file(s) and 0 text file(s)\n",
            "\n",
            "Loading PDF: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "  ✓ Loaded 30 pages from Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "\n",
            "============================================================\n",
            "Total documents loaded: 30\n",
            "============================================================\n",
            "\n",
            "--- Sample content from first document ---\n",
            "Source: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "Content preview (first 500 chars):\n",
            "------------------------------------------------------------\n",
            "Citation: Dubey, B.; Agrawal, S.;\n",
            "Sharma, A.K. India’s Renewable\n",
            "Energy Portfolio: An Investigation of\n",
            "the Untapped Potential of RE,\n",
            "Policies, and Incentives Favoring\n",
            "Energy Security in the Country.\n",
            "Energies 2023, 16, 5491.\n",
            "https://doi.org/10.3390/en16145491\n",
            "Academic Editor: Manolis Souliotis\n",
            "Received: 15 June 2023\n",
            "Revised: 11 July 2023\n",
            "Accepted: 17 July 2023\n",
            "Published: 20 July 2023\n",
            "Copyright: © 2023 by the authors.\n",
            "Licensee MDPI, Basel, Switzerland.\n",
            "This article is an open access article\n",
            "distri...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Ensure pypdf is installed for PDF loading\n",
        "try:\n",
        "    import pypdf\n",
        "except ImportError:\n",
        "    print(\"Installing pypdf package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pypdf\"])\n",
        "    import pypdf\n",
        "    print(\"✓ pypdf installed successfully\")\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "\n",
        "def load_documents_from_data_folder(data_dir):\n",
        "    \"\"\"\n",
        "    Load all documents from the data folder at the project root.\n",
        "    Supports PDF and text files.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    # Resolve to absolute path to ensure we're using the correct directory\n",
        "    data_path = data_path.resolve()\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        raise ValueError(f\"Data directory does not exist: {data_path}\")\n",
        "    \n",
        "    print(f\"Loading documents from: {data_path}\")\n",
        "    \n",
        "    # Get all files in the data folder\n",
        "    pdf_files = list(data_path.glob(\"*.pdf\"))\n",
        "    txt_files = list(data_path.glob(\"*.txt\"))\n",
        "    \n",
        "    print(f\"Found {len(pdf_files)} PDF file(s) and {len(txt_files)} text file(s)\")\n",
        "    \n",
        "    # Load PDF files\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"\\nLoading PDF: {pdf_file.name}\")\n",
        "        try:\n",
        "            loader = PyPDFLoader(str(pdf_file))\n",
        "            docs = loader.load()\n",
        "            # Add source metadata to each document\n",
        "            for doc in docs:\n",
        "                doc.metadata['source'] = str(pdf_file)\n",
        "                doc.metadata['file_name'] = pdf_file.name\n",
        "            documents.extend(docs)\n",
        "            print(f\"  ✓ Loaded {len(docs)} pages from {pdf_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {pdf_file.name}: {e}\")\n",
        "    \n",
        "    # Load text files\n",
        "    for txt_file in txt_files:\n",
        "        print(f\"\\nLoading text file: {txt_file.name}\")\n",
        "        try:\n",
        "            loader = TextLoader(str(txt_file), encoding='utf-8')\n",
        "            docs = loader.load()\n",
        "            # Add source metadata to each document\n",
        "            for doc in docs:\n",
        "                doc.metadata['source'] = str(txt_file)\n",
        "                doc.metadata['file_name'] = txt_file.name\n",
        "            documents.extend(docs)\n",
        "            print(f\"  ✓ Loaded text from {txt_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {txt_file.name}: {e}\")\n",
        "    \n",
        "    return documents\n",
        "\n",
        "# Load all documents from the data folder (located at project root)\n",
        "print(\"=\" * 60)\n",
        "print(\"Loading documents from data folder...\")\n",
        "print(\"=\" * 60)\n",
        "all_documents = load_documents_from_data_folder(config[\"data_dir\"])\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"Total documents loaded: {len(all_documents)}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "if all_documents:\n",
        "    print(f\"\\n--- Sample content from first document ---\")\n",
        "    print(f\"Source: {all_documents[0].metadata.get('file_name', 'Unknown')}\")\n",
        "    print(f\"Content preview (first 500 chars):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(all_documents[0].page_content[:500] + \"...\")\n",
        "    print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"\\n⚠️  No documents were loaded. Please ensure there are PDF or text files in the data folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part1-4-challenge-pro-adv",
      "metadata": {
        "id": "part1-4-challenge-pro-adv"
      },
      "source": [
        "### 1.4. The Upgraded Challenge: A Multi-Source, Multi-Hop Query We Will Conquer\n",
        "\n",
        "This is the query designed to break our baseline RAG system and showcase the power of our advanced agent. It requires the agent to perform multiple distinct information retrieval steps from *different sources* (the static 10-K and the live web) and then synthesize the findings into a coherent analytical narrative.\n",
        "\n",
        "> **The Query:** \"Based on NVIDIA's 2023 10-K filing, identify their key risks related to competition. Then, find recent news (post-filing, from 2024) about AMD's AI chip strategy and explain how this new strategy directly addresses or exacerbates one of NVIDIA's stated risks.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-intro-rag-pro",
      "metadata": {
        "id": "part2-intro-rag-pro"
      },
      "source": [
        "## Part 2: The Baseline - Building and Breaking a \"Vanilla\" RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-1-dep-pro",
      "metadata": {
        "id": "part2-1-dep-pro"
      },
      "source": [
        "### 2.1. Code Dependency: Document Loading and Naive Chunking Strategy\n",
        "\n",
        "Our baseline pipeline begins with a standard approach: load the entire document and split it into fixed-size chunks using a `RecursiveCharacterTextSplitter`. This method is fast but semantically naive, often splitting paragraphs or related ideas across different chunks—a primary source of failure for complex queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "part2-1-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part2-1-code-pro",
        "outputId": "b5c03fa3-0ba2-4e73-a59e-5ebdf8147954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunking the documents...\n",
            "Documents loaded and split into 149 chunks.\n",
            "Total pages/documents processed: 30\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"Chunking the documents...\")\n",
        "\n",
        "# Use the documents loaded from the data folder in section 1.3\n",
        "# Make sure you've run section 1.3 first to load all_documents\n",
        "if 'all_documents' not in globals() or not all_documents:\n",
        "    raise ValueError(\"Please run section 1.3 first to load documents from the data folder.\")\n",
        "\n",
        "# Split all documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "doc_chunks = text_splitter.split_documents(all_documents)\n",
        "\n",
        "print(f\"Documents loaded and split into {len(doc_chunks)} chunks.\")\n",
        "print(f\"Total pages/documents processed: {len(all_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aaf45339",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf45339",
        "outputId": "3a4bd7e7-86ec-45d8-c87e-5c46a16de297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: unstructured[html]\n",
            "Environment and configuration set up successfully.\n",
            "{'data_dir': './data',\n",
            " 'embedding_model': 'BAAI/bge-small-en-v1.5',\n",
            " 'fast_llm': 'gpt-4o-mini',\n",
            " 'llm_provider': 'openai',\n",
            " 'max_reasoning_iterations': 7,\n",
            " 'reasoning_llm': 'gpt-4o-mini',\n",
            " 'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
            " 'top_k_retrieval': 10,\n",
            " 'top_n_rerank': 3,\n",
            " 'vector_store_dir': './vector_store'}\n"
          ]
        }
      ],
      "source": [
        "# To avoid re-running pip install every time, this is commented out if dependencies are already met.\n",
        "# If you encounter ModuleNotFoundError, uncomment the line below and run this cell.\n",
        "!pip install -U langchain langgraph langchain_openai chromadb beautifulsoup4 rank_bm25 lxml sentence-transformers ragas arxiv rich sec-api unstructured[html] tavily-python langchain-community\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from getpass import getpass\n",
        "from pprint import pprint\n",
        "import uuid\n",
        "from typing import List, Dict, TypedDict, Literal, Optional\n",
        "\n",
        "# Securely set API keys\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass(f\"Enter your {var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Load API keys from environment variables or .env file\n",
        "# Never hardcode API keys! Use .env file or environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # Load from .env file if it exists\n",
        "\n",
        "# Set API keys from environment (already loaded from .env or system env)\n",
        "# If not set, use getpass to prompt securely\n",
        "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
        "    _set_env(\"LANGSMITH_API_KEY\")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    _set_env(\"TAVILY_API_KEY\")\n",
        "# Optional: For accessing SEC filings programmatically\n",
        "# _set_env(\"SEC_API_KEY\")\n",
        "\n",
        "# Configure LangSmith tracing\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"Advanced-Deep-Thinking-RAG-v2\"\n",
        "\n",
        "# Central Configuration Dictionary\n",
        "config = {\n",
        "    \"data_dir\": \"./data\",\n",
        "    \"vector_store_dir\": \"./vector_store\",\n",
        "    \"llm_provider\": \"openai\",\n",
        "    \"reasoning_llm\": \"gpt-4o-mini\", # Changed to a faster LLM to avoid rate limits\n",
        "    \"fast_llm\": \"gpt-4o-mini\",\n",
        "    \"embedding_model\": \"BAAI/bge-small-en-v1.5\", # Changed to a local embedding model\n",
        "    \"reranker_model\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    \"max_reasoning_iterations\": 7, # Maximum loops for the reasoning agent\n",
        "    \"top_k_retrieval\": 10,       # Number of documents for initial broad recall\n",
        "    \"top_n_rerank\": 3,\n",
        "}\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(config[\"data_dir\"], exist_ok=True)\n",
        "os.makedirs(config[\"vector_store_dir\"], exist_ok=True)\n",
        "\n",
        "print(\"Environment and configuration set up successfully.\")\n",
        "pprint(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f40ae50f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f40ae50f",
        "outputId": "34941c4c-a81e-459d-8ddd-1030139cfe16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Loading and parsing documents from data folder...\n",
            "============================================================\n",
            "Loading documents from: /Users/pradeepkumar/Development/coding/agentic-ai-deep-rag/notebooks/data\n",
            "Found 1 PDF file(s) and 0 text file(s)\n",
            "\n",
            "Loading PDF: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "  ✓ Loaded 30 pages from Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "\n",
            "============================================================\n",
            "Total documents loaded: 30\n",
            "============================================================\n",
            "\n",
            "--- Sample content from first document ---\n",
            "Source: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "Content preview (first 500 chars):\n",
            "------------------------------------------------------------\n",
            "Citation: Dubey, B.; Agrawal, S.;\n",
            "Sharma, A.K. India’s Renewable\n",
            "Energy Portfolio: An Investigation of\n",
            "the Untapped Potential of RE,\n",
            "Policies, and Incentives Favoring\n",
            "Energy Security in the Country.\n",
            "Energies 2023, 16, 5491.\n",
            "https://doi.org/10.3390/en16145491\n",
            "Academic Editor: Manolis Souliotis\n",
            "Received: 15 June 2023\n",
            "Revised: 11 July 2023\n",
            "Accepted: 17 July 2023\n",
            "Published: 20 July 2023\n",
            "Copyright: © 2023 by the authors.\n",
            "Licensee MDPI, Basel, Switzerland.\n",
            "This article is an open access article\n",
            "distri...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Ensure pypdf is installed for PDF loading\n",
        "try:\n",
        "    import pypdf\n",
        "except ImportError:\n",
        "    print(\"Installing pypdf package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pypdf\"])\n",
        "    import pypdf\n",
        "    print(\"✓ pypdf installed successfully\")\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "\n",
        "def load_documents_from_data_folder(data_dir):\n",
        "    \"\"\"\n",
        "    Load all documents from the data folder at the project root.\n",
        "    Supports PDF and text files.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    # Resolve to absolute path to ensure we're using the correct directory\n",
        "    data_path = data_path.resolve()\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        raise ValueError(f\"Data directory does not exist: {data_path}\")\n",
        "    \n",
        "    print(f\"Loading documents from: {data_path}\")\n",
        "    \n",
        "    # Get all files in the data folder\n",
        "    pdf_files = list(data_path.glob(\"*.pdf\"))\n",
        "    txt_files = list(data_path.glob(\"*.txt\"))\n",
        "    \n",
        "    print(f\"Found {len(pdf_files)} PDF file(s) and {len(txt_files)} text file(s)\")\n",
        "    \n",
        "    # Load PDF files\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"\\nLoading PDF: {pdf_file.name}\")\n",
        "        try:\n",
        "            loader = PyPDFLoader(str(pdf_file))\n",
        "            docs = loader.load()\n",
        "            # Add source metadata to each document\n",
        "            for doc in docs:\n",
        "                doc.metadata['source'] = str(pdf_file)\n",
        "                doc.metadata['file_name'] = pdf_file.name\n",
        "            documents.extend(docs)\n",
        "            print(f\"  ✓ Loaded {len(docs)} pages from {pdf_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {pdf_file.name}: {e}\")\n",
        "    \n",
        "    # Load text files\n",
        "    for txt_file in txt_files:\n",
        "        print(f\"\\nLoading text file: {txt_file.name}\")\n",
        "        try:\n",
        "            loader = TextLoader(str(txt_file), encoding='utf-8')\n",
        "            docs = loader.load()\n",
        "            # Add source metadata to each document\n",
        "            for doc in docs:\n",
        "                doc.metadata['source'] = str(txt_file)\n",
        "                doc.metadata['file_name'] = txt_file.name\n",
        "            documents.extend(docs)\n",
        "            print(f\"  ✓ Loaded text from {txt_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {txt_file.name}: {e}\")\n",
        "    \n",
        "    return documents\n",
        "\n",
        "# Load all documents from the data folder (located at project root)\n",
        "print(\"=\" * 60)\n",
        "print(\"Loading and parsing documents from data folder...\")\n",
        "print(\"=\" * 60)\n",
        "all_documents = load_documents_from_data_folder(config[\"data_dir\"])\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"Total documents loaded: {len(all_documents)}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "if all_documents:\n",
        "    print(f\"\\n--- Sample content from first document ---\")\n",
        "    print(f\"Source: {all_documents[0].metadata.get('file_name', 'Unknown')}\")\n",
        "    print(f\"Content preview (first 500 chars):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(all_documents[0].page_content[:500] + \"...\")\n",
        "    print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"\\n⚠️  No documents were loaded. Please ensure there are PDF or text files in the data folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c27c28",
      "metadata": {},
      "source": [
        "### 2.1.5. Loading or Generating Embeddings (Optional)\n",
        "\n",
        "You can use the embedding pipeline to generate embeddings once and reuse them for both basic and deep RAG. This is especially useful for server-side deployments.\n",
        "\n",
        "**Option 1: Use Pre-Generated Embeddings (Recommended for Production)**\n",
        "Run the embedding generation script first:\n",
        "```bash\n",
        "python scripts/generate_embeddings.py\n",
        "```\n",
        "\n",
        "Then load them in the notebook below.\n",
        "\n",
        "**Option 2: Generate Embeddings in Notebook**\n",
        "The notebook will generate embeddings on-the-fly if they don't exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca85c2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option: Load or generate embeddings using the embedding pipeline\n",
        "# This allows you to reuse embeddings across multiple notebook runs\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve()\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "try:\n",
        "    from src.embedding_pipeline import load_or_generate_embeddings\n",
        "    from src.embeddings import create_embedding_function\n",
        "    from src.vector_store import create_retriever\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"LOADING OR GENERATING EMBEDDINGS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Try to load existing embeddings, or generate new ones\n",
        "    # Set force_regenerate=True to always generate new embeddings\n",
        "    use_pre_generated = True  # Set to False to always generate in notebook\n",
        "    \n",
        "    if use_pre_generated:\n",
        "        print(\"\\nAttempting to load pre-generated embeddings...\")\n",
        "        try:\n",
        "            vector_store = load_or_generate_embeddings(\n",
        "                config=config,\n",
        "                force_regenerate=False\n",
        "            )\n",
        "            embedding_function = create_embedding_function(config)\n",
        "            baseline_retriever = create_retriever(vector_store, k=3)\n",
        "            \n",
        "            # Get document chunks from vector store for compatibility\n",
        "            # Note: We'll use the vector store directly, but we need doc_chunks for some operations\n",
        "            print(\"\\n✓ Using pre-generated embeddings!\")\n",
        "            print(\"Note: If you need doc_chunks variable, it will be created in the next cell.\")\n",
        "            \n",
        "            # Set a flag to indicate we're using pre-generated embeddings\n",
        "            using_pre_generated_embeddings = True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠ Could not load pre-generated embeddings: {e}\")\n",
        "            print(\"Will generate embeddings in the next cell...\")\n",
        "            using_pre_generated_embeddings = False\n",
        "    else:\n",
        "        using_pre_generated_embeddings = False\n",
        "        print(\"\\nSkipping pre-generated embeddings. Will generate in next cell.\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"⚠ Could not import embedding pipeline: {e}\")\n",
        "    print(\"Will use inline embedding generation in the next cell...\")\n",
        "    using_pre_generated_embeddings = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b3fdde9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3fdde9a",
        "outputId": "10e5ef33-d9e9-4df2-ec6f-eb4b9b2db1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunking the documents...\n",
            "Documents loaded and split into 149 chunks.\n",
            "Total pages/documents processed: 30\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"Chunking the documents...\")\n",
        "\n",
        "# Use the documents loaded from the data folder in section 1.3\n",
        "# Make sure you've run section 1.3 first to load all_documents\n",
        "if 'all_documents' not in globals() or not all_documents:\n",
        "    raise ValueError(\"Please run section 1.3 first to load documents from the data folder.\")\n",
        "\n",
        "# Split all documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "doc_chunks = text_splitter.split_documents(all_documents)\n",
        "\n",
        "print(f\"Documents loaded and split into {len(doc_chunks)} chunks.\")\n",
        "print(f\"Total pages/documents processed: {len(all_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9803ddd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "3787f1a3486e4e1d9684c1735b5a83d5",
            "f37c2ef94b7c4471ac5d88c439d57c29",
            "5e4cdaf98a644710a2b52b6750ca80a1",
            "5e61e7626bc8423facc4e39adf9bbd8e",
            "8bcc30595a2646cdb46250accb82ecaf",
            "69224cfb3bad4fe69b1eeec23671827c",
            "7ff946aa385a4c3686e64ef3a25c6ef1",
            "e448eac9817c4fe4baf175009d7e8c3d",
            "cd44f69fdb59429db70e4a50afe99d23",
            "c50e4839d6ca40528c0c804d2e1b65f9",
            "45692e9d397544c3844ceb465acb5677",
            "b155d390f25f4cbb82f7a23466df45e8",
            "93e96fd552b4416e82bf7b24bb6ed58e",
            "c0fd41db72624b5c979ccb1b255d1c17",
            "656d63ac472749fdb6802677d2ef3684",
            "78fa54a532934e09b6286cf24b5dfa19",
            "1caa66a89fcd47ceb29b0e83f50ff725",
            "518847d2fc114e08bf4e9583ae9cbc56",
            "11ff6f0a3c704d618f0c1cd216b796d9",
            "aabee24f843b488c85c1410e035a8e8b",
            "e81fdafc5c5c443f93b3aef1f8cc490c",
            "58be876de60143f4a98444ea61247dd3",
            "97f05514ab6241c199aae2ba0214b04d",
            "333e9d45467040ceb652851f477fcc26",
            "bd7127eaadcb4df0a7f64bc4905bb9b7",
            "9d15fdcad7e149e8a0cefa35279576d0",
            "157638698cd14f5f9654e8ff506f64b8",
            "847b23a36b584711bfe94d232ec4682d",
            "591c2425aa8c4bf38c3e86b4dbf39c49",
            "9acccc0015764220ab99395679080319",
            "17931a6e1b6a4ff6b157a2c7467b9a01",
            "fd83d84bb282404a81107ac210d40b1e",
            "69876fde64b54b64a8651f49d28760d0",
            "e88a31b73e3348efa7023aafacb66a1b",
            "04571cada714422c91a9326c7c936854",
            "4b3b7abec0e545d1bd0f237fa631550f",
            "2ff9d71c41824519b104d0b55dab3d4d",
            "2acd8fa4302a454db864c9aed5858456",
            "63280d99da094e7d8ff8ab8939cf9aef",
            "fa699e5c27dd447db656fb1db4dca001",
            "f494d9a290714a67ac81f9b4214e122f",
            "a4de99c0d1aa49029a3a2e93e3c361d3",
            "b1957061d51d4250b7e416f2266ea1c8",
            "7879c05fcd8a43fd9e1fdc80be7add9a",
            "3399c110df2e456f8e99074160d0df93",
            "838d6734539040a4a90813c528dd7d9a",
            "02938a029ab9430d8a848b4cc2064519",
            "bdf77c79187842c688a320129efb8f20",
            "1bc149187eb94c6ab02b2bb688895acb",
            "8d3b5db870fe4981a9eef170d54278d2",
            "0d4c1b13b3ec426db4b47beec10670b5",
            "a03e2cdfab9545828697f3088252e905",
            "f0747656060c4d04a6aa38bf978687e1",
            "94a79854e97040df8d68255c9b24d812",
            "900dbc61cd014778b536739d06e99853",
            "f8404775a442404890e48fb6466fbfcb",
            "baa0ca00ac8f4f1b896891afa56769d6",
            "36966127998f4b0d936e8e9c9469b20d",
            "7afed18023644c08814a721311463ef0",
            "32f3f43aecd74dce9cae87e234f81040",
            "1fbe22838b6c4e97acff7b35429cbc8b",
            "aefceb78ed014e16a946ca100dc270e8",
            "5c8c9d84fb654cb0b42dbdda35fe19c5",
            "e8b1891f74ba47339d26a44bb3ca81bd",
            "d95b9207f1b448f5b3f43256f71b1a75",
            "5fad01f22b484cd584442f1946e1f8da",
            "ab0ed0de9851475285eaafa2be37a8ea",
            "278b4fdc98ff42cdb670ac512a3b6e92",
            "8fb9ecd12ede4859addf1e600108d36d",
            "ef32ffea621048e7ae0f0874df6c1428",
            "e1d8f1ef65964eedb4e43565d08efed9",
            "de8420154d5e483b913e9f3b7a4e14dd",
            "0d1172f5fc5c478cbdbb168888a8b1cf",
            "1316e9e2e9b14aefbc03b4e497990658",
            "9bf4007387b24b03a64edaa8130f63cc",
            "2c964ebf43144ecfad1f445da0c77d7b",
            "d3cee3e71d904d378803a1656828767b",
            "6ec3b4d3b69f4ed3b16d72a873f4eeb4",
            "e8dcf5cda3dd406aa2a5221c97675a09",
            "aa9070e0093040749e334438b5bc92ae",
            "a25ca01b1a9d4364b0021f1ba4718c21",
            "350210c421d54355b1147dab0a764ccb",
            "01be783453cb4846bc89701fa63453af",
            "9f4a22e27d5c44c7b21e0f8cfad710d2",
            "69491ca4e8e142508a845408e88fd3c2",
            "01c43594c6bd4f27a5d3480216a44ec6",
            "479f0d8d39d747308264dba917656217",
            "e72b748edd3e4cc497ceddfa573598d4",
            "5683517580b14d6c9e4dc594d1f4f682",
            "d20392c7947e4911960ebe1cbc17540d",
            "42068f42b5ca4fa7bab7aab80abd377a",
            "77b63ca1007b4b7090e88eddd5a3cf47",
            "0422649470ed49e7b9557dd4253eadb4",
            "413298a91dba45cb9aee06b5d9744dd6",
            "d225d8daa8104d90a816e4b0abc0988e",
            "ba7e97f93237424190e344e3474767d7",
            "129597a76a7d419c9b444e5eeb40467b",
            "504afb32726b4678bc91376659170b78",
            "a0fba7d36d9841ba8db3b2f4e7437e20",
            "6c713b9da04e493fab7aa1accc4c52ed",
            "8baaa930542b4f5e83cc5d9b4cd5edbf",
            "a3cdbcdebf3c42498a70254e80e44ae4",
            "7fd57b19bbb64023b598d8a667072054",
            "609dc5290a6e4d09aab88b06bc08ea14",
            "fd9d06436c3640acba5010e9e637c67c",
            "4fa45a8fbde844f28b0191aa97892e9f",
            "c2cf71c20d6043ccb55e61b8aac21846",
            "0473d30020804414bb18c2346425894d",
            "665277e22a72446980425172c8ed4fdb",
            "3b47fd2ca2ee4932a50ae03dcbef18a5",
            "2d23157cd4ce4db48808ac9872224845",
            "2f07aef43fc84fffb1eba45bf3d1c9ce",
            "58c12ba8fadb47eca8c5ab9a3199d3b0",
            "8bd5479d817642e8b71490da5c1a8c03",
            "663957a430fa421cb01567055235fdf3",
            "e1fb6c3002e54e54aecc0a41990655e4",
            "29d2ee7037ce4fcebaace5953afddb23",
            "d2a53fb4d83c481b927691986d20844b",
            "0d3304af69834c3e8268d0a19ead1a86",
            "540309d0f7a343068b82836e032b4236",
            "aa318d218c734e039c4b096ac7fc1c1a"
          ]
        },
        "id": "9803ddd2",
        "outputId": "1453c075-2aab-4d38-d47b-34f753e79a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating baseline vector store with FAISS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w5/k1crj13j33n3_y1sj0nlz5yw0000gn/T/ipykernel_7519/1555405908.py:28: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_function = HuggingFaceBgeEmbeddings(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created with 149 documents.\n"
          ]
        }
      ],
      "source": [
        "# Check if we're using pre-generated embeddings\n",
        "if 'using_pre_generated_embeddings' in globals() and using_pre_generated_embeddings:\n",
        "    print(\"Using pre-generated embeddings from previous cell.\")\n",
        "    print(\"Skipping vector store creation.\")\n",
        "    # doc_chunks will be needed for some operations, so we'll extract them if needed\n",
        "    # For now, we'll create a placeholder - the actual chunks are in the vector store\n",
        "    if 'doc_chunks' not in globals():\n",
        "        print(\"Note: doc_chunks variable not set. Some operations may require it.\")\n",
        "else:\n",
        "    # Use FAISS instead of ChromaDB to avoid compatibility issues\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "    \n",
        "    # Ensure required packages are installed\n",
        "    try:\n",
        "        import faiss\n",
        "    except ImportError:\n",
        "        print(\"Installing faiss-cpu...\")\n",
        "        import subprocess\n",
        "        import sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"faiss-cpu\"])\n",
        "        import faiss\n",
        "        print(\"✓ faiss-cpu installed successfully\")\n",
        "    \n",
        "    # Create embedding function\n",
        "    from src.embeddings import create_embedding_function\n",
        "    from src.vector_store import create_vector_store, create_retriever\n",
        "    \n",
        "    print(\"Creating baseline vector store with FAISS...\")\n",
        "    embedding_function = create_embedding_function(config)\n",
        "    \n",
        "    baseline_vector_store = FAISS.from_documents(\n",
        "        documents=doc_chunks,\n",
        "        embedding=embedding_function\n",
        "    )\n",
        "    baseline_retriever = baseline_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "    \n",
        "    print(f\"Vector store created with {len(doc_chunks)} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a9d21ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a9d21ad",
        "outputId": "44937cd7-dd8d-4020-927c-f6d65c1734d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using OpenAI...\n",
            "Baseline RAG chain assembled successfully for energy sector documents.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "\n",
        "# Ensure langchain_openai is installed\n",
        "try:\n",
        "    from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
        "except ImportError:\n",
        "    print(\"Installing langchain_openai package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langchain-openai\"])\n",
        "    from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
        "    print(\"✓ langchain_openai installed successfully\")\n",
        "\n",
        "# Check if using Azure OpenAI or regular OpenAI\n",
        "if config.get(\"llm_provider\") == \"azure_openai\":\n",
        "    template = \"\"\"You are an AI energy sector analyst specializing in renewable energy, green hydrogen, and energy transition. Answer the question based only on the following context from energy sector documents:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Provide a clear, accurate answer based on the context provided. If the context doesn't contain enough information to answer the question, say so.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(template)\n",
        "    \n",
        "    # Get Azure credentials from environment or config\n",
        "    api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") or config.get(\"azure_api_key\")\n",
        "    azure_endpoint = config.get(\"azure_endpoint\") or os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    azure_deployment = config.get(\"azure_deployment_name\") or config.get(\"fast_llm\")\n",
        "    api_version = config.get(\"azure_api_version\") or os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2025-01-01-preview\")\n",
        "    \n",
        "    if not api_key:\n",
        "        raise ValueError(\"Azure OpenAI API key not found. Please set AZURE_OPENAI_API_KEY environment variable or config['azure_api_key']\")\n",
        "    if not azure_endpoint:\n",
        "        raise ValueError(\"Azure OpenAI endpoint not found. Please set config['azure_endpoint'] or AZURE_OPENAI_ENDPOINT environment variable\")\n",
        "    \n",
        "    llm = AzureChatOpenAI(\n",
        "        azure_deployment=azure_deployment,\n",
        "        azure_endpoint=azure_endpoint,\n",
        "        api_version=api_version,\n",
        "        api_key=api_key,\n",
        "        temperature=0\n",
        "    )\n",
        "    print(\"Using Azure OpenAI...\")\n",
        "else:\n",
        "    template = \"\"\"You are an AI energy sector analyst specializing in renewable energy, green hydrogen, and energy transition. Answer the question based only on the following context from energy sector documents:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Provide a clear, accurate answer based on the context provided. If the context doesn't contain enough information to answer the question, say so.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(template)\n",
        "    \n",
        "    llm = ChatOpenAI(model=config[\"fast_llm\"], temperature=0)\n",
        "    print(\"Using OpenAI...\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "baseline_rag_chain = (\n",
        "    {\"context\": baseline_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(\"Baseline RAG chain assembled successfully for energy sector documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "part1-2-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part1-2-code-pro",
        "outputId": "9c639a3f-ba96-41ea-bef1-91bcab45a13e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment and configuration set up successfully.\n",
            "{'azure_api_version': '2025-01-01-preview',\n",
            " 'azure_deployment_name': 'chatbottest01-llm-gpt-4o-mini',\n",
            " 'azure_endpoint': 'https://manju-mh8ukqqk-eastus2.cognitiveservices.azure.com/openai/deployments/chatbottest01-llm-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview',\n",
            " 'data_dir': './data',\n",
            " 'embedding_model': 'BAAI/bge-small-en-v1.5',\n",
            " 'fast_llm': 'gpt-3.5-turbo-0125',\n",
            " 'llm_provider': 'azure_openai',\n",
            " 'max_reasoning_iterations': 7,\n",
            " 'reasoning_llm': 'gpt-3.5-turbo-0125',\n",
            " 'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
            " 'top_k_retrieval': 10,\n",
            " 'top_n_rerank': 3,\n",
            " 'vector_store_dir': './vector_store'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pprint import pprint\n",
        "\n",
        "# Securely set API keys\n",
        "def _set_env(var: str):\n",
        "    if var not in os.environ:\n",
        "        os.environ[var] = getpass(f\"Enter {var}: \")\n",
        "\n",
        "# Set Azure OpenAI environment variables (adjust these to your actual values)\n",
        "# Uncomment and set these if not already set in your environment\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://your-endpoint.openai.azure.com/\"\n",
        "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2025-01-01-preview\"\n",
        "# os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"your-deployment-name\"\n",
        "\n",
        "# Configure LangSmith tracing (optional)\n",
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_PROJECT\"] = \"Deep-Thinking-RAG\"\n",
        "\n",
        "# Central Configuration Dictionary\n",
        "config = {\n",
        "    \"data_dir\": \"./data\",  # Use project root data folder\n",
        "    \"vector_store_dir\": \"./vector_store\",  # Use project root for vector store\n",
        "    \"llm_provider\": \"azure_openai\",\n",
        "    \"reasoning_llm\": \"gpt-3.5-turbo-0125\",  # This will be the model deployed under AZURE_OPENAI_DEPLOYMENT_NAME\n",
        "    \"fast_llm\": \"gpt-3.5-turbo-0125\",  # This will be the model deployed under AZURE_OPENAI_DEPLOYMENT_NAME\n",
        "    \"embedding_model\": \"BAAI/bge-small-en-v1.5\",  # Using HuggingFace model to avoid Azure embedding issues\n",
        "    \"reranker_model\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    \"max_reasoning_iterations\": 7,  # Maximum loops for the reasoning agent\n",
        "    \"top_k_retrieval\": 10,  # Number of documents for initial broad recall\n",
        "    \"top_n_rerank\": 3,\n",
        "    \"azure_deployment_name\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
        "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    \"azure_api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2025-01-01-preview\"),\n",
        "}\n",
        "\n",
        "# Create directories if they don't exist (only if they're in writable locations)\n",
        "try:\n",
        "    os.makedirs(config[\"data_dir\"], exist_ok=True)\n",
        "except (OSError, PermissionError) as e:\n",
        "    print(f\"⚠ Warning: Could not create data directory: {e}\")\n",
        "    print(f\"  Using existing directory: {config['data_dir']}\")\n",
        "\n",
        "try:\n",
        "    os.makedirs(config[\"vector_store_dir\"], exist_ok=True)\n",
        "except (OSError, PermissionError) as e:\n",
        "    print(f\"⚠ Warning: Could not create vector store directory: {e}\")\n",
        "    print(f\"  Using existing directory: {config['vector_store_dir']}\")\n",
        "\n",
        "print(\"Environment and configuration set up successfully.\")\n",
        "pprint(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-2-dep-pro",
      "metadata": {
        "id": "part2-2-dep-pro"
      },
      "source": [
        "### 2.2. Code Dependency: Creating the Vector Store with Dense Embeddings\n",
        "\n",
        "Next, we embed these chunks using OpenAI's `text-embedding-3-small` model and index them in a ChromaDB vector store. This store will power our baseline retriever, which performs a simple semantic similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "part2-2-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part2-2-code-pro",
        "outputId": "e5c0a7bb-fe7e-4da9-8da9-47d655041ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using HuggingFace embeddings (fallback)...\n",
            "Creating baseline vector store with FAISS...\n",
            "Vector store created with 149 documents.\n"
          ]
        }
      ],
      "source": [
        "# Use FAISS instead of ChromaDB to avoid compatibility issues\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Ensure required packages are installed\n",
        "try:\n",
        "    import faiss\n",
        "except ImportError:\n",
        "    print(\"Installing faiss-cpu...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"faiss-cpu\"])\n",
        "    import faiss\n",
        "    print(\"✓ faiss-cpu installed successfully\")\n",
        "\n",
        "# Determine which embedding class to use based on the model name\n",
        "embedding_model = config['embedding_model']\n",
        "embedding_function = None\n",
        "\n",
        "if embedding_model.startswith('text-embedding') or 'openai' in embedding_model.lower():\n",
        "    # Try OpenAI embeddings (Azure or regular)\n",
        "    if config.get(\"llm_provider\") == \"azure_openai\":\n",
        "        try:\n",
        "            from langchain_openai import AzureOpenAIEmbeddings\n",
        "            import os\n",
        "            \n",
        "            api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") or config.get(\"azure_api_key\")\n",
        "            azure_endpoint = config.get(\"azure_endpoint\") or os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "            api_version = config.get(\"azure_api_version\") or os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2025-01-01-preview\")\n",
        "            \n",
        "            # Try to use Azure OpenAI embeddings\n",
        "            # Note: You may need a separate deployment for embeddings\n",
        "            # If embedding deployment name is different, set it in config as 'azure_embedding_deployment'\n",
        "            embedding_deployment = config.get(\"azure_embedding_deployment\") or embedding_model\n",
        "            \n",
        "            if api_key and azure_endpoint:\n",
        "                print(\"Attempting to use Azure OpenAI embeddings...\")\n",
        "                embedding_function = AzureOpenAIEmbeddings(\n",
        "                    azure_deployment=embedding_deployment,\n",
        "                    azure_endpoint=azure_endpoint,\n",
        "                    api_version=api_version,\n",
        "                    api_key=api_key\n",
        "                )\n",
        "                # Test the embedding function\n",
        "                try:\n",
        "                    test_embedding = embedding_function.embed_query(\"test\")\n",
        "                    print(\"✓ Azure OpenAI embeddings working\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠ Azure OpenAI embeddings failed: {e}\")\n",
        "                    print(\"Falling back to HuggingFace embeddings...\")\n",
        "                    embedding_function = None\n",
        "            else:\n",
        "                print(\"⚠ Azure OpenAI credentials not found, falling back to HuggingFace embeddings...\")\n",
        "                embedding_function = None\n",
        "        except ImportError:\n",
        "            print(\"⚠ langchain-openai not available, falling back to HuggingFace embeddings...\")\n",
        "            embedding_function = None\n",
        "        except Exception as e:\n",
        "            print(f\"⚠ Error setting up Azure OpenAI embeddings: {e}\")\n",
        "            print(\"Falling back to HuggingFace embeddings...\")\n",
        "            embedding_function = None\n",
        "    \n",
        "    # If Azure failed or not configured, try regular OpenAI\n",
        "    if embedding_function is None and config.get(\"llm_provider\") != \"azure_openai\":\n",
        "        try:\n",
        "            from langchain_openai import OpenAIEmbeddings\n",
        "            print(\"Using OpenAI embeddings...\")\n",
        "            embedding_function = OpenAIEmbeddings(model=embedding_model)\n",
        "        except ImportError:\n",
        "            print(\"⚠ langchain-openai not available, falling back to HuggingFace embeddings...\")\n",
        "            embedding_function = None\n",
        "        except Exception as e:\n",
        "            print(f\"⚠ Error setting up OpenAI embeddings: {e}\")\n",
        "            print(\"Falling back to HuggingFace embeddings...\")\n",
        "            embedding_function = None\n",
        "\n",
        "# Fallback to HuggingFace embeddings if OpenAI didn't work\n",
        "if embedding_function is None:\n",
        "    try:\n",
        "        import sentence_transformers\n",
        "    except ImportError:\n",
        "        print(\"Installing sentence-transformers...\")\n",
        "        import subprocess\n",
        "        import sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sentence-transformers\"])\n",
        "        import sentence_transformers\n",
        "        print(\"✓ sentence-transformers installed\")\n",
        "    \n",
        "    from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "    print(\"Using HuggingFace embeddings (fallback)...\")\n",
        "    \n",
        "    # Use a reliable HuggingFace model if the config model isn't a valid HF model\n",
        "    if embedding_model.startswith('text-embedding'):\n",
        "        # If config has OpenAI model name, use a default HuggingFace model\n",
        "        hf_model = \"BAAI/bge-small-en-v1.5\"\n",
        "        print(f\"  Using {hf_model} instead of {embedding_model}\")\n",
        "    else:\n",
        "        hf_model = embedding_model\n",
        "    \n",
        "    embedding_function = HuggingFaceBgeEmbeddings(\n",
        "        model_name=hf_model,\n",
        "        encode_kwargs={'normalize_embeddings': True}\n",
        "    )\n",
        "\n",
        "print(\"Creating baseline vector store with FAISS...\")\n",
        "baseline_vector_store = FAISS.from_documents(\n",
        "    documents=doc_chunks,\n",
        "    embedding=embedding_function\n",
        ")\n",
        "baseline_retriever = baseline_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "print(f\"Vector store created with {len(doc_chunks)} documents.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-3-dep-pro",
      "metadata": {
        "id": "part2-3-dep-pro"
      },
      "source": [
        "### 2.3. Code Dependency: Assembling the Simple RAG Chain\n",
        "\n",
        "We use the LangChain Expression Language (LCEL) to construct our linear pipeline. The `RunnablePassthrough` allows us to pass the original question alongside the retrieved context into the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "part2-3-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part2-3-code-pro",
        "outputId": "cd5d480a-8633-4be8-dd31-d9f8eabf480b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline RAG chain assembled successfully.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI # Changed import\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "template = \"\"\"You are an AI energy sector analyst specializing in renewable energy, green hydrogen, and energy transition. Answer the question based only on the following context from energy sector documents:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=config[\"azure_deployment_name\"],\n",
        "    azure_endpoint=config[\"azure_endpoint\"],\n",
        "    api_version=config[\"azure_api_version\"],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "baseline_rag_chain = (\n",
        "    {\"context\": baseline_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(\"Baseline RAG chain assembled successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-4-fail-pro-adv",
      "metadata": {
        "id": "part2-4-fail-pro-adv"
      },
      "source": [
        "### 2.4. The Critical Failure Case: Demonstrating the Need for Advanced Techniques\n",
        "\n",
        "Now we execute our multi-source query against the baseline system. The retriever will attempt to find chunks that match the 'average' semantic meaning of the entire query. This will fail spectacularly because critical information (about AMD's 2024 strategy) does not exist in its knowledge base (the 2023 10-K)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "part2-4-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "part2-4-code-pro-adv",
        "outputId": "f603b03a-995d-470e-a3a6-0d7f355b5b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking Azure OpenAI configuration...\n",
            "  Endpoint: https://manju-mh8ukqqk-eastus2.cognitiveservices.azure.com/openai/deployments/chatbottest01-llm-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview\n",
            "  Deployment: chatbottest01-llm-gpt-4o-mini\n",
            "  API Key: ***NRA1\n",
            "\n",
            "Testing Azure OpenAI connection...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Azure OpenAI connection successful\n",
            "\n",
            "============================================================\n",
            "Executing complex query on the baseline RAG chain...\n",
            "============================================================\n",
            "Query: What are the key cost benchmarks and performance metrics for green hydrogen production in India as outlined in the benchmarking document? Compare these to conventional hydrogen production methods and identify the main factors affecting cost competitiveness.\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- BASELINE RAG OUTPUT ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "--- BASELINE RAG OUTPUT ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The provided context does not contain specific information regarding the cost benchmarks and performance metrics   \n",
              "for green hydrogen production in India, nor does it compare these to conventional hydrogen production methods. The \n",
              "text primarily discusses the challenges and potential of renewable energy sources, particularly solar energy, in   \n",
              "India, along with the government's policies and the importance of clean energy for economic and climatic growth.   \n",
              "\n",
              "To answer your question accurately, I would need specific details from a benchmarking document that outlines the   \n",
              "cost benchmarks and performance metrics for green hydrogen production, as well as comparisons to conventional      \n",
              "methods and factors affecting cost competitiveness. If you have such information or another context, please provide\n",
              "it, and I would be happy to assist!                                                                                \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The provided context does not contain specific information regarding the cost benchmarks and performance metrics   \n",
              "for green hydrogen production in India, nor does it compare these to conventional hydrogen production methods. The \n",
              "text primarily discusses the challenges and potential of renewable energy sources, particularly solar energy, in   \n",
              "India, along with the government's policies and the importance of clean energy for economic and climatic growth.   \n",
              "\n",
              "To answer your question accurately, I would need specific details from a benchmarking document that outlines the   \n",
              "cost benchmarks and performance metrics for green hydrogen production, as well as comparisons to conventional      \n",
              "methods and factors affecting cost competitiveness. If you have such information or another context, please provide\n",
              "it, and I would be happy to assist!                                                                                \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Try to import rich, install if missing\n",
        "try:\n",
        "    from rich.console import Console\n",
        "    from rich.markdown import Markdown\n",
        "    console = Console()\n",
        "    use_rich = True\n",
        "except ImportError:\n",
        "    print(\"Installing rich package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rich\"])\n",
        "        from rich.console import Console\n",
        "        from rich.markdown import Markdown\n",
        "        console = Console()\n",
        "        use_rich = True\n",
        "        print(\"✓ rich installed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Could not install rich: {e}\")\n",
        "        print(\"Using standard print instead...\")\n",
        "        use_rich = False\n",
        "\n",
        "# Validate Azure OpenAI credentials before running query\n",
        "import os\n",
        "\n",
        "if config.get(\"llm_provider\") == \"azure_openai\":\n",
        "    api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") or config.get(\"azure_api_key\")\n",
        "    azure_endpoint = config.get(\"azure_endpoint\") or os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    azure_deployment = config.get(\"azure_deployment_name\") or config.get(\"fast_llm\")\n",
        "    \n",
        "    print(\"Checking Azure OpenAI configuration...\")\n",
        "    print(f\"  Endpoint: {azure_endpoint}\")\n",
        "    print(f\"  Deployment: {azure_deployment}\")\n",
        "    print(f\"  API Key: {'***' + api_key[-4:] if api_key else 'NOT SET'}\")\n",
        "    \n",
        "    if not api_key:\n",
        "        raise ValueError(\n",
        "            \"❌ AZURE_OPENAI_API_KEY is not set. Please set it in your environment or config.\\n\"\n",
        "            \"   You can set it by running: os.environ['AZURE_OPENAI_API_KEY'] = 'your-key-here'\"\n",
        "        )\n",
        "    if not azure_endpoint:\n",
        "        raise ValueError(\n",
        "            \"❌ AZURE_OPENAI_ENDPOINT is not set. Please set it in your environment or config.\\n\"\n",
        "            \"   You can set it by running: os.environ['AZURE_OPENAI_ENDPOINT'] = 'your-endpoint-here'\"\n",
        "        )\n",
        "    \n",
        "    # Test the LLM connection\n",
        "    print(\"\\nTesting Azure OpenAI connection...\")\n",
        "    try:\n",
        "        test_response = llm.invoke(\"Hello\")\n",
        "        print(\"✓ Azure OpenAI connection successful\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Azure OpenAI connection failed: {e}\")\n",
        "        print(\"\\nPlease check:\")\n",
        "        print(\"  1. Your API key is correct and active\")\n",
        "        print(\"  2. Your endpoint URL is correct\")\n",
        "        print(\"  3. Your deployment name exists and is active\")\n",
        "        print(\"  4. Your subscription has sufficient quota\")\n",
        "        raise\n",
        "\n",
        "# Query specific to the green hydrogen benchmarking document\n",
        "complex_query_adv = \"What are the key cost benchmarks and performance metrics for green hydrogen production in India as outlined in the benchmarking document? Compare these to conventional hydrogen production methods and identify the main factors affecting cost competitiveness.\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Executing complex query on the baseline RAG chain...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Query: {complex_query_adv}\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    baseline_result = baseline_rag_chain.invoke(complex_query_adv)\n",
        "    \n",
        "    if use_rich:\n",
        "        console.print(\"\\n--- BASELINE RAG OUTPUT ---\")\n",
        "        console.print(Markdown(baseline_result))\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"BASELINE RAG OUTPUT\")\n",
        "        print(\"=\" * 60)\n",
        "        print(baseline_result)\n",
        "        print(\"=\" * 60)\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error executing query: {e}\")\n",
        "    print(\"\\nTroubleshooting steps:\")\n",
        "    print(\"1. Verify your Azure OpenAI credentials are set correctly\")\n",
        "    print(\"2. Check that your deployment name matches your Azure resource\")\n",
        "    print(\"3. Ensure your subscription is active and has quota\")\n",
        "    print(\"4. Verify the endpoint URL is correct\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "part2-4-code-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "part2-4-code-adv",
        "outputId": "8055ed7a-b366-4372-9058-91bd745d2f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing complex query on the baseline RAG chain...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- BASELINE RAG FAILED OUTPUT ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- BASELINE RAG FAILED OUTPUT ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The provided context does not contain specific information regarding the cost benchmarks and performance metrics   \n",
              "for green hydrogen production in India, nor does it compare these to conventional hydrogen production methods. The \n",
              "text primarily discusses the challenges and potential of renewable energy sources, particularly solar energy, in   \n",
              "India, along with the government's policies and the importance of clean energy for economic and climatic growth.   \n",
              "\n",
              "To answer your question accurately, I would need specific details from a benchmarking document that outlines the   \n",
              "cost benchmarks and performance metrics for green hydrogen production, as well as comparisons to conventional      \n",
              "methods and the factors affecting cost competitiveness. If you have access to such a document or additional        \n",
              "information, please provide it, and I would be happy to assist you further.                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The provided context does not contain specific information regarding the cost benchmarks and performance metrics   \n",
              "for green hydrogen production in India, nor does it compare these to conventional hydrogen production methods. The \n",
              "text primarily discusses the challenges and potential of renewable energy sources, particularly solar energy, in   \n",
              "India, along with the government's policies and the importance of clean energy for economic and climatic growth.   \n",
              "\n",
              "To answer your question accurately, I would need specific details from a benchmarking document that outlines the   \n",
              "cost benchmarks and performance metrics for green hydrogen production, as well as comparisons to conventional      \n",
              "methods and the factors affecting cost competitiveness. If you have access to such a document or additional        \n",
              "information, please provide it, and I would be happy to assist you further.                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "console = Console()\n",
        "\n",
        "complex_query_adv = \"What are the key cost benchmarks and performance metrics for green hydrogen production in India as outlined in the benchmarking document? Compare these to conventional hydrogen production methods and identify the main factors affecting cost competitiveness.\"\n",
        "\n",
        "print(\"Executing complex query on the baseline RAG chain...\")\n",
        "baseline_result = baseline_rag_chain.invoke(complex_query_adv)\n",
        "\n",
        "console.print(\"--- BASELINE RAG FAILED OUTPUT ---\")\n",
        "console.print(Markdown(baseline_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part2-5-diag-pro-adv",
      "metadata": {
        "id": "part2-5-diag-pro-adv"
      },
      "source": [
        "### 2.5. Diagnosis: Why Did It Fail?\n",
        "\n",
        "The output is a classic failure case for RAG systems confined to a static knowledge base.\n",
        "\n",
        "1.  **Irrelevant Context:** The retriever, trying to satisfy all parts of the query at once, likely pulled chunks related to \"competition\" and \"AMD\" from the 10-K, but this information is general and lacks the specifics required.\n",
        "2.  **Missing Information:** The 2023 filing **cannot** contain information about events in 2024. The baseline system has no mechanism to access external, up-to-date knowledge.\n",
        "3.  **No Synthesis:** The system correctly states that it lacks the required information. It cannot perform the requested synthesis because it failed to retrieve one of the two necessary pieces of evidence. It lacks any mechanism to recognize this gap and use a different tool (like web search) to fill it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-intro-deep-pro",
      "metadata": {
        "id": "part3-intro-deep-pro"
      },
      "source": [
        "## Part 3: The \"Deep Thinking\" Upgrade: Engineering an Autonomous Reasoning Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-1-state-pro-adv",
      "metadata": {
        "id": "part3-1-state-pro-adv"
      },
      "source": [
        "### 3.1. Code Dependency: Defining the `RAGState` - The Central Nervous System of Our Agent\n",
        "\n",
        "To build our reasoning agent, we first need a robust way to manage its state. The `RAGState` `TypedDict` will serve as the central nervous system for our agent. It will be passed between every node in our LangGraph workflow, allowing the agent to maintain a coherent line of reasoning, track its progress, and build a comprehensive base of evidence over multiple steps. We will now enhance our `Step` Pydantic model to include a `tool` field, which will be crucial for routing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "part3-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-1-code-pro-adv",
        "outputId": "831c8dda-3105-4db2-e5d4-c1cc194223d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAGState and supporting Pydantic classes defined successfully. \n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from pydantic import BaseModel, Field # Changed import\n",
        "from typing import List, Dict, TypedDict, Literal, Optional\n",
        "\n",
        "# Pydantic model for a single step in the reasoning plan\n",
        "# Update Step model to use correct tool names\n",
        "class Step(BaseModel):\n",
        "    sub_question: str = Field(description=\"A clear, specific sub-question to answer.\")\n",
        "    justification: str = Field(description=\"Why this step is necessary.\")\n",
        "    tool: Literal[\"search_documents\", \"search_web\"] = Field(\n",
        "        description=\"The tool to use: 'search_documents' for local documents, 'search_web' for web search.\"\n",
        "    )\n",
        "    keywords: List[str] = Field(description=\"A list of critical keywords for searching.\")\n",
        "    document_section: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Optional document section to filter search (for 'search_documents' only).\"\n",
        "    )\n",
        "\n",
        "# Pydantic model for the overall plan\n",
        "class Plan(BaseModel):\n",
        "    steps: List[Step] = Field(description=\"A detailed, multi-step plan to answer the user's query.\")\n",
        "\n",
        "# TypedDict for storing the results of a completed step\n",
        "class PastStep(TypedDict):\n",
        "    step_index: int\n",
        "    sub_question: str\n",
        "    retrieved_docs: List[Document]\n",
        "    summary: str\n",
        "\n",
        "# The main state dictionary that will flow through the graph\n",
        "class RAGState(TypedDict):\n",
        "    original_question: str\n",
        "    plan: Plan\n",
        "    past_steps: List[PastStep]\n",
        "    current_step_index: int\n",
        "    retrieved_docs: List[Document]\n",
        "    reranked_docs: List[Document]\n",
        "    synthesized_context: str\n",
        "    final_answer: str\n",
        "\n",
        "print(\"RAGState and supporting Pydantic classes defined successfully. \") # Added a space to force modification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-2-planner-pro-adv",
      "metadata": {
        "id": "part3-2-planner-pro-adv"
      },
      "source": [
        "### 3.2. Component 1: Dynamic Planning and Query Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-2-1-planner-pro-adv",
      "metadata": {
        "id": "part3-2-1-planner-pro-adv"
      },
      "source": [
        "#### 3.2.1. The Tool-Aware Planner Agent: Decomposing the user query and selecting the right tool for each step.\n",
        "\n",
        "The first cognitive act of our agent is to **plan**. We upgrade our 'Planner Agent' to be **tool-aware**. Its sole responsibility is to take the complex user query and decompose it into a structured, multi-step `Plan` object. Crucially, for each step, it must now decide whether the information is likely to be in the static document (`search_10k`) or requires up-to-date, external information (`search_web`). This decision-making at the planning stage is fundamental to the agent's intelligence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "part3-2-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "part3-2-1-code-pro-adv",
        "outputId": "a589222b-6b44-4126-cc48-881279ad47b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool-Aware Planner Agent created successfully.\n",
            "--- Testing Planner Agent ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Plan</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the key cost benchmarks for green hydrogen production in India?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Understanding the cost benchmarks is essential to evaluate the economic viability of green hydrogen production in India.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cost benchmarks'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen production'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'India'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cost benchmarks'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the performance metrics for green hydrogen production in India?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Performance metrics will provide insights into the efficiency and effectiveness of green hydrogen production processes.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'performance metrics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen production'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'India'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'performance metrics'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'How do the cost benchmarks for green hydrogen compare to conventional hydrogen production methods?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A comparative analysis will highlight the differences in cost structures between green and conventional hydrogen production.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cost comparison'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'conventional hydrogen'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'comparative analysis'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the main factors affecting the cost competitiveness of green hydrogen production?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Identifying these factors will help understand the challenges and opportunities for green hydrogen in the market.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cost competitiveness'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'factors affecting cost'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'challenges and opportunities'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mPlan\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the key cost benchmarks for green hydrogen production in India?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Understanding the cost benchmarks is essential to evaluate the economic viability of green hydrogen production in India.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cost benchmarks'\u001b[0m, \u001b[32m'green hydrogen production'\u001b[0m, \u001b[32m'India'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'cost benchmarks'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the performance metrics for green hydrogen production in India?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Performance metrics will provide insights into the efficiency and effectiveness of green hydrogen production processes.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'performance metrics'\u001b[0m, \u001b[32m'green hydrogen production'\u001b[0m, \u001b[32m'India'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'performance metrics'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'How do the cost benchmarks for green hydrogen compare to conventional hydrogen production methods?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'A comparative analysis will highlight the differences in cost structures between green and conventional hydrogen production.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cost comparison'\u001b[0m, \u001b[32m'green hydrogen'\u001b[0m, \u001b[32m'conventional hydrogen'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'comparative analysis'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the main factors affecting the cost competitiveness of green hydrogen production?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Identifying these factors will help understand the challenges and opportunities for green hydrogen in the market.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cost competitiveness'\u001b[0m, \u001b[32m'green hydrogen'\u001b[0m, \u001b[32m'factors affecting cost'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'challenges and opportunities'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from rich.pretty import pprint as rprint\n",
        "\n",
        "planner_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert research planner specializing in energy sector analysis. Your task is to create a clear, multi-step plan to answer a complex user query by retrieving information from multiple sources.\n",
        "\n",
        "You have two tools available:\n",
        "1. `search_documents`: Use this to search for information within the green hydrogen benchmarking document and other energy sector documents in the knowledge base. This is best for:\n",
        "   - Technical specifications, cost benchmarks, and performance metrics\n",
        "   - Policy frameworks, regulatory measures, and government initiatives\n",
        "   - Market analysis, projections, and roadmaps\n",
        "   - Comparative analysis with other countries or regions\n",
        "   - Challenges, opportunities, and recommendations\n",
        "   - Any information contained in the uploaded energy sector documents\n",
        "\n",
        "2. `search_web`: Use this to search the public internet for:\n",
        "   - Recent news and developments (post-document publication)\n",
        "   - Current market trends and updates\n",
        "   - Latest policy announcements or regulatory changes\n",
        "   - Competitor information or industry developments\n",
        "   - Any information not available in the local document knowledge base\n",
        "\n",
        "Decompose the user's query into a series of simple, sequential sub-questions. For each step, decide which tool is more appropriate.\n",
        "\n",
        "For `search_documents` steps, identify the most relevant sections or topics to search for (e.g., 'cost benchmarks', 'policy frameworks', 'technical specifications', 'market projections', 'challenges and opportunities', 'comparative analysis').\n",
        "\n",
        "Ensure the plan is concise, with no more than 4-5 steps, focusing on the most critical information gathering and synthesis needed to comprehensively answer the user's query about green hydrogen and India's energy transition.\"\"\"),\n",
        "    (\"human\", \"User Query: {question}\")\n",
        "])\n",
        "\n",
        "reasoning_llm = AzureChatOpenAI(\n",
        "    azure_deployment=config[\"azure_deployment_name\"],\n",
        "    azure_endpoint=config[\"azure_endpoint\"],\n",
        "    api_version=config[\"azure_api_version\"],\n",
        "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "    temperature=0\n",
        ")\n",
        "planner_agent = planner_prompt | reasoning_llm.with_structured_output(Plan)\n",
        "print(\"Tool-Aware Planner Agent created successfully.\")\n",
        "\n",
        "# Test the planner agent\n",
        "print(\"--- Testing Planner Agent ---\")\n",
        "try:\n",
        "    test_plan = planner_agent.invoke({\"question\": complex_query_adv})\n",
        "    rprint(test_plan)\n",
        "except Exception as e:\n",
        "    print(f\"Error during planner agent test: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-2-2-rewriter-pro",
      "metadata": {
        "id": "part3-2-2-rewriter-pro"
      },
      "source": [
        "#### 3.2.2. Query Rewriting and Expansion: Using an LLM to transform naive sub-questions into high-quality search queries.\n",
        "\n",
        "A sub-question from the plan (e.g., \"What are the risks?\") might not be the optimal query for a vector database or web search engine. We create a 'Query Rewriter' agent that enriches the sub-question with keywords from the plan and context from previous steps, making it a much more effective search query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "part3-2-2-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-2-2-code-pro",
        "outputId": "5739527b-5230-4bbc-eaa9-fe9bf5af74b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Rewriter Agent created successfully.\n",
            "--- Testing Query Rewriter Agent ---\n",
            "Original sub-question: What are the key cost benchmarks for green hydrogen production in India?\n",
            "Rewritten Search Query: Rewritten search query: \"key cost benchmarks for green hydrogen production in India 2023 electrolyzer costs renewable energy prices infrastructure requirements production-linked incentives annual targets 5 million tonnes\"\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "import os\n",
        "\n",
        "query_rewriter_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a search query optimization expert specializing in energy sector and technical documents. Your task is to rewrite a given sub-question into a highly effective search query for a vector database or web search engine, using keywords and context from the research plan.\n",
        "\n",
        "The rewritten query should be:\n",
        "- Specific and use terminology likely to be found in energy sector documents (e.g., \"green hydrogen\", \"levelized cost of hydrogen (LCOH)\", \"electrolyzer efficiency\", \"renewable energy\", \"energy transition\", \"policy frameworks\", \"cost benchmarks\", \"market projections\")\n",
        "- Structured to retrieve the most relevant text snippets from benchmarking documents, technical reports, or policy papers\n",
        "- Use domain-specific terms that appear in green hydrogen and energy transition literature\n",
        "- Include relevant metrics, comparisons, or technical specifications when applicable\"\"\"),\n",
        "    (\"human\", \"Current sub-question: {sub_question}\\n\\nRelevant keywords from plan: {keywords}\\n\\nContext from past steps:\\n{past_context}\")\n",
        "])\n",
        "\n",
        "# Ensure reasoning_llm is defined (should be from previous cell)\n",
        "if 'reasoning_llm' not in locals():\n",
        "    reasoning_llm = AzureChatOpenAI(\n",
        "        azure_deployment=config[\"azure_deployment_name\"],\n",
        "        azure_endpoint=config[\"azure_endpoint\"],\n",
        "        api_version=config[\"azure_api_version\"],\n",
        "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "query_rewriter_agent = query_rewriter_prompt | reasoning_llm | StrOutputParser()\n",
        "print(\"Query Rewriter Agent created successfully.\")\n",
        "\n",
        "# Test the rewriter agent\n",
        "print(\"--- Testing Query Rewriter Agent ---\")\n",
        "try:\n",
        "    # Ensure test_plan is available from the previous cell's execution\n",
        "    if 'test_plan' in locals():\n",
        "        # Use the first step from the plan for testing\n",
        "        test_sub_q = test_plan.steps[0] if test_plan.steps else None\n",
        "        if test_sub_q:\n",
        "            # Updated test context for green hydrogen document\n",
        "            test_past_context = \"\"\"Step 1 Summary: The green hydrogen benchmarking document identifies key cost factors including electrolyzer costs, renewable energy prices, and infrastructure requirements. Step 2 Summary: India's green hydrogen policy framework includes production-linked incentives and targets for 5 million tonnes annual production by 2030.\"\"\"\n",
        "            rewritten_q = query_rewriter_agent.invoke({\n",
        "                \"sub_question\": test_sub_q.sub_question,\n",
        "                \"keywords\": test_sub_q.keywords if hasattr(test_sub_q, 'keywords') else \"\",\n",
        "                \"past_context\": test_past_context\n",
        "            })\n",
        "            print(f\"Original sub-question: {test_sub_q.sub_question}\")\n",
        "            print(f\"Rewritten Search Query: {rewritten_q}\")\n",
        "        else:\n",
        "            print(\"No steps found in test_plan.\")\n",
        "    else:\n",
        "        # Create a sample test if test_plan is not available\n",
        "        print(\"test_plan not defined. Running sample test...\")\n",
        "        sample_sub_question = \"What are the cost benchmarks for green hydrogen production in India?\"\n",
        "        sample_keywords = \"cost benchmarks, green hydrogen, India, production costs, LCOH\"\n",
        "        sample_context = \"Previous analysis identified key cost factors including electrolyzer efficiency and renewable energy pricing.\"\n",
        "        \n",
        "        rewritten_q = query_rewriter_agent.invoke({\n",
        "            \"sub_question\": sample_sub_question,\n",
        "            \"keywords\": sample_keywords,\n",
        "            \"past_context\": sample_context\n",
        "        })\n",
        "        print(f\"Sample sub-question: {sample_sub_question}\")\n",
        "        print(f\"Rewritten Search Query: {rewritten_q}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during query rewriter agent test: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-2-3-metadata-pro",
      "metadata": {
        "id": "part3-2-3-metadata-pro"
      },
      "source": [
        "#### 3.2.3. Entity and Constraint Extraction: Identifying metadata filters to enable filtered vector search.\n",
        "\n",
        "This is a crucial step for precision when using the `search_10k` tool. Our planner already extracts the likely `document_section`. To use this, we need to re-process our documents, adding this section title as metadata to each chunk. This allows us to perform a *filtered search*, telling the vector store to *only* search within chunks that have the correct metadata (e.g., only search for risks in the 'Risk Factors' section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "part3-2-3-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "part3-2-3-code-pro",
        "outputId": "97da6f97-9341-4148-bce7-57c90eee9f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing documents and adding metadata...\n",
            "Using 30 documents from all_documents\n",
            "Extracted 301 content sections with titles.\n",
            "Section titles found:\n",
            "  - Citation: Dubey, B.; Agrawal, S.;\n",
            "  - Energies 2023, 16, 5491.\n",
            "  - , Seema Agrawal and Ashok Kumar Sharma\n",
            "  - * Correspondence: bharatdubey8888@gmail.com\n",
            "  - 482 GW of installed capacity and more than 40 percent of power production (inclu\n",
            "  - 500 GW of green and clean energy by 2030. This paper highlights the important de\n",
            "  - India has signiﬁcant potential for clean and green energy opportunities in the f\n",
            "  - The MNRE estimates a renewable energy potential of around 1700.68 GW from abunda\n",
            "  - Energies 2023, 16, 5491 2 of 30\n",
            "  - A total of 42.6% of the nation’s installed capacity is made up of generation usi\n",
            "\n",
            "Created 305 chunks with section metadata.\n",
            "\n",
            "--- Sample Chunks with Metadata ---\n",
            "\n",
            "Chunk 1:\n",
            "  Section: Energies 2023, 16, 5491.\n",
            "  Source: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "  Content preview: https://doi.org/10.3390/en16145491\n",
            "Academic Editor: Manolis Souliotis\n",
            "Received: 15 June 2023\n",
            "Revised: 11 July 2023\n",
            "Accepted: 17 July 2023...\n",
            "\n",
            "Chunk 2:\n",
            "  Section: , Seema Agrawal and Ashok Kumar Sharma\n",
            "  Source: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "  Content preview: Department of Electrical Engineering, Rajasthan Technical University, Rawatbhata Road, Kota 324010, India;...\n",
            "\n",
            "Chunk 3:\n",
            "  Section: * Correspondence: bharatdubey8888@gmail.com\n",
            "  Source: Copy of Benchmarking-Green-Hydrogen-in-Indias-Energy-Transition.pdf\n",
            "  Content preview: Abstract: Access to inexpensive, safe, consistent, and clean energy is a critical necessity for all to\n",
            "achieve the SDGs. India’s renewable energy (RE)...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from rich.pretty import pprint as rprint\n",
        "import uuid\n",
        "from typing import List, Dict, TypedDict, Literal, Optional\n",
        "\n",
        "print(\"Processing documents and adding metadata...\")\n",
        "\n",
        "# Use all_documents from section 1.3, or doc_chunks from section 2.1\n",
        "if 'all_documents' in globals() and all_documents:\n",
        "    source_documents = all_documents\n",
        "    print(f\"Using {len(source_documents)} documents from all_documents\")\n",
        "elif 'doc_chunks' in globals() and doc_chunks:\n",
        "    source_documents = doc_chunks\n",
        "    print(f\"Using {len(doc_chunks)} chunks from doc_chunks\")\n",
        "else:\n",
        "    raise ValueError(\"No documents found. Please run section 1.3 to load documents first.\")\n",
        "\n",
        "# Combine all document content for section extraction\n",
        "raw_text = \"\\n\\n\".join([doc.page_content for doc in source_documents])\n",
        "\n",
        "# Define patterns to identify section headers in energy sector documents\n",
        "# Common patterns: numbered sections, chapter titles, major headings\n",
        "section_patterns = [\n",
        "    re.compile(r'^(Chapter\\s+\\d+[\\.:]?\\s+[A-Z][^\\n]*)', re.MULTILINE | re.IGNORECASE),\n",
        "    re.compile(r'^(\\d+\\.\\s+[A-Z][^\\n]*)', re.MULTILINE),  # Numbered sections like \"1. Introduction\"\n",
        "    re.compile(r'^([A-Z][A-Z\\s]{10,}\\n)', re.MULTILINE),  # ALL CAPS headings\n",
        "    re.compile(r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\s*:?\\s*\\n)', re.MULTILINE),  # Title Case headings\n",
        "]\n",
        "\n",
        "# Try to find sections using multiple patterns\n",
        "sections_data = []\n",
        "current_section = (\"Introduction\", \"\")\n",
        "lines = raw_text.split('\\n')\n",
        "\n",
        "# Simple heuristic: Look for lines that look like section headers\n",
        "# (short lines, title case, followed by content)\n",
        "potential_sections = []\n",
        "for i, line in enumerate(lines):\n",
        "    line_stripped = line.strip()\n",
        "    # Skip empty lines\n",
        "    if not line_stripped:\n",
        "        continue\n",
        "    \n",
        "    # Check if line looks like a section header\n",
        "    # Criteria: relatively short, title case or all caps, possibly numbered\n",
        "    is_potential_header = (\n",
        "        len(line_stripped) < 100 and  # Not too long\n",
        "        (line_stripped[0].isupper() or line_stripped[0].isdigit()) and  # Starts with capital or number\n",
        "        (line_stripped.isupper() or  # All caps\n",
        "         any(c.isupper() for c in line_stripped if c.isalpha())) and  # Has capitals\n",
        "        not line_stripped.endswith('.') or len(line_stripped.split()) < 10  # Not a full sentence\n",
        "    )\n",
        "    \n",
        "    if is_potential_header:\n",
        "        # Check if next few lines have content (not just another header)\n",
        "        next_content = \"\"\n",
        "        for j in range(i+1, min(i+5, len(lines))):\n",
        "            if lines[j].strip() and not lines[j].strip()[0].isupper() or len(lines[j].strip()) > 50:\n",
        "                next_content = lines[j].strip()\n",
        "                break\n",
        "        \n",
        "        if next_content or i == 0:  # Include first potential header or ones with content\n",
        "            potential_sections.append((i, line_stripped))\n",
        "\n",
        "# If we found potential sections, use them\n",
        "if potential_sections:\n",
        "    for idx, (line_num, header) in enumerate(potential_sections):\n",
        "        next_line_num = potential_sections[idx + 1][0] if idx + 1 < len(potential_sections) else len(lines)\n",
        "        content = '\\n'.join(lines[line_num+1:next_line_num]).strip()\n",
        "        if content or idx == 0:  # Include first section even if empty\n",
        "            sections_data.append((header, content))\n",
        "else:\n",
        "    # Fallback: Split by major paragraph breaks or use document structure\n",
        "    # Split by double newlines (common in PDFs)\n",
        "    paragraphs = raw_text.split('\\n\\n')\n",
        "    current_section_title = \"Document Content\"\n",
        "    current_content = []\n",
        "    \n",
        "    for para in paragraphs:\n",
        "        para_stripped = para.strip()\n",
        "        if not para_stripped:\n",
        "            continue\n",
        "        \n",
        "        # Check if paragraph looks like a header\n",
        "        if len(para_stripped) < 100 and para_stripped[0].isupper():\n",
        "            # Save previous section if it has content\n",
        "            if current_content:\n",
        "                sections_data.append((current_section_title, '\\n\\n'.join(current_content)))\n",
        "            current_section_title = para_stripped\n",
        "            current_content = []\n",
        "        else:\n",
        "            current_content.append(para_stripped)\n",
        "    \n",
        "    # Add final section\n",
        "    if current_content:\n",
        "        sections_data.append((current_section_title, '\\n\\n'.join(current_content)))\n",
        "\n",
        "# If still no sections, create one large section\n",
        "if not sections_data:\n",
        "    sections_data = [(\"Full Document\", raw_text)]\n",
        "\n",
        "print(f\"Extracted {len(sections_data)} content sections with titles.\")\n",
        "print(\"Section titles found:\")\n",
        "for title, _ in sections_data[:10]:  # Show first 10\n",
        "    print(f\"  - {title[:80]}\")\n",
        "\n",
        "# Initialize text splitter if not already defined\n",
        "if 'text_splitter' not in globals():\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "\n",
        "doc_chunks_with_metadata = []\n",
        "for section_title, content in sections_data:\n",
        "    # Skip sections with no content\n",
        "    if not content.strip():\n",
        "        continue\n",
        "\n",
        "    # Clean section title for metadata\n",
        "    clean_section_title = section_title.replace('\\n', ' ').strip()[:200]  # Limit length\n",
        "\n",
        "    # Get source file name from first document\n",
        "    source_file = source_documents[0].metadata.get('file_name', 'unknown') if source_documents else 'unknown'\n",
        "\n",
        "    section_chunks = text_splitter.split_text(content)\n",
        "    if not section_chunks:  # If content is too small to chunk\n",
        "        doc_chunks_with_metadata.append(\n",
        "            Document(\n",
        "                page_content=content.strip() or clean_section_title,\n",
        "                metadata={\n",
        "                    \"section\": clean_section_title,\n",
        "                    \"source_doc\": source_file,\n",
        "                    \"file_name\": source_file,\n",
        "                    \"id\": str(uuid.uuid4())\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        for chunk in section_chunks:\n",
        "            chunk_id = str(uuid.uuid4())\n",
        "            doc_chunks_with_metadata.append(\n",
        "                Document(\n",
        "                    page_content=chunk,\n",
        "                    metadata={\n",
        "                        \"section\": clean_section_title,\n",
        "                        \"source_doc\": source_file,\n",
        "                        \"file_name\": source_file,\n",
        "                        \"id\": chunk_id\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "\n",
        "print(f\"\\nCreated {len(doc_chunks_with_metadata)} chunks with section metadata.\")\n",
        "\n",
        "# Show sample chunks\n",
        "print(\"\\n--- Sample Chunks with Metadata ---\")\n",
        "for i, chunk in enumerate(doc_chunks_with_metadata[:3]):\n",
        "    print(f\"\\nChunk {i+1}:\")\n",
        "    print(f\"  Section: {chunk.metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"  Source: {chunk.metadata.get('file_name', 'Unknown')}\")\n",
        "    print(f\"  Content preview: {chunk.page_content[:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-3-retrieval-pro-adv",
      "metadata": {
        "id": "part3-3-retrieval-pro-adv"
      },
      "source": [
        "### 3.3. Component 2: The Multi-Stage, Adaptive Retrieval Funnel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-3-1-supervisor-pro",
      "metadata": {
        "id": "part3-3-1-supervisor-pro"
      },
      "source": [
        "#### 3.3.1. NEW: The Retrieval Supervisor Agent\n",
        "\n",
        "This is a new, crucial component for intelligent retrieval. Not all questions are created equal. Some benefit from semantic search (e.g., \"What are the company's feelings on climate change?\"), while others are better with keyword search (e.g., \"What was the revenue for the 'Compute & Networking' segment?\").\n",
        "\n",
        "The **Retrieval Supervisor** is a small LLM agent that acts as a router. For each `search_10k` step, it analyzes the sub-question and decides which retrieval strategy—`vector_search`, `keyword_search`, or `hybrid_search`—is most appropriate. This adds a layer of dynamic decision-making that optimizes the retrieval process for each specific query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "part3-3-1-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-3-1-code-pro",
        "outputId": "7392f14a-7bf6-437c-fc93-a9004bb84875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval Supervisor Agent created.\n",
            "--- Testing Retrieval Supervisor Agent ---\n",
            "Query: 'revenue growth for the Compute & Networking segment in fiscal year 2023'\n",
            "Decision: keyword_search, Justification: The query contains specific terms such as 'revenue growth', 'Compute & Networking segment', and 'fiscal year 2023', which suggests that the user is looking for precise data or reports related to these exact terms.\n",
            "Query: 'general sentiment about market competition and technological innovation'\n",
            "Decision: vector_search, Justification: The query is focused on general sentiment, which is conceptual and relates to opinions and trends in market competition and technological innovation. A vector search is best suited for capturing the nuances and semantic relationships in such abstract topics.\n"
          ]
        }
      ],
      "source": [
        "class RetrievalDecision(BaseModel):\n",
        "    strategy: Literal[\"vector_search\", \"keyword_search\", \"hybrid_search\"]\n",
        "    justification: str\n",
        "\n",
        "retrieval_supervisor_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a retrieval strategy expert. Based on the user's query, you must decide the best retrieval strategy.\\nYou have three options:\\n1. `vector_search`: Best for conceptual, semantic, or similarity-based queries.\\n2. `keyword_search`: Best for queries with specific, exact terms, names, or codes (e.g., 'Item 1A', 'Hopper architecture').\\n3. `hybrid_search`: A good default that combines both, but may be less precise than a targeted strategy.\"\"\"),\n",
        "    (\"human\", \"User Query: {sub_question}\")\n",
        "])\n",
        "\n",
        "# Assuming reasoning_llm is already defined as AzureChatOpenAI\n",
        "retrieval_supervisor_agent = retrieval_supervisor_prompt | reasoning_llm.with_structured_output(RetrievalDecision)\n",
        "print(\"Retrieval Supervisor Agent created.\")\n",
        "\n",
        "# Test the supervisor\n",
        "print(\"--- Testing Retrieval Supervisor Agent ---\")\n",
        "try:\n",
        "    query1 = \"revenue growth for the Compute & Networking segment in fiscal year 2023\"\n",
        "    decision1 = retrieval_supervisor_agent.invoke({\"sub_question\": query1})\n",
        "    print(f\"Query: '{query1}'\")\n",
        "    print(f\"Decision: {decision1.strategy}, Justification: {decision1.justification}\")\n",
        "\n",
        "    query2 = \"general sentiment about market competition and technological innovation\"\n",
        "    decision2 = retrieval_supervisor_agent.invoke({\"sub_question\": query2})\n",
        "    print(f\"Query: '{query2}'\")\n",
        "    print(f\"Decision: {decision2.strategy}, Justification: {decision2.justification}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during retrieval supervisor agent test: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-3-2-strategies-pro",
      "metadata": {
        "id": "part3-3-2-strategies-pro"
      },
      "source": [
        "#### 3.3.2. Implementing the Retrieval Strategies\n",
        "\n",
        "Now we build our advanced retriever. We create a new vector store with our metadata-rich chunks. We then implement three distinct search functions: pure vector search, pure keyword search (BM25), and a hybrid approach that fuses the results using Reciprocal Rank Fusion (RRF). Our `retrieval_node` in the graph will use the decision from the `RetrievalSupervisor` to call the appropriate function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "part3-3-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-3-1-code-pro-adv",
        "outputId": "57ceaaa0-97f8-49f5-cac4-d481f7d7035e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating advanced vector store with metadata...\n",
            "Advanced vector store created with 305 documents.\n",
            "Building BM25 index for keyword search...\n",
            "All retrieval strategy functions ready.\n",
            "\n",
            "--- Testing Keyword Search ---\n",
            "Query: green hydrogen cost benchmarks production India\n",
            "Found 5 documents.\n",
            "Top result section: India imported 90% of its panels from China before the implementation of safeguard\n",
            "Top result preview: duties. To promote production in India, the Indian government levied a safeguard tax....\n",
            "\n",
            "--- Testing Semantic Search ---\n",
            "Query: What are the key cost factors for green hydrogen production?\n",
            "Found 5 documents.\n",
            "Top result section: India has embarked on the world’s biggest renewable capacity growth journey. The\n",
            "Top result preview: government wants to boost the use of sustainable energy by investing heavily in green\n",
            "energies. Energy security, electricity scarcity, energy access, among other things, and\n",
            "climate change, played a r...\n",
            "\n",
            "--- Testing Hybrid Search ---\n",
            "Query: policy frameworks incentives green hydrogen India\n",
            "Found 5 documents.\n",
            "Top result section: their targets and achievements. The following conclusions were drawn:\n",
            "Top result preview: • The main focus is on clean and green energy, free from carbon emissions, which\n",
            "requires a centralized space or portal for policy planning, and its implementation...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure required packages are installed\n",
        "try:\n",
        "    from rank_bm25 import BM25Okapi\n",
        "except ImportError:\n",
        "    print(\"Installing rank-bm25 package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rank-bm25\"])\n",
        "    from rank_bm25 import BM25Okapi\n",
        "    print(\"✓ rank-bm25 installed successfully\")\n",
        "\n",
        "try:\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "except ImportError:\n",
        "    print(\"Installing faiss-cpu...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"faiss-cpu\"])\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "    print(\"✓ faiss-cpu installed successfully\")\n",
        "\n",
        "print(\"Creating advanced vector store with metadata...\")\n",
        "\n",
        "# Ensure embedding_function is available\n",
        "if 'embedding_function' not in globals():\n",
        "    raise ValueError(\"embedding_function not found. Please run the vector store creation cell first.\")\n",
        "\n",
        "# Ensure doc_chunks_with_metadata is available\n",
        "if 'doc_chunks_with_metadata' not in globals():\n",
        "    raise ValueError(\"doc_chunks_with_metadata not found. Please run the document processing cell first.\")\n",
        "\n",
        "# Use FAISS instead of ChromaDB\n",
        "advanced_vector_store = FAISS.from_documents(\n",
        "    documents=doc_chunks_with_metadata,\n",
        "    embedding=embedding_function\n",
        ")\n",
        "print(f\"Advanced vector store created with {len(doc_chunks_with_metadata)} documents.\")\n",
        "\n",
        "print(\"Building BM25 index for keyword search...\")\n",
        "tokenized_corpus = [doc.page_content.split(\" \") for doc in doc_chunks_with_metadata]\n",
        "doc_ids_list = [doc.metadata[\"id\"] for doc in doc_chunks_with_metadata]\n",
        "doc_map = {doc.metadata[\"id\"]: doc for doc in doc_chunks_with_metadata}\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "def vector_search_only(query: str, section_filter: str = None, k: int = 10):\n",
        "    \"\"\"Semantic search using FAISS with optional section filtering\"\"\"\n",
        "    if section_filter and \"Unknown\" not in section_filter:\n",
        "        # Filter documents by section before searching\n",
        "        filtered_docs = [doc for doc in doc_chunks_with_metadata \n",
        "                        if doc.metadata.get(\"section\", \"\") == section_filter]\n",
        "        if filtered_docs:\n",
        "            # Create temporary vector store for filtered docs\n",
        "            temp_store = FAISS.from_documents(filtered_docs, embedding=embedding_function)\n",
        "            return temp_store.similarity_search(query, k=k)\n",
        "    \n",
        "    return advanced_vector_store.similarity_search(query, k=k)\n",
        "\n",
        "def bm25_search_only(query: str, k: int = 10):\n",
        "    \"\"\"Keyword-based search using BM25\"\"\"\n",
        "    tokenized_query = query.split(\" \")\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    top_k_indices = np.argsort(bm25_scores)[::-1][:k]\n",
        "    return [doc_map[doc_ids_list[i]] for i in top_k_indices]\n",
        "\n",
        "def hybrid_search(query: str, section_filter: str = None, k: int = 10):\n",
        "    \"\"\"Combines BM25 keyword search and semantic vector search using Reciprocal Rank Fusion\"\"\"\n",
        "    # 1. Keyword Search (BM25)\n",
        "    bm25_docs = bm25_search_only(query, k=k)\n",
        "\n",
        "    # 2. Semantic Search (with metadata filtering)\n",
        "    semantic_docs = vector_search_only(query, section_filter=section_filter, k=k)\n",
        "\n",
        "    # 3. Reciprocal Rank Fusion (RRF)\n",
        "    all_docs = {doc.metadata[\"id\"]: doc for doc in bm25_docs + semantic_docs}.values()\n",
        "    ranked_lists = [[doc.metadata[\"id\"] for doc in bm25_docs], [doc.metadata[\"id\"] for doc in semantic_docs]]\n",
        "\n",
        "    rrf_scores = {}\n",
        "    for doc_list in ranked_lists:\n",
        "        for i, doc_id in enumerate(doc_list):\n",
        "            if doc_id not in rrf_scores:\n",
        "                rrf_scores[doc_id] = 0\n",
        "            rrf_scores[doc_id] += 1 / (i + 61)  # RRF rank constant k = 60\n",
        "\n",
        "    sorted_doc_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)\n",
        "    final_docs = [doc_map[doc_id] for doc_id in sorted_doc_ids[:k]]\n",
        "    return final_docs\n",
        "\n",
        "print(\"All retrieval strategy functions ready.\")\n",
        "\n",
        "# Test Keyword Search with green hydrogen relevant query\n",
        "print(\"\\n--- Testing Keyword Search ---\")\n",
        "test_query = \"green hydrogen cost benchmarks production India\"\n",
        "test_results = bm25_search_only(test_query, k=5)\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"Found {len(test_results)} documents.\")\n",
        "if test_results:\n",
        "    print(f\"Top result section: {test_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {test_results[0].page_content[:200]}...\")\n",
        "\n",
        "# Test Semantic Search\n",
        "print(\"\\n--- Testing Semantic Search ---\")\n",
        "test_query_semantic = \"What are the key cost factors for green hydrogen production?\"\n",
        "semantic_results = vector_search_only(test_query_semantic, k=5)\n",
        "print(f\"Query: {test_query_semantic}\")\n",
        "print(f\"Found {len(semantic_results)} documents.\")\n",
        "if semantic_results:\n",
        "    print(f\"Top result section: {semantic_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {semantic_results[0].page_content[:200]}...\")\n",
        "\n",
        "# Test Hybrid Search\n",
        "print(\"\\n--- Testing Hybrid Search ---\")\n",
        "test_query_hybrid = \"policy frameworks incentives green hydrogen India\"\n",
        "hybrid_results = hybrid_search(test_query_hybrid, k=5)\n",
        "print(f\"Query: {test_query_hybrid}\")\n",
        "print(f\"Found {len(hybrid_results)} documents.\")\n",
        "if hybrid_results:\n",
        "    print(f\"Top result section: {hybrid_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {hybrid_results[0].page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-3-3-reranker-pro",
      "metadata": {
        "id": "part3-3-3-reranker-pro"
      },
      "source": [
        "#### 3.3.3. Stage 2 (High Precision): Cross-Encoder Reranker.\n",
        "\n",
        "After retrieving a broad set of `k` documents, we use a more computationally expensive but far more accurate **Cross-Encoder** model. Unlike embedding models (bi-encoders) that create vectors independently, a cross-encoder processes the query and each document *together*, yielding a much more nuanced relevance score. This allows us to re-rank the `k` candidates and select the top `n` with high confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "part3-3-2-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "30271ed7d4cb4c8784e4a21e8501ca8e",
            "fa38683265344c33833bed6a5b5b74ec",
            "820d45c64aef405e877f84710fff37d3",
            "c934d35cc81041de9de8294aedaef29e",
            "b74af6f60e374e61a1205aa306954b5f",
            "66316808d94f45adb8842f20b2555c3f",
            "18d761044ac347b7910d99da20a18380",
            "b18fa14e16cc43b683412f7d789e490d",
            "5dacc5ca9dc145a59d7b28ab1ced3943",
            "71726d43b8d24e3494ade9f096510a2a",
            "58de3427f73a4cadb0a990c1f4586f51",
            "d79e2f86d08846a08c0e2d9a44915777",
            "129811a2736c473f8f5792614e2a5eb3",
            "7e103ab49a904c09b582f887d1deee07",
            "e51f5537759a44db9cc15ce9ff05a3cd",
            "5e82dd89cff346d2ba16ee91e8cf71e2",
            "a5e226c5557b4fa1bbedd563df2edbcc",
            "c781a0c2ec524fd897f24c336bcb8bfb",
            "9528ef2fa06041a78db2dfb43db053ab",
            "38da0df867994120b261b11b49edeeb9",
            "26099d0292d640539be65aa77fcb2321",
            "ad1aa52287854440a527c6bca383b311",
            "65c033f377714e5a81a8178b4121f9dc",
            "669e42203560435db2962790387673f6",
            "df98353095ae4e2295ef4cc5ad9253a5",
            "7120dba3bbde40359702841bb0e30059",
            "024a9c42d31347c9919f3f482c24e368",
            "43e725a6640e4ad69da5786f4a50cf39",
            "d187c12c60224281809fc378c55b2e2e",
            "703a94e7e3644809a5a849346be762eb",
            "2a6edb2dee4a4fd094c39841dc64a095",
            "780d4e532e4d40faa2288a36fba29a35",
            "c2eb23b29c1b466588c68ac38b1d5a6a",
            "fe9f24d8462a4a189878c526ebaf8e89",
            "dfb12ed69cc04b3abeff03df2efa2d8e",
            "9c33feb267ae454791c2d3a60657e304",
            "7d7afca7e7334a65ad66c60340a06216",
            "439df160977c4376a4e7b9008f4e5c45",
            "56abcbeef18d4163b41b5cd774798a29",
            "115e7789a1c04c388eed27ad6431afe3",
            "d1df53c2d1944f8db242e04b81b4a763",
            "69527922f7ef4b26929dd2b58ede351c",
            "5e0f038825184ddf8791da9dd55d26b1",
            "bb820426ae454a6aa22de5ddb2decb66",
            "d95f1dbec51543b4a27c610fb5853d9c",
            "c008babef3484f0fa9a682f514c5166d",
            "3f8c1329c9f74767b946b942e3254392",
            "3778dbc947094e1181554937ebd8c62e",
            "134ea9e644d94c9e8cd1d57333852923",
            "a7cd00e35e23451796d7f4be353ab714",
            "9b7b3a7f4cbb4dde950f3bc7a73e5cf6",
            "d56d8ca84d9e439d99e7cd504faf49a8",
            "fe420ced4fcd49fba88914134dca37f1",
            "a9e3c21573a84343ac6ecb9f1deda914",
            "cd671fd928d24292bcc0091929796d35",
            "2fa03023ccb34a08b7c5e8610cfda8dd",
            "63496ad0475d47ce804c32e9d59ac97e",
            "a06f2c0a708748b5a15c8d8a387cc1cd",
            "42c8e92da89548088144506467b64a92",
            "fa254953ce2b44e1b3b4dc54725099d6",
            "175d85418f6c46f8aa10408e78eff346",
            "ba655a3ab2fa4f35ae0988def09a85e0",
            "bcaf2c0464b2448f9f0883bd32f19741",
            "5d2534658e844d26becdc77b98599cc9",
            "bfbd84082ea840d1ad83270601c9022e",
            "e11661d1dce24af695fb8c92a91de7e0",
            "39d23ad664db46dd8e0a7f36385bda3c",
            "5856b69826b9450d97a1a5fb56ac7a35",
            "c5b916b553664de2906e90bc9a303dc1",
            "9c562baea6b0417d8f7b25bc351ede8f",
            "d31fcf233c0c4f9db432d3b1a1173f7f",
            "a2be5c93c2a742eaa89c621dbcb33ea0",
            "d982a0ef48134faa9a2e6ebe01ce9f50",
            "4eb3c019e2f746daac8bc4e5164da4fb",
            "cf0e108f46144e109197337986889467",
            "e21e2030a0a0449abcb0a2f1fbd0e271",
            "4be84eec4e074e2692d9973bf035f983"
          ]
        },
        "id": "part3-3-2-code-pro-adv",
        "outputId": "047880b6-6c10-4076-e9e4-a15d76fa0421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing CrossEncoder reranker...\n",
            "Cross-Encoder ready.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "print(\"Initializing CrossEncoder reranker...\")\n",
        "reranker = CrossEncoder(config[\"reranker_model\"])\n",
        "\n",
        "def rerank_documents_function(query: str, documents: List[Document]) -> List[Document]:\n",
        "    if not documents: return []\n",
        "    pairs = [(query, doc.page_content) for doc in documents]\n",
        "    scores = reranker.predict(pairs)\n",
        "\n",
        "    # Combine documents with their scores and sort\n",
        "    doc_scores = list(zip(documents, scores))\n",
        "    doc_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top N documents\n",
        "    reranked_docs = [doc for doc, score in doc_scores[:config[\"top_n_rerank\"]]]\n",
        "    return reranked_docs\n",
        "\n",
        "print(\"Cross-Encoder ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-3-4-distill-pro",
      "metadata": {
        "id": "part3-3-4-distill-pro"
      },
      "source": [
        "#### 3.3.4. Stage 3 (Contextual Distillation): Implementing logic to synthesize a concise context.\n",
        "\n",
        "The final step in our retrieval funnel is to distill the top `n` highly relevant chunks into a single, clean paragraph of context. This removes redundancy and presents the information to the downstream agents in a clean, easy-to-process format. We create a dedicated 'Distiller Agent' for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "part3-3-3-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-3-3-code-pro-adv",
        "outputId": "93d728a5-1137-41a1-a344-a061fad764a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contextual Distiller Agent created.\n"
          ]
        }
      ],
      "source": [
        "distiller_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful assistant. Your task is to synthesize the following retrieved document snippets into a single, concise paragraph.\\nThe goal is to provide a clear and coherent context that directly answers the question: '{question}'.\\nFocus on removing redundant information and organizing the content logically. Answer only with the synthesized context.\"\"\"),\n",
        "    (\"human\", \"Retrieved Documents:\\n{context}\")\n",
        "])\n",
        "\n",
        "# Assuming reasoning_llm is already defined as AzureChatOpenAI\n",
        "distiller_agent = distiller_prompt | reasoning_llm | StrOutputParser()\n",
        "print(\"Contextual Distiller Agent created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-4-tool-pro",
      "metadata": {
        "id": "part3-4-tool-pro"
      },
      "source": [
        "### 3.4. Component 3: Tool Augmentation with Web Search\n",
        "\n",
        "To answer questions about recent events or competitors, our agent needs to break out of its static knowledge base. We equip it with a web search tool using the Tavily Search API. The `planner_agent` will decide when to invoke this tool. The results from the web search will be formatted into LangChain `Document` objects, allowing them to be processed by the same reranking and compression pipeline as the documents retrieved from our vector store. This ensures a seamless integration of internal and external knowledge sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "part3-4-code-pro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-4-code-pro",
        "outputId": "478abcb5-4795-47c5-bc43-476125452989"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w5/k1crj13j33n3_y1sj0nlz5yw0000gn/T/ipykernel_7519/126255760.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  web_search_tool = TavilySearchResults(k=3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Web search tool (Tavily) initialized.\n",
            "--- Testing Web Search Tool ---\n",
            "Found 5 results for query: 'AMD AI chip strategy 2024'\n",
            "Top result snippet: 2024 for its AI chips. [...] To meet the growing demand for AI chips, AMD has been actively working on expanding its production capacity. The company aims to increase its market share in the AI chip market, which is projected to reach USD 45 billion ...\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)\n",
        "\n",
        "def web_search_function(query: str) -> List[Document]:\n",
        "    results = web_search_tool.invoke({\"query\": query})\n",
        "    return [Document(page_content=res[\"content\"], metadata={\"source\": res[\"url\"]}) for res in results]\n",
        "\n",
        "print(\"Web search tool (Tavily) initialized.\")\n",
        "\n",
        "# Test the web search\n",
        "print(\"--- Testing Web Search Tool ---\")\n",
        "test_query_web = \"AMD AI chip strategy 2024\"\n",
        "test_results_web = web_search_function(test_query_web)\n",
        "print(f\"Found {len(test_results_web)} results for query: '{test_query_web}'\")\n",
        "if test_results_web:\n",
        "    print(f\"Top result snippet: {test_results_web[0].page_content[:250]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-5-critique-pro",
      "metadata": {
        "id": "part3-5-critique-pro"
      },
      "source": [
        "### 3.5. Component 4: The Self-Critique and Control Flow Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-5-1-reflect-pro",
      "metadata": {
        "id": "part3-5-1-reflect-pro"
      },
      "source": [
        "#### 3.5.1. The \"Update and Reflect\" Step: An agent that synthesizes new findings into the `RAGState`'s reasoning history.\n",
        "\n",
        "After each retrieval loop, the agent needs to integrate its new knowledge. The 'Reflection Agent' takes the distilled context from the current step and creates a concise summary. This summary is then appended to the `past_steps` list in our `RAGState`, forming a cumulative log of the agent's research journey."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "part3-4-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-4-1-code-pro-adv",
        "outputId": "179bc216-e687-4863-f1b9-2fe6591053db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reflection Agent created.\n"
          ]
        }
      ],
      "source": [
        "reflection_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a research assistant. Based on the retrieved context for the current sub-question, write a concise, one-sentence summary of the key findings.\\nThis summary will be added to our research history. Be factual and to the point.\"\"\"),\n",
        "    (\"human\", \"Current sub-question: {sub_question}\\n\\nDistilled context:\\n{context}\")\n",
        "])\n",
        "# Assuming reasoning_llm is already defined as AzureChatOpenAI\n",
        "reflection_agent = reflection_prompt | reasoning_llm | StrOutputParser()\n",
        "print(\"Reflection Agent created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-5-2-policy-pro",
      "metadata": {
        "id": "part3-5-2-policy-pro"
      },
      "source": [
        "#### 3.5.2. Policy Implementation (LLM-as-a-Judge): Prompting an LLM to inspect the current state and decide the next action.\n",
        "\n",
        "This is the cognitive core of our agent's autonomy. The 'Policy Agent' acts as a supervisor. After each reflection step, it examines the *entire* research history (`past_steps`) in relation to the original question and the plan. It then makes a structured decision: `CONTINUE_PLAN` if more information is needed, or `FINISH` if the question has been comprehensively answered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "part3-4-2-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part3-4-2-code-pro-adv",
        "outputId": "8375b57d-eaaf-4318-b94d-495d1c2dac75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy Agent created.\n",
            "--- Testing Policy Agent (Incomplete State) ---\n",
            "Decision: CONTINUE_PLAN\n",
            "Justification: While initial cost benchmarks for green hydrogen production in India have been identified, further information is needed on performance metrics, a comparative analysis with conventional hydrogen production methods, and the main factors affecting cost competitiveness to comprehensively answer the original question.\n",
            "\n",
            "--- Testing Policy Agent (Complete State) ---\n",
            "Decision: FINISH\n",
            "Justification: The research history provides comprehensive information on key cost benchmarks, performance metrics, comparative analysis with conventional hydrogen production, and the main factors affecting cost competitiveness for green hydrogen production in India. All necessary aspects of the original question have been addressed.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "class Decision(BaseModel):\n",
        "    next_action: Literal[\"CONTINUE_PLAN\", \"FINISH\"]\n",
        "    justification: str\n",
        "\n",
        "policy_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a master strategist specializing in energy sector research and analysis. Your role is to analyze the research progress and decide the next action.\n",
        "\n",
        "You have the original question, the initial plan, and a log of completed steps with their summaries.\n",
        "\n",
        "Your decision criteria:\n",
        "- If the collected information in the Research History is sufficient to comprehensively answer the Original Question about green hydrogen, energy transition, policy frameworks, cost benchmarks, or related energy sector topics, decide to FINISH.\n",
        "- Otherwise, if the plan is not yet complete or critical information is still missing, decide to CONTINUE_PLAN.\n",
        "\n",
        "Consider whether you have:\n",
        "- Sufficient data points, metrics, or benchmarks\n",
        "- Complete policy framework information\n",
        "- Adequate comparative analysis (if required)\n",
        "- All necessary technical specifications or cost factors\n",
        "- Comprehensive coverage of challenges and opportunities (if asked)\"\"\"),\n",
        "    (\"human\", \"Original Question: {question}\\n\\nInitial Plan:\\n{plan}\\n\\nResearch History (Completed Steps):\\n{history}\")\n",
        "])\n",
        "\n",
        "# Ensure reasoning_llm is defined (should be from previous cell)\n",
        "if 'reasoning_llm' not in locals():\n",
        "    from langchain_openai import AzureChatOpenAI\n",
        "    import os\n",
        "    reasoning_llm = AzureChatOpenAI(\n",
        "        azure_deployment=config[\"azure_deployment_name\"],\n",
        "        azure_endpoint=config[\"azure_endpoint\"],\n",
        "        api_version=config[\"azure_api_version\"],\n",
        "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "policy_agent = policy_prompt | reasoning_llm.with_structured_output(Decision)\n",
        "print(\"Policy Agent created.\")\n",
        "\n",
        "# Test the policy agent with different states\n",
        "print(\"--- Testing Policy Agent (Incomplete State) ---\")\n",
        "try:\n",
        "    if 'test_plan' in locals() and test_plan:\n",
        "        plan_str = json.dumps([s.model_dump() for s in test_plan.steps], indent=2)\n",
        "        \n",
        "        # Updated test history for green hydrogen document\n",
        "        incomplete_history = \"\"\"Step 1 Summary: The green hydrogen benchmarking document identifies key cost factors including electrolyzer costs, renewable energy prices, and infrastructure requirements. Initial cost benchmarks show green hydrogen production costs ranging from $3-7 per kg depending on renewable energy source and scale.\"\"\"\n",
        "        \n",
        "        # Use the complex_query_adv if available, otherwise use a default query\n",
        "        query_to_use = complex_query_adv if 'complex_query_adv' in globals() else \"What are the key cost benchmarks for green hydrogen production in India?\"\n",
        "        \n",
        "        decision1 = policy_agent.invoke({\n",
        "            \"question\": query_to_use, \n",
        "            \"plan\": plan_str, \n",
        "            \"history\": incomplete_history\n",
        "        })\n",
        "        print(f\"Decision: {decision1.next_action}\")\n",
        "        print(f\"Justification: {decision1.justification}\")\n",
        "\n",
        "        # Complete history with more comprehensive information\n",
        "        complete_history = incomplete_history + \"\"\"\n",
        "Step 2 Summary: Policy frameworks in India include the National Green Hydrogen Mission with targets of 5 million tonnes annual production by 2030, production-linked incentives, and regulatory support for electrolyzer manufacturing.\n",
        "Step 3 Summary: Comparative analysis shows India's green hydrogen costs are competitive with international benchmarks, with potential for further reduction through scale, technology improvements, and renewable energy cost reductions.\n",
        "Step 4 Summary: Key challenges include high initial capital costs, intermittent renewable energy supply, and infrastructure development needs. Opportunities include abundant renewable resources, government support, and growing market demand.\"\"\"\n",
        "        \n",
        "        decision2 = policy_agent.invoke({\n",
        "            \"question\": query_to_use, \n",
        "            \"plan\": plan_str, \n",
        "            \"history\": complete_history\n",
        "        })\n",
        "        print(\"\\n--- Testing Policy Agent (Complete State) ---\")\n",
        "        print(f\"Decision: {decision2.next_action}\")\n",
        "        print(f\"Justification: {decision2.justification}\")\n",
        "    else:\n",
        "        print(\"test_plan not defined. Running sample test with mock data...\")\n",
        "        \n",
        "        # Sample test without test_plan\n",
        "        sample_plan = json.dumps([\n",
        "            {\"sub_question\": \"What are the cost benchmarks for green hydrogen?\", \"tool\": \"search_documents\"},\n",
        "            {\"sub_question\": \"What policy frameworks support green hydrogen in India?\", \"tool\": \"search_documents\"},\n",
        "            {\"sub_question\": \"How do costs compare to conventional hydrogen?\", \"tool\": \"search_documents\"}\n",
        "        ], indent=2)\n",
        "        \n",
        "        incomplete_history = \"Step 1 Summary: Cost benchmarks identified for green hydrogen production.\"\n",
        "        complete_history = incomplete_history + \"\\nStep 2 Summary: Policy frameworks documented.\\nStep 3 Summary: Cost comparison completed.\"\n",
        "        \n",
        "        sample_query = \"What are the key cost benchmarks and policy frameworks for green hydrogen in India?\"\n",
        "        \n",
        "        decision1 = policy_agent.invoke({\n",
        "            \"question\": sample_query,\n",
        "            \"plan\": sample_plan,\n",
        "            \"history\": incomplete_history\n",
        "        })\n",
        "        print(f\"Decision (Incomplete): {decision1.next_action}\")\n",
        "        print(f\"Justification: {decision1.justification}\")\n",
        "        \n",
        "        decision2 = policy_agent.invoke({\n",
        "            \"question\": sample_query,\n",
        "            \"plan\": sample_plan,\n",
        "            \"history\": complete_history\n",
        "        })\n",
        "        print(f\"\\nDecision (Complete): {decision2.next_action}\")\n",
        "        print(f\"Justification: {decision2.justification}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error during policy agent test: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part3-5-3-stopping-pro",
      "metadata": {
        "id": "part3-5-3-stopping-pro"
      },
      "source": [
        "#### 3.5.3. Defining Robust Stopping Criteria\n",
        "\n",
        "Our system needs clear and robust conditions to stop the reasoning loop. We have three such criteria:\n",
        "1.  **Policy Decision:** The primary stopping condition is when the `policy_agent` confidently decides to `FINISH`.\n",
        "2.  **Plan Completion:** If the agent has executed every step in its plan, it will naturally conclude its work.\n",
        "3.  **Max Iterations:** As a safeguard against infinite loops or runaway processes, we enforce a hard limit (`max_reasoning_iterations` from our config) on the number of research cycles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part4-intro-graph-pro",
      "metadata": {
        "id": "part4-intro-graph-pro"
      },
      "source": [
        "## Part 4: Assembly with LangGraph - Orchestrating the Reasoning Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part4-1-nodes-pro-adv",
      "metadata": {
        "id": "part4-1-nodes-pro-adv"
      },
      "source": [
        "### 4.1. Code Dependency: Defining the Graph Nodes\n",
        "\n",
        "Now, we translate our conceptual components into concrete graph nodes. Each node is a Python function that accepts the `RAGState` dictionary, performs its designated task, and returns a dictionary containing the state updates. We add a new `web_search_node` to handle the external search tool, and we modify the `retrieval_node` to incorporate the adaptive strategy chosen by our new Supervisor agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "part4-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part4-1-code-pro-adv",
        "outputId": "d60215cc-e296-43c0-cc55-c0da45f9d463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All graph nodes defined successfully.\n"
          ]
        }
      ],
      "source": [
        "def get_past_context_str(past_steps: List[PastStep]) -> str:\n",
        "    return \"\\n\\n\".join([f\"Step {s['step_index']}: {s['sub_question']}\\nSummary: {s['summary']}\" for s in past_steps])\n",
        "\n",
        "def plan_node(state: RAGState) -> Dict:\n",
        "    console.print(\"--- 🧠: Generating Plan ---\")\n",
        "    plan = planner_agent.invoke({\"question\": state[\"original_question\"]})\n",
        "    rprint(plan)\n",
        "    return {\"plan\": plan, \"current_step_index\": 0, \"past_steps\": []}\n",
        "\n",
        "def retrieval_node(state: RAGState) -> Dict:\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    console.print(f\"--- 🔍: Retrieving from 10-K (Step {current_step_index + 1}: {current_step.sub_question}) ---\")\n",
        "    past_context = get_past_context_str(state['past_steps'])\n",
        "    rewritten_query = query_rewriter_agent.invoke({\n",
        "        \"sub_question\": current_step.sub_question,\n",
        "        \"keywords\": current_step.keywords,\n",
        "        \"past_context\": past_context\n",
        "    })\n",
        "    console.print(f\"  Rewritten Query: {rewritten_query}\")\n",
        "\n",
        "    # NEW: Adaptive Retrieval Strategy\n",
        "    retrieval_decision = retrieval_supervisor_agent.invoke({\"sub_question\": rewritten_query})\n",
        "    console.print(f\"  Supervisor Decision: Use `{retrieval_decision.strategy}`. Justification: {retrieval_decision.justification}\")\n",
        "\n",
        "    if retrieval_decision.strategy == 'vector_search':\n",
        "        retrieved_docs = vector_search_only(rewritten_query, section_filter=current_step.document_section, k=config['top_k_retrieval'])\n",
        "    elif retrieval_decision.strategy == 'keyword_search':\n",
        "        retrieved_docs = bm25_search_only(rewritten_query, k=config['top_k_retrieval'])\n",
        "    else: # hybrid_search\n",
        "        retrieved_docs = hybrid_search(rewritten_query, section_filter=current_step.document_section, k=config['top_k_retrieval'])\n",
        "\n",
        "    return {\"retrieved_docs\": retrieved_docs}\n",
        "\n",
        "def web_search_node(state: RAGState) -> Dict:\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    console.print(f\"--- 🌐: Searching Web (Step {current_step_index + 1}: {current_step.sub_question}) ---\")\n",
        "    past_context = get_past_context_str(state['past_steps'])\n",
        "    rewritten_query = query_rewriter_agent.invoke({\n",
        "        \"sub_question\": current_step.sub_question,\n",
        "        \"keywords\": current_step.keywords,\n",
        "        \"past_context\": past_context\n",
        "    })\n",
        "    console.print(f\"  Rewritten Query: {rewritten_query}\")\n",
        "    retrieved_docs = web_search_function(rewritten_query)\n",
        "    return {\"retrieved_docs\": retrieved_docs}\n",
        "\n",
        "def rerank_node(state: RAGState) -> Dict:\n",
        "    console.print(\"--- 🎯: Reranking Documents ---\")\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    reranked_docs = rerank_documents_function(current_step.sub_question, state[\"retrieved_docs\"])\n",
        "    console.print(f\"  Reranked to top {len(reranked_docs)} documents.\")\n",
        "    return {\"reranked_docs\": reranked_docs}\n",
        "\n",
        "def compression_node(state: RAGState) -> Dict:\n",
        "    console.print(\"--- ✂️: Distilling Context ---\")\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    context = format_docs(state[\"reranked_docs\"])\n",
        "    synthesized_context = distiller_agent.invoke({\"question\": current_step.sub_question, \"context\": context})\n",
        "    console.print(f\"  Distilled Context Snippet: {synthesized_context[:200]}...\")\n",
        "    return {\"synthesized_context\": synthesized_context}\n",
        "\n",
        "def reflection_node(state: RAGState) -> Dict:\n",
        "    console.print(\"--- 🤔: Reflecting on Findings ---\")\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    summary = reflection_agent.invoke({\"sub_question\": current_step.sub_question, \"context\": state['synthesized_context']})\n",
        "    console.print(f\"  Summary: {summary}\")\n",
        "    new_past_step = {\n",
        "        \"step_index\": current_step_index + 1,\n",
        "        \"sub_question\": current_step.sub_question,\n",
        "        \"retrieved_docs\": state['reranked_docs'],\n",
        "        \"summary\": summary\n",
        "    }\n",
        "    return {\"past_steps\": state[\"past_steps\"] + [new_past_step], \"current_step_index\": current_step_index + 1}\n",
        "\n",
        "def final_answer_node(state: RAGState) -> Dict:\n",
        "    console.print(\"--- ✅: Generating Final Answer with Citations ---\")\n",
        "    # Create a consolidated context with metadata for citation\n",
        "    final_context = \"\"\n",
        "    for i, step in enumerate(state['past_steps']):\n",
        "        final_context += f\"\\n--- Findings from Research Step {i+1} ---\\n\"\n",
        "        for doc in step['retrieved_docs']:\n",
        "            source = doc.metadata.get('section') or doc.metadata.get('source')\n",
        "            final_context += f\"Source: {source}\\nContent: {doc.page_content}\\n\\n\"\n",
        "\n",
        "    final_answer_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are an expert financial analyst. Synthesize the research findings from internal documents and web searches into a comprehensive, multi-paragraph answer for the user's original question.\\nYour answer must be grounded in the provided context. At the end of any sentence that relies on specific information, you MUST add a citation. For 10-K documents, use [Source: <section title>]. For web results, use [Source: <URL>].\"\"\"),\n",
        "        (\"human\", \"Original Question: {question}\\n\\nResearch History and Context:\\n{context}\")\n",
        "    ])\n",
        "\n",
        "    # Correct way to invoke the LLM with a prompt template and ensure string output\n",
        "    final_answer_chain = final_answer_prompt | reasoning_llm | StrOutputParser() # Added StrOutputParser\n",
        "    final_answer = final_answer_chain.invoke({\"question\": state['original_question'], \"context\": final_context})\n",
        "    return {\"final_answer\": final_answer}\n",
        "\n",
        "print(\"All graph nodes defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part4-2-edges-pro-adv",
      "metadata": {
        "id": "part4-2-edges-pro-adv"
      },
      "source": [
        "### 4.2. Code Dependency: Defining the Conditional Edges - Implementing the Self-Critique Policy Logic\n",
        "\n",
        "We now define the logic that controls the flow of our graph. We add a `route_by_tool` function that checks the plan and directs the agent to either the `retrieval_node` or the `web_search_node`. The `should_continue_node` remains the primary controller for the main reasoning loop, implementing our stopping criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "part4-2-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part4-2-code-pro-adv",
        "outputId": "97c45dbc-f5e8-4b72-8e2d-e632e42de5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "route_by_tool function updated to map 'search_10k' -> 'search_documents'\n",
            "Conditional edge logic functions defined.\n"
          ]
        }
      ],
      "source": [
        "# Update route_by_tool to map old tool names to new ones\n",
        "def route_by_tool(state: RAGState) -> str:\n",
        "    current_step_index = state.get(\"current_step_index\", 0)\n",
        "    if current_step_index >= len(state[\"plan\"].steps):\n",
        "        return \"search_web\"  # Default if out of bounds\n",
        "    \n",
        "    current_step = state[\"plan\"].steps[current_step_index]\n",
        "    tool = current_step.tool\n",
        "    \n",
        "    # Map old tool names to new ones for compatibility\n",
        "    if tool == \"search_10k\":\n",
        "        return \"search_documents\"\n",
        "    elif tool == \"search_documents\":\n",
        "        return \"search_documents\"\n",
        "    elif tool == \"search_web\":\n",
        "        return \"search_web\"\n",
        "    else:\n",
        "        # Default to document search for unknown tools\n",
        "        return \"search_documents\"\n",
        "\n",
        "# Ensure the graph uses the updated routing\n",
        "# Rebuild the graph with correct edges if needed\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# If graph is already defined, we just need to ensure route_by_tool is updated\n",
        "# The graph edges should already be correct from the previous cell\n",
        "\n",
        "print(\"route_by_tool function updated to map 'search_10k' -> 'search_documents'\")\n",
        "\n",
        "def should_continue_node(state: RAGState) -> str:\n",
        "    console.print(\"--- 🚦: Evaluating Policy ---\")\n",
        "    current_step_index = state[\"current_step_index\"]\n",
        "\n",
        "    if current_step_index >= len(state[\"plan\"].steps):\n",
        "        console.print(\"  -> Plan complete. Finishing.\")\n",
        "        return \"finish\"\n",
        "\n",
        "    if current_step_index >= config[\"max_reasoning_iterations\"]:\n",
        "        console.print(\"  -> Max iterations reached. Finishing.\")\n",
        "        return \"finish\"\n",
        "\n",
        "    # Check if the last retrieval step failed to find documents\n",
        "    if not state[\"reranked_docs\"]:\n",
        "        console.print(\"  -> Retrieval failed for the last step. Continuing with next step in plan.\")\n",
        "        return \"continue\"\n",
        "\n",
        "    history = get_past_context_str(state['past_steps'])\n",
        "    plan_str = json.dumps([s.model_dump() for s in state['plan'].steps]) # Changed .dict() to .model_dump()\n",
        "    decision = policy_agent.invoke({\"question\": state[\"original_question\"], \"plan\": plan_str, \"history\": history})\n",
        "    console.print(f\"  -> Decision: {decision.next_action} | Justification: {decision.justification}\")\n",
        "\n",
        "    if decision.next_action == \"FINISH\":\n",
        "        return \"finish\"\n",
        "    else: # CONTINUE_PLAN\n",
        "        return \"continue\"\n",
        "\n",
        "print(\"Conditional edge logic functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part4-3-build-pro-adv",
      "metadata": {
        "id": "part4-3-build-pro-adv"
      },
      "source": [
        "### 4.3. Building the `StateGraph`: Wiring the Deep Thinking RAG Machine\n",
        "\n",
        "Now we instantiate the `StateGraph` and assemble our more advanced cognitive architecture. The key change is adding a conditional entry point after the `plan` node. This `route_by_tool` edge will direct the agent to the correct tool for the current step. After each tool execution and subsequent processing, the graph flows to the `reflect` node, which then loops back to the tool router for the next step in the plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "part4-3-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part4-3-code-pro-adv",
        "outputId": "842594ce-c9ef-4ae3-a83f-98311e26b9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StateGraph constructed successfully.\n",
            "Graph nodes: ['plan', 'retrieve_documents', 'retrieve_web', 'rerank', 'compress', 'reflect', 'generate_final_answer', 'choose_next_tool']\n"
          ]
        }
      ],
      "source": [
        "# Ensure langgraph is installed\n",
        "try:\n",
        "    from langgraph.graph import StateGraph, END\n",
        "except ImportError:\n",
        "    print(\"Installing langgraph package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langgraph\"])\n",
        "    from langgraph.graph import StateGraph, END\n",
        "    print(\"✓ langgraph installed successfully\")\n",
        "\n",
        "# Ensure RAGState is defined (should be from previous cells)\n",
        "if 'RAGState' not in globals():\n",
        "    from typing import TypedDict, List, Annotated\n",
        "    from langchain_core.documents import Document\n",
        "    \n",
        "    class RAGState(TypedDict):\n",
        "        question: str\n",
        "        plan: str\n",
        "        retrieved_docs: List[Document]\n",
        "        web_results: List[Document]\n",
        "        reranked_docs: List[Document]\n",
        "        compressed_context: str\n",
        "        research_history: str\n",
        "        final_answer: str\n",
        "        current_step: int\n",
        "        max_steps: int\n",
        "\n",
        "# Ensure all node functions are defined\n",
        "# These should be defined in previous cells, but we'll check\n",
        "required_nodes = ['plan_node', 'retrieval_node', 'web_search_node', 'rerank_node', \n",
        "                 'compression_node', 'reflection_node', 'final_answer_node', \n",
        "                 'route_by_tool', 'should_continue_node']\n",
        "\n",
        "missing_nodes = [node for node in required_nodes if node not in globals()]\n",
        "if missing_nodes:\n",
        "    print(f\"⚠ Warning: The following node functions are not defined: {missing_nodes}\")\n",
        "    print(\"Please ensure all node functions are defined before building the graph.\")\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(RAGState)\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"plan\", plan_node)\n",
        "graph.add_node(\"retrieve_documents\", retrieval_node)  # Changed from \"retrieve_10k\" to \"retrieve_documents\"\n",
        "graph.add_node(\"retrieve_web\", web_search_node)\n",
        "graph.add_node(\"rerank\", rerank_node)\n",
        "graph.add_node(\"compress\", compression_node)\n",
        "graph.add_node(\"reflect\", reflection_node)\n",
        "graph.add_node(\"generate_final_answer\", final_answer_node)\n",
        "# Routing node for dynamic tool selection\n",
        "graph.add_node(\"choose_next_tool\", lambda state: state)\n",
        "\n",
        "graph.set_entry_point(\"plan\")\n",
        "\n",
        "# After initial plan, direct to the routing point\n",
        "graph.add_edge(\"plan\", \"choose_next_tool\")\n",
        "\n",
        "# Use 'choose_next_tool' as the source for dynamic routing to the correct tool\n",
        "graph.add_conditional_edges(\n",
        "    \"choose_next_tool\",  # Source is our routing node\n",
        "    route_by_tool,  # This function will decide the next actual tool node\n",
        "    {\n",
        "        \"search_documents\": \"retrieve_documents\",  # Changed from \"search_10k\" to \"search_documents\"\n",
        "        \"search_web\": \"retrieve_web\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Common pipeline after retrieval\n",
        "graph.add_edge(\"retrieve_documents\", \"rerank\")  # Changed from \"retrieve_10k\"\n",
        "graph.add_edge(\"retrieve_web\", \"rerank\")\n",
        "graph.add_edge(\"rerank\", \"compress\")\n",
        "graph.add_edge(\"compress\", \"reflect\")\n",
        "\n",
        "# After reflection, use should_continue_node to decide if we keep looping or finish\n",
        "graph.add_conditional_edges(\n",
        "    \"reflect\",  # Source is 'reflect'\n",
        "    should_continue_node,\n",
        "    {\n",
        "        \"continue\": \"choose_next_tool\",  # If continue, go back to the routing point for the next step\n",
        "        \"finish\": \"generate_final_answer\",\n",
        "    },\n",
        ")\n",
        "\n",
        "graph.add_edge(\"generate_final_answer\", END)\n",
        "\n",
        "print(\"StateGraph constructed successfully.\")\n",
        "print(\"Graph nodes:\", list(graph.nodes.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part4-4-viz-pro-adv",
      "metadata": {
        "id": "part4-4-viz-pro-adv"
      },
      "source": [
        "### 4.4. Compiling and Visualizing the Iterative Workflow\n",
        "\n",
        "The final step is to compile our graph definition into an executable `Runnable`. We then generate a visual diagram of the graph. The new diagram will clearly show the branching logic where the agent decides between its internal knowledge base (`retrieve_10k`) and its external web search tool (`retrieve_web`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "part4-4-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "part4-4-code-pro-adv",
        "outputId": "0832714c-fdcc-47d4-d950-04146e7dbb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph compiled successfully.\n",
            "Graph visualization failed: Install pygraphviz to draw graphs: `pip install pygraphviz`.. Please ensure pygraphviz is installed.\n"
          ]
        }
      ],
      "source": [
        "deep_thinking_rag_graph = graph.compile()\n",
        "print(\"Graph compiled successfully.\")\n",
        "\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    # Correctly call get_graph() before draw_png()\n",
        "    png_image = deep_thinking_rag_graph.get_graph().draw_png()\n",
        "    display(Image(png_image))\n",
        "except Exception as e:\n",
        "    print(f\"Graph visualization failed: {e}. Please ensure pygraphviz is installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part5-intro-redemption-pro",
      "metadata": {
        "id": "part5-intro-redemption-pro"
      },
      "source": [
        "## Part 5: Redemption - Running the Deep Thinking Pipeline on Our Challenge Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part5-1-invoke-pro-adv",
      "metadata": {
        "id": "part5-1-invoke-pro-adv"
      },
      "source": [
        "### 5.1. Invoking the Graph: A Step-by-Step Trace of the Full Reasoning Process\n",
        "\n",
        "With our graph compiled, we can now invoke it with our complex, multi-source query. We use the `.stream()` method to observe the agent's execution in real-time. The trace will now demonstrate the agent's ability to first query its internal knowledge base, and then seamlessly switch to its web search tool to gather the external information required to fully answer the user's question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "part5-1-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "part5-1-code-pro-adv",
        "outputId": "b216fb1b-9820-4fab-ee49-58b9161131e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph already exists. Verifying edges...\n",
            "Note: If you updated route_by_tool, you may need to rebuild the graph\n",
            "\n",
            "--- Invoking Deep Thinking RAG Graph ---\n",
            "Query: What are the key cost benchmarks and performance metrics for green hydrogen production in India as o...\n",
            "✓ Step 0 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🧠: Generating Plan ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🧠: Generating Plan ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Plan</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the key cost benchmarks for green hydrogen production in India?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Understanding the cost benchmarks is essential to evaluate the economic viability of green hydrogen production in India.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cost benchmarks'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen production'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'India'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cost benchmarks'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the performance metrics for green hydrogen production in India?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Performance metrics will provide insights into the efficiency and effectiveness of green hydrogen production processes.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'performance metrics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen production'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'India'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'performance metrics'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'How do the cost benchmarks and performance metrics of green hydrogen compare to conventional hydrogen production methods?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A comparative analysis will highlight the advantages and disadvantages of green hydrogen relative to conventional methods, which is crucial for understanding its market position.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'comparison'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'conventional hydrogen'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cost'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'performance'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'comparative analysis'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What are the main factors affecting the cost competitiveness of green hydrogen production in India?'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Identifying these factors will help in understanding the challenges and opportunities for green hydrogen in the Indian market.'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_documents'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cost competitiveness'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'factors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'green hydrogen'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'India'</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'challenges and opportunities'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mPlan\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the key cost benchmarks for green hydrogen production in India?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Understanding the cost benchmarks is essential to evaluate the economic viability of green hydrogen production in India.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cost benchmarks'\u001b[0m, \u001b[32m'green hydrogen production'\u001b[0m, \u001b[32m'India'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'cost benchmarks'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the performance metrics for green hydrogen production in India?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Performance metrics will provide insights into the efficiency and effectiveness of green hydrogen production processes.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'performance metrics'\u001b[0m, \u001b[32m'green hydrogen production'\u001b[0m, \u001b[32m'India'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'performance metrics'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'How do the cost benchmarks and performance metrics of green hydrogen compare to conventional hydrogen production methods?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'A comparative analysis will highlight the advantages and disadvantages of green hydrogen relative to conventional methods, which is crucial for understanding its market position.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'comparison'\u001b[0m, \u001b[32m'green hydrogen'\u001b[0m, \u001b[32m'conventional hydrogen'\u001b[0m, \u001b[32m'cost'\u001b[0m, \u001b[32m'performance'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'comparative analysis'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m'What are the main factors affecting the cost competitiveness of green hydrogen production in India?'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m'Identifying these factors will help in understanding the challenges and opportunities for green hydrogen in the Indian market.'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_documents'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cost competitiveness'\u001b[0m, \u001b[32m'factors'\u001b[0m, \u001b[32m'green hydrogen'\u001b[0m, \u001b[32m'India'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'challenges and opportunities'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 0 completed\n",
            "  Tool: search_documents, Question: What are the key cost benchmarks for green hydrogen producti...\n",
            "✓ Step 0 completed\n",
            "  Tool: search_documents, Question: What are the key cost benchmarks for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: What are the key cost benchmarks for green hydrogen production in India?<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m1\u001b[0m: What are the key cost benchmarks for green hydrogen production in India?\u001b[1m)\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: Rewritten search query: <span style=\"color: #008000; text-decoration-color: #008000\">\"key cost benchmarks for green hydrogen production in India 2023, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">levelized cost of hydrogen (LCOH), electrolyzer efficiency, renewable energy integration, market projections, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">policy frameworks for hydrogen economy\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Rewritten Query: Rewritten search query: \u001b[32m\"key cost benchmarks for green hydrogen production in India 2023, \u001b[0m\n",
              "\u001b[32mlevelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, electrolyzer efficiency, renewable energy integration, market projections, \u001b[0m\n",
              "\u001b[32mpolicy frameworks for hydrogen economy\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `keyword_search`. Justification: The query contains specific terms and phrases such as \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'key cost benchmarks'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'levelized cost of hydrogen (LCOH)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'electrolyzer efficiency'</span>, and <span style=\"color: #008000; text-decoration-color: #008000\">'policy frameworks for </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">hydrogen economy'</span>, which indicate a need for precise information. A keyword search will effectively retrieve \n",
              "documents that contain these exact terms, ensuring relevant and accurate results.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Supervisor Decision: Use `keyword_search`. Justification: The query contains specific terms and phrases such as \n",
              "\u001b[32m'key cost benchmarks'\u001b[0m, \u001b[32m'levelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'electrolyzer efficiency'\u001b[0m, and \u001b[32m'policy frameworks for \u001b[0m\n",
              "\u001b[32mhydrogen economy'\u001b[0m, which indicate a need for precise information. A keyword search will effectively retrieve \n",
              "documents that contain these exact terms, ensuring relevant and accurate results.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 0 completed\n",
            "  Tool: search_documents, Question: What are the key cost benchmarks for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🎯: Reranking Documents ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 0 completed\n",
            "  Tool: search_documents, Question: What are the key cost benchmarks for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ✂️: Distilling Context ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: Key cost benchmarks for green hydrogen production in India are influenced by the \n",
              "country's expanding renewable energy sector, particularly solar power, which accounts for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>% of total energy \n",
              "generatio<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Distilled Context Snippet: Key cost benchmarks for green hydrogen production in India are influenced by the \n",
              "country's expanding renewable energy sector, particularly solar power, which accounts for \u001b[1;36m33\u001b[0m% of total energy \n",
              "generatio\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 0 completed\n",
            "  Tool: search_documents, Question: What are the key cost benchmarks for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🤔: Reflecting on Findings ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: Key cost benchmarks for green hydrogen production in India are primarily influenced by the growth of the\n",
              "renewable energy sector, especially solar power, and are affected by import duties on photovoltaic modules, which \n",
              "together impact the overall competitiveness and viability of green hydrogen production.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Summary: Key cost benchmarks for green hydrogen production in India are primarily influenced by the growth of the\n",
              "renewable energy sector, especially solar power, and are affected by import duties on photovoltaic modules, which \n",
              "together impact the overall competitiveness and viability of green hydrogen production.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🚦: Evaluating Policy ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: The research history only covers the key cost benchmarks for green \n",
              "hydrogen production in India. The performance metrics, comparative analysis with conventional hydrogen production \n",
              "methods, and the main factors affecting cost competitiveness are still missing, which are essential to \n",
              "comprehensively answer the original question.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  -> Decision: CONTINUE_PLAN | Justification: The research history only covers the key cost benchmarks for green \n",
              "hydrogen production in India. The performance metrics, comparative analysis with conventional hydrogen production \n",
              "methods, and the main factors affecting cost competitiveness are still missing, which are essential to \n",
              "comprehensively answer the original question.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 1 completed\n",
            "  Tool: search_documents, Question: What are the performance metrics for green hydrogen producti...\n",
            "✓ Step 1 completed\n",
            "  Tool: search_documents, Question: What are the performance metrics for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: What are the performance metrics for green hydrogen production in India?<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m2\u001b[0m: What are the performance metrics for green hydrogen production in India?\u001b[1m)\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: Rewritten search query: <span style=\"color: #008000; text-decoration-color: #008000\">\"performance metrics for green hydrogen production in India 2023, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">including electrolyzer efficiency, levelized cost of hydrogen (LCOH), renewable energy integration, and market </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">projections\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Rewritten Query: Rewritten search query: \u001b[32m\"performance metrics for green hydrogen production in India 2023, \u001b[0m\n",
              "\u001b[32mincluding electrolyzer efficiency, levelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, renewable energy integration, and market \u001b[0m\n",
              "\u001b[32mprojections\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `keyword_search`. Justification: The query contains specific terms and metrics such as \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'electrolyzer efficiency'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'levelized cost of hydrogen (LCOH)'</span>, and <span style=\"color: #008000; text-decoration-color: #008000\">'market projections'</span>, which indicate a need for\n",
              "precise information. A keyword search will effectively retrieve documents that contain these exact terms.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Supervisor Decision: Use `keyword_search`. Justification: The query contains specific terms and metrics such as \n",
              "\u001b[32m'electrolyzer efficiency'\u001b[0m, \u001b[32m'levelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, and \u001b[32m'market projections'\u001b[0m, which indicate a need for\n",
              "precise information. A keyword search will effectively retrieve documents that contain these exact terms.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 1 completed\n",
            "  Tool: search_documents, Question: What are the performance metrics for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🎯: Reranking Documents ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 1 completed\n",
            "  Tool: search_documents, Question: What are the performance metrics for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ✂️: Distilling Context ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: India's performance metrics for green hydrogen production are closely linked to its \n",
              "renewable energy capacity, which includes significant contributions from solar <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748.99</span> GW<span style=\"font-weight: bold\">)</span>, wind <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">695.51</span> GW<span style=\"font-weight: bold\">)</span>, small\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Distilled Context Snippet: India's performance metrics for green hydrogen production are closely linked to its \n",
              "renewable energy capacity, which includes significant contributions from solar \u001b[1m(\u001b[0m\u001b[1;36m748.99\u001b[0m GW\u001b[1m)\u001b[0m, wind \u001b[1m(\u001b[0m\u001b[1;36m695.51\u001b[0m GW\u001b[1m)\u001b[0m, small\n",
              "\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 1 completed\n",
            "  Tool: search_documents, Question: What are the performance metrics for green hydrogen producti...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🤔: Reflecting on Findings ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: India's green hydrogen production performance metrics are significantly influenced by its renewable \n",
              "energy capacity, with a total of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748.99</span> GW from solar, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">695.51</span> GW from wind, and a goal of achieving over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>% of its\n",
              "energy from renewables, primarily solar, by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Summary: India's green hydrogen production performance metrics are significantly influenced by its renewable \n",
              "energy capacity, with a total of \u001b[1;36m748.99\u001b[0m GW from solar, \u001b[1;36m695.51\u001b[0m GW from wind, and a goal of achieving over \u001b[1;36m38\u001b[0m% of its\n",
              "energy from renewables, primarily solar, by \u001b[1;36m2022\u001b[0m.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🚦: Evaluating Policy ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: The research history has provided insights into the key cost \n",
              "benchmarks and performance metrics for green hydrogen production in India. However, the comparative analysis with \n",
              "conventional hydrogen production methods and the identification of main factors affecting cost competitiveness are \n",
              "still pending. These elements are crucial to comprehensively answer the original question.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  -> Decision: CONTINUE_PLAN | Justification: The research history has provided insights into the key cost \n",
              "benchmarks and performance metrics for green hydrogen production in India. However, the comparative analysis with \n",
              "conventional hydrogen production methods and the identification of main factors affecting cost competitiveness are \n",
              "still pending. These elements are crucial to comprehensively answer the original question.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 2 completed\n",
            "  Tool: search_documents, Question: How do the cost benchmarks and performance metrics of green ...\n",
            "✓ Step 2 completed\n",
            "  Tool: search_documents, Question: How do the cost benchmarks and performance metrics of green ...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: How do the cost benchmarks and performance metrics of green hydrogen compare \n",
              "to conventional hydrogen production methods?<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m3\u001b[0m: How do the cost benchmarks and performance metrics of green hydrogen compare \n",
              "to conventional hydrogen production methods?\u001b[1m)\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: Rewritten search query: \n",
              "\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"comparison of cost benchmarks and performance metrics for green hydrogen production versus conventional hydrogen </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">production methods in India, including levelized cost of hydrogen (LCOH), electrolyzer efficiency, renewable energy</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">capacity impacts, and market projections for the energy transition\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Rewritten Query: Rewritten search query: \n",
              "\n",
              "\u001b[32m\"comparison of cost benchmarks and performance metrics for green hydrogen production versus conventional hydrogen \u001b[0m\n",
              "\u001b[32mproduction methods in India, including levelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, electrolyzer efficiency, renewable energy\u001b[0m\n",
              "\u001b[32mcapacity impacts, and market projections for the energy transition\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `vector_search`. Justification: The query is complex and involves conceptual comparisons\n",
              "between green hydrogen and conventional hydrogen production methods, focusing on various performance metrics and \n",
              "benchmarks. This suggests a need for semantic understanding and similarity-based retrieval, making vector search \n",
              "the most suitable strategy.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Supervisor Decision: Use `vector_search`. Justification: The query is complex and involves conceptual comparisons\n",
              "between green hydrogen and conventional hydrogen production methods, focusing on various performance metrics and \n",
              "benchmarks. This suggests a need for semantic understanding and similarity-based retrieval, making vector search \n",
              "the most suitable strategy.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 2 completed\n",
            "  Tool: search_documents, Question: How do the cost benchmarks and performance metrics of green ...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🎯: Reranking Documents ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 2 completed\n",
            "  Tool: search_documents, Question: How do the cost benchmarks and performance metrics of green ...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ✂️: Distilling Context ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: The cost benchmarks and performance metrics of green hydrogen production are \n",
              "increasingly being compared to conventional hydrogen methods, particularly as the global energy landscape shifts \n",
              "towards su<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Distilled Context Snippet: The cost benchmarks and performance metrics of green hydrogen production are \n",
              "increasingly being compared to conventional hydrogen methods, particularly as the global energy landscape shifts \n",
              "towards su\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 2 completed\n",
            "  Tool: search_documents, Question: How do the cost benchmarks and performance metrics of green ...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🤔: Reflecting on Findings ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: Green hydrogen production currently has higher initial costs compared to conventional hydrogen methods, \n",
              "primarily due to technology and infrastructure requirements, but these costs are expected to decrease over time, \n",
              "while conventional methods are more cost-effective but raise sustainability concerns.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Summary: Green hydrogen production currently has higher initial costs compared to conventional hydrogen methods, \n",
              "primarily due to technology and infrastructure requirements, but these costs are expected to decrease over time, \n",
              "while conventional methods are more cost-effective but raise sustainability concerns.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🚦: Evaluating Policy ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: While the research has provided insights into cost benchmarks, \n",
              "performance metrics, and a comparative analysis with conventional hydrogen production, it lacks a comprehensive \n",
              "identification of the main factors affecting the cost competitiveness of green hydrogen production in India. This \n",
              "information is critical to fully address the original question.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  -> Decision: CONTINUE_PLAN | Justification: While the research has provided insights into cost benchmarks, \n",
              "performance metrics, and a comparative analysis with conventional hydrogen production, it lacks a comprehensive \n",
              "identification of the main factors affecting the cost competitiveness of green hydrogen production in India. This \n",
              "information is critical to fully address the original question.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 3 completed\n",
            "  Tool: search_documents, Question: What are the main factors affecting the cost competitiveness...\n",
            "✓ Step 3 completed\n",
            "  Tool: search_documents, Question: What are the main factors affecting the cost competitiveness...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: What are the main factors affecting the cost competitiveness of green \n",
              "hydrogen production in India?<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m4\u001b[0m: What are the main factors affecting the cost competitiveness of green \n",
              "hydrogen production in India?\u001b[1m)\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: Rewritten search query: \n",
              "\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"factors influencing cost competitiveness of green hydrogen production in India, impact of renewable energy growth </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">on levelized cost of hydrogen (LCOH), electrolyzer efficiency, policy frameworks, and market projections for green </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">hydrogen in India\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Rewritten Query: Rewritten search query: \n",
              "\n",
              "\u001b[32m\"factors influencing cost competitiveness of green hydrogen production in India, impact of renewable energy growth \u001b[0m\n",
              "\u001b[32mon levelized cost of hydrogen \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLCOH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, electrolyzer efficiency, policy frameworks, and market projections for green \u001b[0m\n",
              "\u001b[32mhydrogen in India\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `vector_search`. Justification: The query involves complex concepts related to green \n",
              "hydrogen production, including factors influencing cost competitiveness, renewable energy growth, electrolyzer \n",
              "efficiency, and policy frameworks. These topics are more conceptual and require understanding of the relationships \n",
              "and implications between them, making vector search the best strategy for retrieving relevant information.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Supervisor Decision: Use `vector_search`. Justification: The query involves complex concepts related to green \n",
              "hydrogen production, including factors influencing cost competitiveness, renewable energy growth, electrolyzer \n",
              "efficiency, and policy frameworks. These topics are more conceptual and require understanding of the relationships \n",
              "and implications between them, making vector search the best strategy for retrieving relevant information.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 3 completed\n",
            "  Tool: search_documents, Question: What are the main factors affecting the cost competitiveness...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🎯: Reranking Documents ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 3 completed\n",
            "  Tool: search_documents, Question: What are the main factors affecting the cost competitiveness...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ✂️: Distilling Context ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: The cost competitiveness of green hydrogen production in India is influenced by \n",
              "several key factors, including government policies, the stability of the energy supply, and the involvement of the \n",
              "priva<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Distilled Context Snippet: The cost competitiveness of green hydrogen production in India is influenced by \n",
              "several key factors, including government policies, the stability of the energy supply, and the involvement of the \n",
              "priva\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 3 completed\n",
            "  Tool: search_documents, Question: What are the main factors affecting the cost competitiveness...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🤔: Reflecting on Findings ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: The cost competitiveness of green hydrogen production in India is primarily influenced by government \n",
              "policies, energy supply stability, private sector involvement, and challenges such as market volatility and \n",
              "infrastructure needs.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  Summary: The cost competitiveness of green hydrogen production in India is primarily influenced by government \n",
              "policies, energy supply stability, private sector involvement, and challenges such as market volatility and \n",
              "infrastructure needs.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- 🚦: Evaluating Policy ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Plan complete. Finishing.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "  -> Plan complete. Finishing.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 4 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✅: Generating Final Answer with Citations ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ✅: Generating Final Answer with Citations ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Step 4 completed\n",
            "\n",
            "--- Graph Stream Finished ---\n",
            "\n",
            "============================================================\n",
            "FINAL ANSWER\n",
            "============================================================\n",
            "The production of green hydrogen in India is increasingly being recognized as a pivotal component of the country's energy transition strategy. Key cost benchmarks and performance metrics for green hydrogen production are influenced by several factors, including the cost of renewable energy sources, technology adoption, and government policies. As outlined in various benchmarking documents, the cost of producing green hydrogen is primarily driven by the price of electricity, which is expected to decrease as renewable energy capacity expands. Currently, the cost of green hydrogen production in India is estimated to be around ₹300-400 per kg, with projections suggesting that this could drop to ₹150-200 per kg by 2030 as renewable energy becomes more prevalent and efficient [Source: Energies 2023, 16, 5491].\n",
            "\n",
            "In comparison, conventional hydrogen production methods, such as steam methane reforming (SMR), typically have lower upfront costs but are heavily reliant on fossil fuels, making them less sustainable in the long term. The cost of hydrogen produced via SMR is approximately ₹150-200 per kg, but this does not account for the environmental costs associated with carbon emissions [Source: Energies 2023, 16, 5491]. The stark difference in sustainability and long-term viability between green hydrogen and conventional methods highlights the importance of transitioning to cleaner energy sources.\n",
            "\n",
            "Several factors affect the cost competitiveness of green hydrogen production in India. Firstly, the availability and cost of renewable energy sources, particularly solar and wind, play a crucial role. India has significant potential for solar energy, with estimates suggesting a capacity of around 748.99 GW, which can significantly lower the cost of green hydrogen production as solar energy becomes more widely utilized [Source: MNRE]. Secondly, technological advancements in electrolysis and hydrogen storage are essential for improving efficiency and reducing costs. The current efficiency of electrolysis systems is around 60-70%, and ongoing research aims to enhance this to 80% or more, which would further decrease production costs [Source: Energies 2023, 16, 5491].\n",
            "\n",
            "Government policies and incentives also significantly impact the competitiveness of green hydrogen. Initiatives such as the National Hydrogen Mission aim to promote the development of hydrogen technologies and infrastructure, which can help reduce costs through economies of scale and increased investment in research and development [Source: Energies 2023, 16, 5491]. Additionally, the implementation of carbon pricing could make conventional hydrogen production methods less attractive, further enhancing the competitiveness of green hydrogen.\n",
            "\n",
            "In summary, while green hydrogen production in India currently faces higher costs compared to conventional methods, the potential for cost reduction through advancements in renewable energy, technology, and supportive government policies presents a promising outlook. As these factors converge, green hydrogen could become a cornerstone of India's energy strategy, aligning with global sustainability goals and reducing reliance on fossil fuels.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Recompile the graph to use the updated route_by_tool function\n",
        "# If the graph was already compiled, we need to rebuild it\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Check if graph needs to be rebuilt\n",
        "if 'deep_thinking_rag_graph' in globals():\n",
        "    print(\"Graph already exists. Verifying edges...\")\n",
        "    # The graph should use the current route_by_tool function\n",
        "    # If it was compiled before, we may need to rebuild\n",
        "    print(\"Note: If you updated route_by_tool, you may need to rebuild the graph\")\n",
        "else:\n",
        "    print(\"Graph not found. Please build it first.\")\n",
        "\n",
        "# Prepare the graph input\n",
        "final_state = None\n",
        "\n",
        "graph_input = {\n",
        "    \"original_question\": complex_query_adv,\n",
        "    \"question\": complex_query_adv,\n",
        "    \"plan\": None,\n",
        "    \"retrieved_docs\": [],\n",
        "    \"web_results\": [],\n",
        "    \"reranked_docs\": [],\n",
        "    \"compressed_context\": \"\",\n",
        "    \"research_history\": \"\",\n",
        "    \"final_answer\": \"\",\n",
        "    \"current_step\": 0,\n",
        "    \"current_step_index\": 0,\n",
        "    \"past_steps\": [],\n",
        "    \"max_steps\": config.get(\"max_reasoning_iterations\", 7)\n",
        "}\n",
        "\n",
        "print(\"\\n--- Invoking Deep Thinking RAG Graph ---\")\n",
        "print(f\"Query: {complex_query_adv[:100]}...\")\n",
        "\n",
        "# Increase recursion_limit to allow more graph steps\n",
        "try:\n",
        "    for chunk in deep_thinking_rag_graph.stream(\n",
        "        graph_input, \n",
        "        stream_config={\"recursion_limit\": 50}, \n",
        "        stream_mode=\"values\"\n",
        "    ):\n",
        "        final_state = chunk\n",
        "        # Print progress\n",
        "        if \"current_step_index\" in chunk:\n",
        "            step_idx = chunk.get(\"current_step_index\", 0)\n",
        "            print(f\"✓ Step {step_idx} completed\")\n",
        "            if \"plan\" in chunk and chunk[\"plan\"]:\n",
        "                plan = chunk[\"plan\"]\n",
        "                if hasattr(plan, 'steps') and step_idx < len(plan.steps):\n",
        "                    step = plan.steps[step_idx]\n",
        "                    print(f\"  Tool: {step.tool}, Question: {step.sub_question[:60]}...\")\n",
        "    \n",
        "    print(\"\\n--- Graph Stream Finished ---\")\n",
        "    \n",
        "    if final_state:\n",
        "        if \"final_answer\" in final_state and final_state[\"final_answer\"]:\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"FINAL ANSWER\")\n",
        "            print(\"=\" * 60)\n",
        "            print(final_state[\"final_answer\"])\n",
        "            print(\"=\" * 60)\n",
        "        else:\n",
        "            print(\"\\n⚠ No final answer generated\")\n",
        "            if \"research_history\" in final_state:\n",
        "                print(\"\\nResearch History:\")\n",
        "                print(final_state[\"research_history\"][:500] + \"...\")\n",
        "        \n",
        "except KeyError as e:\n",
        "    print(f\"\\n❌ KeyError: {e}\")\n",
        "    print(\"\\nThis usually means:\")\n",
        "    print(\"1. route_by_tool is returning a tool name that doesn't match graph edges\")\n",
        "    print(\"2. The graph edges are: 'search_documents' and 'search_web'\")\n",
        "    print(\"3. But route_by_tool is returning: 'search_10k'\")\n",
        "    print(\"\\nSolution: Ensure route_by_tool function is defined above and maps 'search_10k' -> 'search_documents'\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "213e6a96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating advanced vector store with metadata...\n",
            "Advanced vector store created with 305 documents.\n",
            "Building BM25 index for keyword search...\n",
            "All retrieval strategy functions ready.\n",
            "\n",
            "--- Testing Keyword Search ---\n",
            "Query: green hydrogen cost benchmarks production India\n",
            "Found 5 documents.\n",
            "Top result section: India imported 90% of its panels from China before the implementation of safeguard\n",
            "Top result preview: duties. To promote production in India, the Indian government levied a safeguard tax....\n",
            "\n",
            "--- Testing Semantic Search ---\n",
            "Query: What are the key cost factors for green hydrogen production?\n",
            "Found 5 documents.\n",
            "Top result section: India has embarked on the world’s biggest renewable capacity growth journey. The\n",
            "Top result preview: government wants to boost the use of sustainable energy by investing heavily in green\n",
            "energies. Energy security, electricity scarcity, energy access, among other things, and\n",
            "climate change, played a r...\n",
            "\n",
            "--- Testing Hybrid Search ---\n",
            "Query: policy frameworks incentives green hydrogen India\n",
            "Found 5 documents.\n",
            "Top result section: their targets and achievements. The following conclusions were drawn:\n",
            "Top result preview: • The main focus is on clean and green energy, free from carbon emissions, which\n",
            "requires a centralized space or portal for policy planning, and its implementation...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure required packages are installed\n",
        "try:\n",
        "    from rank_bm25 import BM25Okapi\n",
        "except ImportError:\n",
        "    print(\"Installing rank-bm25 package...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rank-bm25\"])\n",
        "    from rank_bm25 import BM25Okapi\n",
        "    print(\"✓ rank-bm25 installed successfully\")\n",
        "\n",
        "try:\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "except ImportError:\n",
        "    print(\"Installing faiss-cpu...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"faiss-cpu\"])\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "    print(\"✓ faiss-cpu installed successfully\")\n",
        "\n",
        "print(\"Creating advanced vector store with metadata...\")\n",
        "\n",
        "# Ensure embedding_function is available\n",
        "if 'embedding_function' not in globals():\n",
        "    raise ValueError(\"embedding_function not found. Please run the vector store creation cell first.\")\n",
        "\n",
        "# Ensure doc_chunks_with_metadata is available\n",
        "if 'doc_chunks_with_metadata' not in globals():\n",
        "    raise ValueError(\"doc_chunks_with_metadata not found. Please run the document processing cell first.\")\n",
        "\n",
        "# Use FAISS instead of ChromaDB\n",
        "advanced_vector_store = FAISS.from_documents(\n",
        "    documents=doc_chunks_with_metadata,\n",
        "    embedding=embedding_function\n",
        ")\n",
        "print(f\"Advanced vector store created with {len(doc_chunks_with_metadata)} documents.\")\n",
        "\n",
        "print(\"Building BM25 index for keyword search...\")\n",
        "tokenized_corpus = [doc.page_content.split(\" \") for doc in doc_chunks_with_metadata]\n",
        "doc_ids_list = [doc.metadata[\"id\"] for doc in doc_chunks_with_metadata]\n",
        "doc_map = {doc.metadata[\"id\"]: doc for doc in doc_chunks_with_metadata}\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "def vector_search_only(query: str, section_filter: str = None, k: int = 10):\n",
        "    \"\"\"Semantic search using FAISS with optional section filtering\"\"\"\n",
        "    if section_filter and \"Unknown\" not in section_filter:\n",
        "        # Filter documents by section before searching\n",
        "        filtered_docs = [doc for doc in doc_chunks_with_metadata \n",
        "                        if doc.metadata.get(\"section\", \"\") == section_filter]\n",
        "        if filtered_docs:\n",
        "            # Create temporary vector store for filtered docs\n",
        "            temp_store = FAISS.from_documents(filtered_docs, embedding=embedding_function)\n",
        "            return temp_store.similarity_search(query, k=k)\n",
        "    \n",
        "    return advanced_vector_store.similarity_search(query, k=k)\n",
        "\n",
        "def bm25_search_only(query: str, k: int = 10):\n",
        "    \"\"\"Keyword-based search using BM25\"\"\"\n",
        "    tokenized_query = query.split(\" \")\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    top_k_indices = np.argsort(bm25_scores)[::-1][:k]\n",
        "    return [doc_map[doc_ids_list[i]] for i in top_k_indices]\n",
        "\n",
        "def hybrid_search(query: str, section_filter: str = None, k: int = 10):\n",
        "    \"\"\"Combines BM25 keyword search and semantic vector search using Reciprocal Rank Fusion\"\"\"\n",
        "    # 1. Keyword Search (BM25)\n",
        "    bm25_docs = bm25_search_only(query, k=k)\n",
        "\n",
        "    # 2. Semantic Search (with metadata filtering)\n",
        "    semantic_docs = vector_search_only(query, section_filter=section_filter, k=k)\n",
        "\n",
        "    # 3. Reciprocal Rank Fusion (RRF)\n",
        "    all_docs = {doc.metadata[\"id\"]: doc for doc in bm25_docs + semantic_docs}.values()\n",
        "    ranked_lists = [[doc.metadata[\"id\"] for doc in bm25_docs], [doc.metadata[\"id\"] for doc in semantic_docs]]\n",
        "\n",
        "    rrf_scores = {}\n",
        "    for doc_list in ranked_lists:\n",
        "        for i, doc_id in enumerate(doc_list):\n",
        "            if doc_id not in rrf_scores:\n",
        "                rrf_scores[doc_id] = 0\n",
        "            rrf_scores[doc_id] += 1 / (i + 61)  # RRF rank constant k = 60\n",
        "\n",
        "    sorted_doc_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)\n",
        "    final_docs = [doc_map[doc_id] for doc_id in sorted_doc_ids[:k]]\n",
        "    return final_docs\n",
        "\n",
        "print(\"All retrieval strategy functions ready.\")\n",
        "\n",
        "# Test Keyword Search with green hydrogen relevant query\n",
        "print(\"\\n--- Testing Keyword Search ---\")\n",
        "test_query = \"green hydrogen cost benchmarks production India\"\n",
        "test_results = bm25_search_only(test_query, k=5)\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"Found {len(test_results)} documents.\")\n",
        "if test_results:\n",
        "    print(f\"Top result section: {test_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {test_results[0].page_content[:200]}...\")\n",
        "\n",
        "# Test Semantic Search\n",
        "print(\"\\n--- Testing Semantic Search ---\")\n",
        "test_query_semantic = \"What are the key cost factors for green hydrogen production?\"\n",
        "semantic_results = vector_search_only(test_query_semantic, k=5)\n",
        "print(f\"Query: {test_query_semantic}\")\n",
        "print(f\"Found {len(semantic_results)} documents.\")\n",
        "if semantic_results:\n",
        "    print(f\"Top result section: {semantic_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {semantic_results[0].page_content[:200]}...\")\n",
        "\n",
        "# Test Hybrid Search\n",
        "print(\"\\n--- Testing Hybrid Search ---\")\n",
        "test_query_hybrid = \"policy frameworks incentives green hydrogen India\"\n",
        "hybrid_results = hybrid_search(test_query_hybrid, k=5)\n",
        "print(f\"Query: {test_query_hybrid}\")\n",
        "print(f\"Found {len(hybrid_results)} documents.\")\n",
        "if hybrid_results:\n",
        "    print(f\"Top result section: {hybrid_results[0].metadata.get('section', 'Unknown')}\")\n",
        "    print(f\"Top result preview: {hybrid_results[0].page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part5-2-analyze-pro-adv",
      "metadata": {
        "id": "part5-2-analyze-pro-adv"
      },
      "source": [
        "### 5.2. Analyzing the Final High-Quality Output with Full Provenance\n",
        "\n",
        "The agent has successfully executed its plan, using the right tool for each step. Now, we examine the `final_answer` stored in the terminal state. Unlike the baseline's failure, we expect a cohesive, multi-part answer that successfully synthesizes information from two different sources into a single analytical response, complete with citations to both the 10-K and the web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "part5-2-code-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "part5-2-code-pro-adv",
        "outputId": "b159035b-c9bf-49f9-e00b-43e234e002da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- DEEP THINKING RAG FINAL ANSWER ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- DEEP THINKING RAG FINAL ANSWER ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The production of green hydrogen in India is increasingly being recognized as a pivotal component of the country's \n",
              "energy transition strategy. Key cost benchmarks and performance metrics for green hydrogen production are          \n",
              "influenced by several factors, including the cost of renewable energy sources, technology adoption, and government \n",
              "policies. As outlined in various benchmarking documents, the cost of producing green hydrogen is primarily driven  \n",
              "by the price of electricity, which is expected to decrease as renewable energy capacity expands. Currently, the    \n",
              "cost of green hydrogen production in India is estimated to be around ₹300-400 per kg, with projections suggesting  \n",
              "that this could drop to ₹150-200 per kg by 2030 as renewable energy becomes more prevalent and efficient [Source:  \n",
              "Energies 2023, 16, 5491].                                                                                          \n",
              "\n",
              "In comparison, conventional hydrogen production methods, such as steam methane reforming (SMR), typically have     \n",
              "lower upfront costs but are heavily reliant on fossil fuels, making them less sustainable in the long term. The    \n",
              "cost of hydrogen produced via SMR is approximately ₹150-200 per kg, but this does not account for the environmental\n",
              "costs associated with carbon emissions [Source: Energies 2023, 16, 5491]. The stark difference in sustainability   \n",
              "and long-term viability between green hydrogen and conventional methods highlights the importance of transitioning \n",
              "to cleaner energy sources.                                                                                         \n",
              "\n",
              "Several factors affect the cost competitiveness of green hydrogen production in India. Firstly, the availability   \n",
              "and cost of renewable energy sources, particularly solar and wind, play a crucial role. India has significant      \n",
              "potential for solar energy, with estimates suggesting a capacity of around 748.99 GW, which can significantly lower\n",
              "the cost of green hydrogen production as solar energy becomes more widely utilized [Source: MNRE]. Secondly,       \n",
              "technological advancements in electrolysis and hydrogen storage are essential for improving efficiency and reducing\n",
              "costs. The current efficiency of electrolysis systems is around 60-70%, and ongoing research aims to enhance this  \n",
              "to 80% or more, which would further decrease production costs [Source: Energies 2023, 16, 5491].                   \n",
              "\n",
              "Government policies and incentives also significantly impact the competitiveness of green hydrogen. Initiatives    \n",
              "such as the National Hydrogen Mission aim to promote the development of hydrogen technologies and infrastructure,  \n",
              "which can help reduce costs through economies of scale and increased investment in research and development        \n",
              "[Source: Energies 2023, 16, 5491]. Additionally, the implementation of carbon pricing could make conventional      \n",
              "hydrogen production methods less attractive, further enhancing the competitiveness of green hydrogen.              \n",
              "\n",
              "In summary, while green hydrogen production in India currently faces higher costs compared to conventional methods,\n",
              "the potential for cost reduction through advancements in renewable energy, technology, and supportive government   \n",
              "policies presents a promising outlook. As these factors converge, green hydrogen could become a cornerstone of     \n",
              "India's energy strategy, aligning with global sustainability goals and reducing reliance on fossil fuels.          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The production of green hydrogen in India is increasingly being recognized as a pivotal component of the country's \n",
              "energy transition strategy. Key cost benchmarks and performance metrics for green hydrogen production are          \n",
              "influenced by several factors, including the cost of renewable energy sources, technology adoption, and government \n",
              "policies. As outlined in various benchmarking documents, the cost of producing green hydrogen is primarily driven  \n",
              "by the price of electricity, which is expected to decrease as renewable energy capacity expands. Currently, the    \n",
              "cost of green hydrogen production in India is estimated to be around ₹300-400 per kg, with projections suggesting  \n",
              "that this could drop to ₹150-200 per kg by 2030 as renewable energy becomes more prevalent and efficient [Source:  \n",
              "Energies 2023, 16, 5491].                                                                                          \n",
              "\n",
              "In comparison, conventional hydrogen production methods, such as steam methane reforming (SMR), typically have     \n",
              "lower upfront costs but are heavily reliant on fossil fuels, making them less sustainable in the long term. The    \n",
              "cost of hydrogen produced via SMR is approximately ₹150-200 per kg, but this does not account for the environmental\n",
              "costs associated with carbon emissions [Source: Energies 2023, 16, 5491]. The stark difference in sustainability   \n",
              "and long-term viability between green hydrogen and conventional methods highlights the importance of transitioning \n",
              "to cleaner energy sources.                                                                                         \n",
              "\n",
              "Several factors affect the cost competitiveness of green hydrogen production in India. Firstly, the availability   \n",
              "and cost of renewable energy sources, particularly solar and wind, play a crucial role. India has significant      \n",
              "potential for solar energy, with estimates suggesting a capacity of around 748.99 GW, which can significantly lower\n",
              "the cost of green hydrogen production as solar energy becomes more widely utilized [Source: MNRE]. Secondly,       \n",
              "technological advancements in electrolysis and hydrogen storage are essential for improving efficiency and reducing\n",
              "costs. The current efficiency of electrolysis systems is around 60-70%, and ongoing research aims to enhance this  \n",
              "to 80% or more, which would further decrease production costs [Source: Energies 2023, 16, 5491].                   \n",
              "\n",
              "Government policies and incentives also significantly impact the competitiveness of green hydrogen. Initiatives    \n",
              "such as the National Hydrogen Mission aim to promote the development of hydrogen technologies and infrastructure,  \n",
              "which can help reduce costs through economies of scale and increased investment in research and development        \n",
              "[Source: Energies 2023, 16, 5491]. Additionally, the implementation of carbon pricing could make conventional      \n",
              "hydrogen production methods less attractive, further enhancing the competitiveness of green hydrogen.              \n",
              "\n",
              "In summary, while green hydrogen production in India currently faces higher costs compared to conventional methods,\n",
              "the potential for cost reduction through advancements in renewable energy, technology, and supportive government   \n",
              "policies presents a promising outlook. As these factors converge, green hydrogen could become a cornerstone of     \n",
              "India's energy strategy, aligning with global sustainability goals and reducing reliance on fossil fuels.          \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "console.print(\"--- DEEP THINKING RAG FINAL ANSWER ---\")\n",
        "console.print(Markdown(final_state['final_answer']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part5-3-compare-pro-adv",
      "metadata": {
        "id": "part5-3-compare-pro-adv"
      },
      "source": [
        "### 5.3. Side-by-Side Comparison: Vanilla RAG vs. Deep Thinking RAG\n",
        "\n",
        "| Feature                 | Vanilla RAG (Failed)                                                                                                                              | Deep Thinking RAG (Success)                                                                                                                                                                                                                                                                                            |\n",
        "|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Cognitive Model**     | Linear, stateless, one-shot retrieval.                                                                                                            | Cyclical, stateful, multi-step reasoning loop.                                                                                                                                                                                                                                                                         |\n",
        "| **Planning**            | None. The entire complex query is treated as a single search.                                                                                     | Explicit planning step decomposes the query into a structured, multi-step research plan, **assigning the correct tool (internal vs. web) to each step.**                                                                                                                                                                 |\n",
        "| **Retrieval Strategy**  | Naive semantic search on a single static source.                                                                             | **Adaptive, multi-stage funnel:** A supervisor agent **dynamically selects the best retrieval strategy** (vector, keyword, or hybrid) for each sub-question, followed by a cross-encoder for high-precision reranking.                                                                                                         |\n",
        "| **Knowledge Source**    | Restricted to the single, static 10-K document.                                                                                                   | **Multi-source knowledge:** Can seamlessly access both the static internal document and the live web to gather all necessary evidence.                                                                                                                                                                                           |\n",
        "| **Answer Quality**      | Completely failed to answer the second part of the query due to a lack of information. Unable to perform any synthesis.                                     | Answered all parts of the query comprehensively. **Successfully synthesized information from two different sources** (10-K and web search) into a coherent, analytical narrative with verifiable source citations for both.                                                                                                    |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part6-intro-eval-pro",
      "metadata": {
        "id": "part6-intro-eval-pro"
      },
      "source": [
        "## Part 6: A Production-Grade Evaluation Framework\n",
        "\n",
        "To move from anecdotal success to objective validation, we employ a rigorous, automated evaluation framework. We will use the **RAGAs** (RAG Assessment) library to score both our baseline and advanced pipelines across a suite of metrics designed to quantify the quality and reliability of RAG systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part6-metrics-pro",
      "metadata": {
        "id": "part6-metrics-pro"
      },
      "source": [
        "### 6.1. Evaluation Metrics Overview\n",
        "**Context Precision & Recall** measure the quality of the retrieved information. Precision is the signal-to-noise ratio, while Recall measures whether all relevant information was found.\n",
        "\n",
        "**Answer Faithfulness** measures whether the answer is grounded in the provided context, preventing hallucination.\n",
        "\n",
        "**Answer Correctness** measures how well the answer addresses the user's query when compared to a 'ground truth' ideal answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part6-4-ragas-code-pro-adv",
      "metadata": {
        "id": "part6-4-ragas-code-pro-adv"
      },
      "source": [
        "### 6.2. Code Dependency: Implementing an Automated Evaluation with RAGAs\n",
        "\n",
        "We construct a `Dataset` object for evaluation. This dataset includes our new multi-source user query, the answers generated by both pipelines, their respective retrieved contexts, and a manually crafted 'ground truth' answer. RAGAs then uses LLMs to score our key metrics, providing a quantitative measure of the advanced agent's superiority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "part6-4-code-impl-pro-adv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "4bed465460ce409baffc227a3a381f7e",
            "752a66111b0b48f4ad2bd022def2ac3b",
            "e9167b7f45714d019ea9df780b5ff982",
            "6659da1f90f34a33a1280b29e99be124",
            "bda183142f1846bbb71962651634641f",
            "aac5acf3e76d461190857b8ee617360b",
            "87e90c8ccd164f30926d196575f387a6",
            "3dcf0e83926c476993223317afdaa84f",
            "1ff34a9f56ab4865b3aff98e8e83bea4",
            "3eee5f3bbaf14eadab13589ac94039af",
            "93fbf639cf9b49deabf4b81f06f6001e"
          ]
        },
        "id": "part6-4-code-impl-pro-adv",
        "outputId": "ccfe5995-244c-4b1f-cf4e-87de3afe8e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE EVALUATION - Baseline vs Deep Thinking RAG\n",
            "================================================================================\n",
            "\n",
            "Calculating comprehensive metrics...\n",
            "\n",
            "================================================================================\n",
            "QUERY\n",
            "================================================================================\n",
            "What are the key cost benchmarks and performance metrics for green hydrogen production in India as outlined in the benchmarking document? Compare these to conventional hydrogen production methods and identify the main factors affecting cost competitiveness.\n",
            "\n",
            "================================================================================\n",
            "BASELINE RAG RESPONSE\n",
            "================================================================================\n",
            "Answer Length: 861 characters, 126 words\n",
            "Retrieved Contexts: 0 chunks\n",
            "Sentences: 5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RESPONSE:\n",
            "--------------------------------------------------------------------------------\n",
            "The provided context does not contain specific information regarding the cost benchmarks and performance metrics for green hydrogen production in India, nor does it compare these to conventional hydrogen production methods. The text primarily discusses the challenges and potential of renewable energy sources, particularly solar energy, in India, along with the government's policies and the importance of clean energy for economic and climatic growth.\n",
            "\n",
            "To answer your question accurately, I would need specific details from a benchmarking document that outlines the cost benchmarks and performance metrics for green hydrogen production, as well as comparisons to conventional methods and the factors affecting cost competitiveness. If you have access to such a document or additional information, please provide it, and I would be happy to assist you further.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "DEEP THINKING RAG RESPONSE\n",
            "================================================================================\n",
            "Answer Length: 3180 characters, 448 words\n",
            "Retrieved Contexts: 0 chunks\n",
            "Sentences: 19\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RESPONSE:\n",
            "--------------------------------------------------------------------------------\n",
            "The production of green hydrogen in India is increasingly being recognized as a pivotal component of the country's energy transition strategy. Key cost benchmarks and performance metrics for green hydrogen production are influenced by several factors, including the cost of renewable energy sources, technology adoption, and government policies. As outlined in various benchmarking documents, the cost of producing green hydrogen is primarily driven by the price of electricity, which is expected to decrease as renewable energy capacity expands. Currently, the cost of green hydrogen production in India is estimated to be around ₹300-400 per kg, with projections suggesting that this could drop to ₹150-200 per kg by 2030 as renewable energy becomes more prevalent and efficient [Source: Energies 2023, 16, 5491].\n",
            "\n",
            "In comparison, conventional hydrogen production methods, such as steam methane reforming (SMR), typically have lower upfront costs but are heavily reliant on fossil fuels, making them less sustainable in the long term. The cost of hydrogen produced via SMR is approximately ₹150-200 per kg, but this does not account for the environmental costs associated with carbon emissions [Source: Energies 2023, 16, 5491]. The stark difference in sustainability and long-term viability between green hydrogen and conventional methods highlights the importance of transitioning to cleaner energy sources.\n",
            "\n",
            "Several factors affect the cost competitiveness of green hydrogen production in India. Firstly, the availability and cost of renewable energy sources, particularly solar and wind, play a crucial role. India has significant potential for solar energy, with estimates suggesting a capacity of around 748.99 GW, which can significantly lower the cost of green hydrogen production as solar energy becomes more widely utilized [Source: MNRE]. Secondly, technological advancements in electrolysis and hydrogen storage are essential for improving efficiency and reducing costs. The current efficiency of electrolysis systems is around 60-70%, and ongoing research aims to enhance this to 80% or more, which would further decrease production costs [Source: Energies 2023, 16, 5491].\n",
            "\n",
            "Government policies and incentives also significantly impact the competitiveness of green hydrogen. Initiatives such as the National Hydrogen Mission aim to promote the development of hydrogen technologies and infrastructure, which can help reduce costs through economies of scale and increased investment in research and development [Source: Energies 2023, 16, 5491]. Additionally, the implementation of carbon pricing could make conventional hydrogen production methods less attractive, further enhancing the competitiveness of green hydrogen.\n",
            "\n",
            "In summary, while green hydrogen production in India currently faces higher costs compared to conventional methods, the potential for cost reduction through advancements in renewable energy, technology, and supportive government policies presents a promising outlook. As these factors converge, green hydrogen could become a cornerstone of India's energy strategy, aligning with global sustainability goals and reducing reliance on fossil fuels.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "ALL METRICS COMPARISON\n",
            "================================================================================\n",
            "\n",
            "                    Metric Baseline RAG Deep Thinking RAG Improvement\n",
            "Answer Length (characters)          861              3180     +269.3%\n",
            "                Word Count          126               448     +255.6%\n",
            "            Sentence Count            5                19     +280.0%\n",
            "Average Words per Sentence         25.2              23.6       -6.4%\n",
            "           Key Terms Found           10                17      +70.0%\n",
            "        Key Terms Coverage        0.370             0.630      +70.0%\n",
            "     Numerical Data Points            0                23  ∞ (from 0)\n",
            " Has Specific Values (0/1)            0                 1  ∞ (from 0)\n",
            "        Key Facts Coverage        0.400             0.500      +25.0%\n",
            " Context Precision (RAGAS)          0.0               0.0         N/A\n",
            "    Context Recall (RAGAS)          0.0               0.0         N/A\n",
            "      Faithfulness (RAGAS)          0.0               0.0         N/A\n",
            "Answer Correctness (RAGAS)        0.288             0.221      -23.3%\n",
            "          Answer Precision        0.259             0.144      -44.3%\n",
            "             Answer Recall        0.324             0.471      +45.5%\n",
            "      Context Word Overlap            0                 0         N/A\n",
            "       Context Usage Ratio            0                 0         N/A\n",
            "   Context-Based Sentences            0                 0         N/A\n",
            "    Context Reliance Ratio            0                 0         N/A\n",
            "   Ground Truth Similarity        0.324             0.471      +45.5%\n",
            "         Question Coverage        0.724             0.759       +4.8%\n",
            "         Specificity Ratio          0.0               0.4  ∞ (from 0)\n",
            "         Readability Score         69.6              72.8       +4.7%\n",
            "    Has Introduction (0/1)            0                 0         N/A\n",
            "      Has Conclusion (0/1)            0                 0         N/A\n",
            "       Has Structure (0/1)            0                 1  ∞ (from 0)\n",
            "\n",
            "================================================================================\n",
            "SUMMARY STATISTICS\n",
            "================================================================================\n",
            "\n",
            "                    Metric Baseline RAG Deep Thinking RAG Improvement\n",
            "  Overall Score (weighted)        26.2%             34.5%      +31.7%\n",
            "        Key Terms Coverage        37.0%             63.0%      +70.0%\n",
            "   Ground Truth Similarity        32.4%             47.1%      +45.5%\n",
            "             Context Usage         0.0%              0.0%         N/A\n",
            "         Question Coverage        72.4%             75.9%       +4.8%\n",
            " Context Precision (RAGAS)        0.000             0.000         N/A\n",
            "    Context Recall (RAGAS)        0.000             0.000         N/A\n",
            "      Faithfulness (RAGAS)        0.000             0.000         N/A\n",
            "Answer Correctness (RAGAS)        0.288             0.221      -23.3%\n",
            "               Specificity         0.00              0.38         N/A\n",
            "               Readability         69.6              72.8       +4.7%\n",
            "\n",
            "================================================================================\n",
            "KEY FINDINGS\n",
            "================================================================================\n",
            "  ✓ Deep Thinking RAG shows 31.7% improvement in overall score\n",
            "  ✓ Deep Thinking RAG covers 7 more key terms\n",
            "  ✓ Deep Thinking RAG includes 23 more numerical data points\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Enhanced manual evaluation with comprehensive metrics including RAGAS-style metrics\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE EVALUATION - Baseline vs Deep Thinking RAG\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def comprehensive_evaluation(question, answer, ground_truth, contexts, model_name=\"Model\"):\n",
        "    \"\"\"Comprehensive evaluation metrics including RAGAS-style metrics.\"\"\"\n",
        "    metrics = {}\n",
        "    \n",
        "    # Basic metrics\n",
        "    metrics['answer_length'] = len(answer)\n",
        "    metrics['word_count'] = len(answer.split())\n",
        "    metrics['sentence_count'] = len(re.split(r'[.!?]+', answer))\n",
        "    metrics['avg_words_per_sentence'] = metrics['word_count'] / max(metrics['sentence_count'], 1)\n",
        "    \n",
        "    # Key terms coverage (energy sector specific)\n",
        "    energy_keywords = [\n",
        "        'green hydrogen', 'hydrogen', 'renewable', 'energy', 'transition',\n",
        "        'cost', 'benchmark', 'production', 'India', 'policy', 'framework',\n",
        "        'electrolyzer', 'LCOH', 'levelized', 'incentive', 'target', '2030',\n",
        "        'renewable energy', 'solar', 'wind', 'infrastructure', 'challenge',\n",
        "        'opportunity', 'market', 'investment', 'technology', 'efficiency'\n",
        "    ]\n",
        "    \n",
        "    answer_lower = answer.lower()\n",
        "    found_keywords = [kw for kw in energy_keywords if kw in answer_lower]\n",
        "    metrics['key_terms_found'] = len(found_keywords)\n",
        "    metrics['key_terms_coverage'] = len(found_keywords) / len(energy_keywords)\n",
        "    metrics['key_terms_list'] = found_keywords\n",
        "    \n",
        "    # Technical terms (numbers, percentages, specific values)\n",
        "    numbers = re.findall(r'\\$?\\d+[.,]?\\d*[%]?', answer)\n",
        "    metrics['numerical_data_points'] = len(numbers)\n",
        "    metrics['has_specific_values'] = 1 if len(numbers) > 0 else 0\n",
        "    \n",
        "    # Context usage\n",
        "    if contexts:\n",
        "        context_text = ' '.join(contexts[:5]).lower()  # First 5 contexts\n",
        "        context_words = set(context_text.split())\n",
        "        answer_words = set(answer_lower.split())\n",
        "        overlap = len(context_words.intersection(answer_words))\n",
        "        metrics['context_word_overlap'] = overlap\n",
        "        metrics['context_usage_ratio'] = overlap / max(len(answer_words), 1)\n",
        "        \n",
        "        # Check for direct quotes or paraphrases from context\n",
        "        context_sentences = re.split(r'[.!?]+', context_text)\n",
        "        answer_sentences = re.split(r'[.!?]+', answer_lower)\n",
        "        similar_sentences = 0\n",
        "        for ans_sent in answer_sentences:\n",
        "            if len(ans_sent.split()) > 5:  # Only check substantial sentences\n",
        "                for ctx_sent in context_sentences:\n",
        "                    if len(ctx_sent.split()) > 5:\n",
        "                        # Simple similarity check\n",
        "                        ans_words = set(ans_sent.split())\n",
        "                        ctx_words = set(ctx_sent.split())\n",
        "                        if len(ans_words.intersection(ctx_words)) / max(len(ans_words), 1) > 0.3:\n",
        "                            similar_sentences += 1\n",
        "                            break\n",
        "        metrics['context_based_sentences'] = similar_sentences\n",
        "        metrics['context_reliance_ratio'] = similar_sentences / max(len(answer_sentences), 1)\n",
        "    else:\n",
        "        metrics['context_word_overlap'] = 0\n",
        "        metrics['context_usage_ratio'] = 0\n",
        "        metrics['context_based_sentences'] = 0\n",
        "        metrics['context_reliance_ratio'] = 0\n",
        "    \n",
        "    # Ground truth similarity\n",
        "    gt_words = set(ground_truth.lower().split())\n",
        "    answer_words = set(answer_lower.split())\n",
        "    answer_gt_overlap = len(gt_words.intersection(answer_words))\n",
        "    metrics['ground_truth_word_overlap'] = answer_gt_overlap\n",
        "    metrics['ground_truth_similarity'] = answer_gt_overlap / max(len(gt_words), 1)\n",
        "    \n",
        "    # Answer structure and quality\n",
        "    metrics['has_introduction'] = 1 if answer_lower.startswith(('based on', 'according to', 'the document', 'the analysis')) else 0\n",
        "    metrics['has_conclusion'] = 1 if any(word in answer_lower[-100:] for word in ['conclusion', 'summary', 'overall', 'in summary']) else 0\n",
        "    metrics['has_structure'] = 1 if any(word in answer_lower for word in ['first', 'second', 'third', 'additionally', 'furthermore', 'however']) else 0\n",
        "    \n",
        "    # Completeness (check if answer addresses key question components)\n",
        "    question_lower = question.lower()\n",
        "    question_keywords = set(question_lower.split())\n",
        "    question_answer_overlap = len(question_keywords.intersection(answer_words))\n",
        "    metrics['question_coverage'] = question_answer_overlap / max(len(question_keywords), 1)\n",
        "    \n",
        "    # Specificity score (ratio of specific terms to general terms)\n",
        "    specific_terms = ['million', 'tonnes', '2030', 'kg', 'percent', '%', 'dollar', '$', \n",
        "                     'policy', 'framework', 'mission', 'incentive', 'target']\n",
        "    general_terms = ['the', 'is', 'are', 'and', 'or', 'but', 'a', 'an', 'in', 'on', 'at', 'to', 'for']\n",
        "    specific_count = sum(1 for term in specific_terms if term in answer_lower)\n",
        "    general_count = sum(1 for term in general_terms if term in answer_lower)\n",
        "    metrics['specificity_ratio'] = specific_count / max(general_count, 1) if general_count > 0 else specific_count\n",
        "    \n",
        "    # Readability (simple Flesch-like metric based on sentence and word length)\n",
        "    avg_sentence_length = metrics['avg_words_per_sentence']\n",
        "    metrics['readability_score'] = max(0, min(100, 100 - (avg_sentence_length - 10) * 2))\n",
        "    \n",
        "    # RAGAS-STYLE METRICS (Manual Implementation)\n",
        "    # 1. Context Precision: Proportion of retrieved contexts that are relevant\n",
        "    if contexts:\n",
        "        relevant_contexts = 0\n",
        "        question_gt_keywords = set(question_lower.split()) | set(ground_truth.lower().split())\n",
        "        \n",
        "        for ctx in contexts[:10]:  # Check first 10 contexts\n",
        "            ctx_lower = ctx.lower()\n",
        "            ctx_words = set(ctx_lower.split())\n",
        "            overlap_ratio = len(question_gt_keywords.intersection(ctx_words)) / max(len(question_gt_keywords), 1)\n",
        "            if overlap_ratio > 0.1:  # At least 10% keyword overlap\n",
        "                relevant_contexts += 1\n",
        "        \n",
        "        metrics['context_precision'] = relevant_contexts / max(len(contexts), 1)\n",
        "    else:\n",
        "        metrics['context_precision'] = 0.0\n",
        "    \n",
        "    # 2. Context Recall: Proportion of relevant information from ground truth found in contexts\n",
        "    if contexts:\n",
        "        all_context_text = ' '.join(contexts).lower()\n",
        "        context_words = set(all_context_text.split())\n",
        "        gt_words_set = set(ground_truth.lower().split())\n",
        "        \n",
        "        gt_words_in_context = len(gt_words_set.intersection(context_words))\n",
        "        metrics['context_recall'] = gt_words_in_context / max(len(gt_words_set), 1)\n",
        "    else:\n",
        "        metrics['context_recall'] = 0.0\n",
        "    \n",
        "    # 3. Faithfulness: Measures if answer is grounded in context (no hallucinations)\n",
        "    if contexts:\n",
        "        all_context_text = ' '.join(contexts).lower()\n",
        "        answer_sentences = [s.strip() for s in re.split(r'[.!?]+', answer_lower) if len(s.strip()) > 10]\n",
        "        context_sentences = [s.strip() for s in re.split(r'[.!?]+', all_context_text) if len(s.strip()) > 10]\n",
        "        \n",
        "        faithful_sentences = 0\n",
        "        for ans_sent in answer_sentences:\n",
        "            ans_words = set(ans_sent.split())\n",
        "            for ctx_sent in context_sentences:\n",
        "                ctx_words = set(ctx_sent.split())\n",
        "                overlap = len(ans_words.intersection(ctx_words))\n",
        "                if overlap / max(len(ans_words), 1) > 0.3:\n",
        "                    faithful_sentences += 1\n",
        "                    break\n",
        "        \n",
        "        metrics['faithfulness'] = faithful_sentences / max(len(answer_sentences), 1) if answer_sentences else 0.0\n",
        "    else:\n",
        "        metrics['faithfulness'] = 0.0\n",
        "    \n",
        "    # 4. Answer Correctness: How well the answer matches the ground truth\n",
        "    gt_words_set = set(ground_truth.lower().split())\n",
        "    answer_words_set = set(answer_lower.split())\n",
        "    \n",
        "    word_overlap = len(gt_words_set.intersection(answer_words_set))\n",
        "    word_precision = word_overlap / max(len(answer_words_set), 1)\n",
        "    word_recall = word_overlap / max(len(gt_words_set), 1)\n",
        "    \n",
        "    if word_precision + word_recall > 0:\n",
        "        metrics['answer_correctness'] = 2 * (word_precision * word_recall) / (word_precision + word_recall)\n",
        "    else:\n",
        "        metrics['answer_correctness'] = 0.0\n",
        "    \n",
        "    metrics['answer_precision'] = word_precision\n",
        "    metrics['answer_recall'] = word_recall\n",
        "    \n",
        "    # Check for key facts from ground truth\n",
        "    gt_key_facts = [\n",
        "        'green hydrogen', 'cost', 'benchmark', 'India', 'policy',\n",
        "        'electrolyzer', 'renewable', '2030', 'million', 'tonnes'\n",
        "    ]\n",
        "    facts_in_answer = sum(1 for fact in gt_key_facts if fact in answer_lower)\n",
        "    metrics['key_facts_coverage'] = facts_in_answer / len(gt_key_facts)\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Ensure variables are defined\n",
        "if 'complex_query_adv' not in globals():\n",
        "    complex_query_adv = \"What are the key cost benchmarks and performance metrics for green hydrogen production in India?\"\n",
        "\n",
        "if 'ground_truth_answer_adv' not in globals():\n",
        "    ground_truth_answer_adv = \"\"\"Based on the green hydrogen benchmarking document, key cost benchmarks for green hydrogen production in India include electrolyzer costs, renewable energy prices, and infrastructure requirements. The document identifies that green hydrogen costs range from $3-7 per kg depending on scale and renewable energy source. Policy frameworks such as India's National Green Hydrogen Mission with targets of 5 million tonnes by 2030, along with production-linked incentives, are key factors supporting adoption. Main challenges include high capital costs and infrastructure needs, while opportunities include abundant renewable resources and government support.\"\"\"\n",
        "\n",
        "baseline_answer = baseline_result if 'baseline_result' in globals() else \"No baseline answer available\"\n",
        "advanced_answer = \"\"\n",
        "if 'final_state' in locals() and final_state:\n",
        "    advanced_answer = final_state.get('final_answer', '')\n",
        "elif 'baseline_result' in globals():\n",
        "    advanced_answer = baseline_result\n",
        "\n",
        "if not baseline_answer or baseline_answer == \"No baseline answer available\":\n",
        "    baseline_answer = \"Answer not available\"\n",
        "\n",
        "if not advanced_answer:\n",
        "    advanced_answer = baseline_answer\n",
        "\n",
        "# Get contexts\n",
        "baseline_contexts_list = baseline_contexts[0] if 'baseline_contexts' in locals() and baseline_contexts else []\n",
        "advanced_contexts_list = advanced_contexts[0] if 'advanced_contexts' in locals() and advanced_contexts else []\n",
        "\n",
        "# Calculate metrics for both models\n",
        "print(\"\\nCalculating comprehensive metrics...\")\n",
        "baseline_metrics = comprehensive_evaluation(\n",
        "    complex_query_adv, \n",
        "    baseline_answer, \n",
        "    ground_truth_answer_adv, \n",
        "    baseline_contexts_list,\n",
        "    \"Baseline RAG\"\n",
        ")\n",
        "\n",
        "advanced_metrics = comprehensive_evaluation(\n",
        "    complex_query_adv, \n",
        "    advanced_answer, \n",
        "    ground_truth_answer_adv, \n",
        "    advanced_contexts_list,\n",
        "    \"Deep Thinking RAG\"\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# DISPLAY RESPONSES ONE AFTER THE OTHER\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"QUERY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{complex_query_adv}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BASELINE RAG RESPONSE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Answer Length: {len(baseline_answer)} characters, {len(baseline_answer.split())} words\")\n",
        "print(f\"Retrieved Contexts: {len(baseline_contexts_list)} chunks\")\n",
        "print(f\"Sentences: {baseline_metrics['sentence_count']}\")\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"RESPONSE:\")\n",
        "print(\"-\" * 80)\n",
        "print(baseline_answer)\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DEEP THINKING RAG RESPONSE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Answer Length: {len(advanced_answer)} characters, {len(advanced_answer.split())} words\")\n",
        "print(f\"Retrieved Contexts: {len(advanced_contexts_list)} chunks\")\n",
        "print(f\"Sentences: {advanced_metrics['sentence_count']}\")\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"RESPONSE:\")\n",
        "print(\"-\" * 80)\n",
        "print(advanced_answer)\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# ALL METRICS COMPARISON TABLE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ALL METRICS COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create comprehensive comparison table with all metrics\n",
        "all_metrics = [\n",
        "    # Basic Metrics\n",
        "    ('answer_length', 'Answer Length (characters)'),\n",
        "    ('word_count', 'Word Count'),\n",
        "    ('sentence_count', 'Sentence Count'),\n",
        "    ('avg_words_per_sentence', 'Average Words per Sentence'),\n",
        "    \n",
        "    # Content Quality\n",
        "    ('key_terms_found', 'Key Terms Found'),\n",
        "    ('key_terms_coverage', 'Key Terms Coverage'),\n",
        "    ('numerical_data_points', 'Numerical Data Points'),\n",
        "    ('has_specific_values', 'Has Specific Values (0/1)'),\n",
        "    ('key_facts_coverage', 'Key Facts Coverage'),\n",
        "    \n",
        "    # RAGAS-Style Metrics\n",
        "    ('context_precision', 'Context Precision (RAGAS)'),\n",
        "    ('context_recall', 'Context Recall (RAGAS)'),\n",
        "    ('faithfulness', 'Faithfulness (RAGAS)'),\n",
        "    ('answer_correctness', 'Answer Correctness (RAGAS)'),\n",
        "    ('answer_precision', 'Answer Precision'),\n",
        "    ('answer_recall', 'Answer Recall'),\n",
        "    \n",
        "    # Context Usage\n",
        "    ('context_word_overlap', 'Context Word Overlap'),\n",
        "    ('context_usage_ratio', 'Context Usage Ratio'),\n",
        "    ('context_based_sentences', 'Context-Based Sentences'),\n",
        "    ('context_reliance_ratio', 'Context Reliance Ratio'),\n",
        "    \n",
        "    # Answer Quality\n",
        "    ('ground_truth_similarity', 'Ground Truth Similarity'),\n",
        "    ('question_coverage', 'Question Coverage'),\n",
        "    ('specificity_ratio', 'Specificity Ratio'),\n",
        "    ('readability_score', 'Readability Score'),\n",
        "    \n",
        "    # Structure\n",
        "    ('has_introduction', 'Has Introduction (0/1)'),\n",
        "    ('has_conclusion', 'Has Conclusion (0/1)'),\n",
        "    ('has_structure', 'Has Structure (0/1)'),\n",
        "]\n",
        "\n",
        "comparison_data = {\n",
        "    'Metric': [],\n",
        "    'Baseline RAG': [],\n",
        "    'Deep Thinking RAG': [],\n",
        "    'Improvement': []\n",
        "}\n",
        "\n",
        "for metric_key, metric_name in all_metrics:\n",
        "    baseline_val = baseline_metrics.get(metric_key, 0)\n",
        "    advanced_val = advanced_metrics.get(metric_key, 0)\n",
        "    \n",
        "    # Calculate improvement\n",
        "    if isinstance(baseline_val, (int, float)) and baseline_val > 0:\n",
        "        improvement = ((advanced_val - baseline_val) / baseline_val) * 100\n",
        "        improvement_str = f\"{improvement:+.1f}%\"\n",
        "    elif isinstance(baseline_val, (int, float)) and baseline_val == 0 and advanced_val > 0:\n",
        "        improvement_str = \"∞ (from 0)\"\n",
        "    else:\n",
        "        improvement_str = \"N/A\"\n",
        "    \n",
        "    # Format values\n",
        "    if isinstance(baseline_val, float) and 0 < baseline_val < 1:\n",
        "        baseline_str = f\"{baseline_val:.3f}\"\n",
        "        advanced_str = f\"{advanced_val:.3f}\"\n",
        "    elif isinstance(baseline_val, float):\n",
        "        baseline_str = f\"{baseline_val:.1f}\"\n",
        "        advanced_str = f\"{advanced_val:.1f}\"\n",
        "    else:\n",
        "        baseline_str = str(baseline_val)\n",
        "        advanced_str = str(advanced_val)\n",
        "    \n",
        "    comparison_data['Metric'].append(metric_name)\n",
        "    comparison_data['Baseline RAG'].append(baseline_str)\n",
        "    comparison_data['Deep Thinking RAG'].append(advanced_str)\n",
        "    comparison_data['Improvement'].append(improvement_str)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY STATISTICS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate overall scores\n",
        "baseline_overall = (\n",
        "    baseline_metrics['key_terms_coverage'] * 0.2 +\n",
        "    baseline_metrics['ground_truth_similarity'] * 0.2 +\n",
        "    baseline_metrics['context_usage_ratio'] * 0.15 +\n",
        "    baseline_metrics['question_coverage'] * 0.15 +\n",
        "    baseline_metrics['context_precision'] * 0.1 +\n",
        "    baseline_metrics['context_recall'] * 0.1 +\n",
        "    baseline_metrics['faithfulness'] * 0.05 +\n",
        "    baseline_metrics['answer_correctness'] * 0.05\n",
        ") * 100\n",
        "\n",
        "advanced_overall = (\n",
        "    advanced_metrics['key_terms_coverage'] * 0.2 +\n",
        "    advanced_metrics['ground_truth_similarity'] * 0.2 +\n",
        "    advanced_metrics['context_usage_ratio'] * 0.15 +\n",
        "    advanced_metrics['question_coverage'] * 0.15 +\n",
        "    advanced_metrics['context_precision'] * 0.1 +\n",
        "    advanced_metrics['context_recall'] * 0.1 +\n",
        "    advanced_metrics['faithfulness'] * 0.05 +\n",
        "    advanced_metrics['answer_correctness'] * 0.05\n",
        ") * 100\n",
        "\n",
        "summary_data = {\n",
        "    'Metric': [\n",
        "        'Overall Score (weighted)',\n",
        "        'Key Terms Coverage',\n",
        "        'Ground Truth Similarity',\n",
        "        'Context Usage',\n",
        "        'Question Coverage',\n",
        "        'Context Precision (RAGAS)',\n",
        "        'Context Recall (RAGAS)',\n",
        "        'Faithfulness (RAGAS)',\n",
        "        'Answer Correctness (RAGAS)',\n",
        "        'Specificity',\n",
        "        'Readability'\n",
        "    ],\n",
        "    'Baseline RAG': [\n",
        "        f\"{baseline_overall:.1f}%\",\n",
        "        f\"{baseline_metrics['key_terms_coverage']:.1%}\",\n",
        "        f\"{baseline_metrics['ground_truth_similarity']:.1%}\",\n",
        "        f\"{baseline_metrics['context_usage_ratio']:.1%}\",\n",
        "        f\"{baseline_metrics['question_coverage']:.1%}\",\n",
        "        f\"{baseline_metrics['context_precision']:.3f}\",\n",
        "        f\"{baseline_metrics['context_recall']:.3f}\",\n",
        "        f\"{baseline_metrics['faithfulness']:.3f}\",\n",
        "        f\"{baseline_metrics['answer_correctness']:.3f}\",\n",
        "        f\"{baseline_metrics['specificity_ratio']:.2f}\",\n",
        "        f\"{baseline_metrics['readability_score']:.1f}\"\n",
        "    ],\n",
        "    'Deep Thinking RAG': [\n",
        "        f\"{advanced_overall:.1f}%\",\n",
        "        f\"{advanced_metrics['key_terms_coverage']:.1%}\",\n",
        "        f\"{advanced_metrics['ground_truth_similarity']:.1%}\",\n",
        "        f\"{advanced_metrics['context_usage_ratio']:.1%}\",\n",
        "        f\"{advanced_metrics['question_coverage']:.1%}\",\n",
        "        f\"{advanced_metrics['context_precision']:.3f}\",\n",
        "        f\"{advanced_metrics['context_recall']:.3f}\",\n",
        "        f\"{advanced_metrics['faithfulness']:.3f}\",\n",
        "        f\"{advanced_metrics['answer_correctness']:.3f}\",\n",
        "        f\"{advanced_metrics['specificity_ratio']:.2f}\",\n",
        "        f\"{advanced_metrics['readability_score']:.1f}\"\n",
        "    ],\n",
        "    'Improvement': [\n",
        "        f\"{((advanced_overall - baseline_overall) / baseline_overall * 100):+.1f}%\" if baseline_overall > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['key_terms_coverage'] - baseline_metrics['key_terms_coverage']) / baseline_metrics['key_terms_coverage'] * 100):+.1f}%\" if baseline_metrics['key_terms_coverage'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['ground_truth_similarity'] - baseline_metrics['ground_truth_similarity']) / baseline_metrics['ground_truth_similarity'] * 100):+.1f}%\" if baseline_metrics['ground_truth_similarity'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['context_usage_ratio'] - baseline_metrics['context_usage_ratio']) / baseline_metrics['context_usage_ratio'] * 100):+.1f}%\" if baseline_metrics['context_usage_ratio'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['question_coverage'] - baseline_metrics['question_coverage']) / baseline_metrics['question_coverage'] * 100):+.1f}%\" if baseline_metrics['question_coverage'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['context_precision'] - baseline_metrics['context_precision']) / baseline_metrics['context_precision'] * 100):+.1f}%\" if baseline_metrics['context_precision'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['context_recall'] - baseline_metrics['context_recall']) / baseline_metrics['context_recall'] * 100):+.1f}%\" if baseline_metrics['context_recall'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['faithfulness'] - baseline_metrics['faithfulness']) / baseline_metrics['faithfulness'] * 100):+.1f}%\" if baseline_metrics['faithfulness'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['answer_correctness'] - baseline_metrics['answer_correctness']) / baseline_metrics['answer_correctness'] * 100):+.1f}%\" if baseline_metrics['answer_correctness'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['specificity_ratio'] - baseline_metrics['specificity_ratio']) / baseline_metrics['specificity_ratio'] * 100):+.1f}%\" if baseline_metrics['specificity_ratio'] > 0 else \"N/A\",\n",
        "        f\"{((advanced_metrics['readability_score'] - baseline_metrics['readability_score']) / baseline_metrics['readability_score'] * 100):+.1f}%\" if baseline_metrics['readability_score'] > 0 else \"N/A\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + summary_df.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# KEY FINDINGS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY FINDINGS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "findings = []\n",
        "if advanced_overall > baseline_overall:\n",
        "    findings.append(f\"✓ Deep Thinking RAG shows {((advanced_overall - baseline_overall) / baseline_overall * 100):.1f}% improvement in overall score\")\n",
        "else:\n",
        "    findings.append(f\"⚠ Deep Thinking RAG shows {((advanced_overall - baseline_overall) / baseline_overall * 100):.1f}% change in overall score\")\n",
        "\n",
        "if advanced_metrics['key_terms_found'] > baseline_metrics['key_terms_found']:\n",
        "    findings.append(f\"✓ Deep Thinking RAG covers {advanced_metrics['key_terms_found'] - baseline_metrics['key_terms_found']} more key terms\")\n",
        "\n",
        "if advanced_metrics['context_precision'] > baseline_metrics['context_precision']:\n",
        "    findings.append(f\"✓ Context Precision improved: {baseline_metrics['context_precision']:.3f} → {advanced_metrics['context_precision']:.3f}\")\n",
        "\n",
        "if advanced_metrics['context_recall'] > baseline_metrics['context_recall']:\n",
        "    findings.append(f\"✓ Context Recall improved: {baseline_metrics['context_recall']:.3f} → {advanced_metrics['context_recall']:.3f}\")\n",
        "\n",
        "if advanced_metrics['faithfulness'] > baseline_metrics['faithfulness']:\n",
        "    findings.append(f\"✓ Faithfulness improved: {baseline_metrics['faithfulness']:.3f} → {advanced_metrics['faithfulness']:.3f} (less hallucination)\")\n",
        "\n",
        "if advanced_metrics['answer_correctness'] > baseline_metrics['answer_correctness']:\n",
        "    findings.append(f\"✓ Answer Correctness improved: {baseline_metrics['answer_correctness']:.3f} → {advanced_metrics['answer_correctness']:.3f}\")\n",
        "\n",
        "if advanced_metrics['numerical_data_points'] > baseline_metrics['numerical_data_points']:\n",
        "    findings.append(f\"✓ Deep Thinking RAG includes {advanced_metrics['numerical_data_points'] - baseline_metrics['numerical_data_points']} more numerical data points\")\n",
        "\n",
        "if advanced_metrics['context_usage_ratio'] > baseline_metrics['context_usage_ratio']:\n",
        "    findings.append(f\"✓ Deep Thinking RAG uses context more effectively ({advanced_metrics['context_usage_ratio']:.1%} vs {baseline_metrics['context_usage_ratio']:.1%})\")\n",
        "\n",
        "for finding in findings:\n",
        "    print(f\"  {finding}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a08e428d",
      "metadata": {
        "id": "a08e428d"
      },
      "source": [
        "### Restart Runtime\n",
        "\n",
        "**IMPORTANT:** Please restart your Colab runtime now (`Runtime > Restart runtime...`).\n",
        "\n",
        "After the runtime has restarted, you **must** re-run **all** setup cells from the very beginning of the notebook (`part1-2-code-pro` onwards) up to `part6-4-code-impl-pro-adv` to ensure all components are re-initialized with the correct `ragas` environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "58b7823d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58b7823d",
        "outputId": "001e4286-6793-49d4-b49d-6143ae88ddf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!pip show ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part6-5-interpret-pro-adv",
      "metadata": {
        "id": "part6-5-interpret-pro-adv"
      },
      "source": [
        "### 6.3. Interpreting the Evaluation Scores for Our Advanced Pipeline\n",
        "\n",
        "The quantitative results provide a definitive verdict on the superiority of the Deep Thinking architecture:\n",
        "\n",
        "-   **Context Precision (0.50 vs 1.00):** The baseline's context was only partially relevant, as it could only retrieve general information about competition without the crucial details on AMD's 2024 strategy. The advanced agent's multi-step, multi-tool retrieval achieved a perfect score.\n",
        "-   **Context Recall (0.33 vs 1.00):** The baseline retriever completely missed the information from the web, resulting in a very low recall score. The advanced agent's planning and tool-use ensured all necessary information from all sources was queried, achieving perfect recall.\n",
        "-   **Faithfulness (1.00 vs 1.00):** Both systems were highly faithful to the context they were given. The baseline correctly stated it didn't have the information, and the advanced agent correctly used the information it found.\n",
        "-   **Answer Correctness (0.40 vs 0.99):** This is the ultimate measure of quality. The baseline's answer was less than 40% correct because it was missing the entire second half of the required analysis. The advanced agent's answer was nearly perfect, demonstrating its ability to perform true synthesis across multiple knowledge sources.\n",
        "\n",
        "**Conclusion:** The evaluation provides objective, quantitative proof that the architectural shift to a cyclical, tool-aware, and adaptive reasoning agent results in a dramatic and measurable improvement in performance on complex, real-world queries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part7-intro-prod-pro",
      "metadata": {
        "id": "part7-intro-prod-pro"
      },
      "source": [
        "## Part 7: Optimizations and Production Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part7-1-cache-pro",
      "metadata": {
        "id": "part7-1-cache-pro"
      },
      "source": [
        "### 7.1. Optimization 1: Implementing a Cache for Repeated Sub-Queries\n",
        "\n",
        "Our agent makes multiple calls to expensive LLMs (Planner, Rewriter, etc.). In a production environment where users may ask similar questions, caching these calls is essential for performance and cost management. LangChain provides built-in caching that can be easily integrated with our agents.\n",
        "\n",
        "```python\n",
        "from langchain.globals import set_llm_cache\n",
        "from langchain.cache import InMemoryCache\n",
        "\n",
        "# To enable caching for all LLM calls in the session\n",
        "set_llm_cache(InMemoryCache())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part7-2-provenance-pro",
      "metadata": {
        "id": "part7-2-provenance-pro"
      },
      "source": [
        "### 7.2. Feature 1: Provenance and Citations - Building User Trust\n",
        "\n",
        "Users need to trust the answers our agent provides. A critical feature for production is **provenance**. We have implemented this in our `final_answer_node`. By explicitly prompting the final LLM to use the source metadata (`section` title or `URL`) attached to each piece of evidence, we generate citations directly in the final answer. This makes the agent's reasoning transparent and verifiable across all its knowledge sources."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part7-3-discussion-pro",
      "metadata": {
        "id": "part7-3-discussion-pro"
      },
      "source": [
        "### 7.3. Discussion: The Next Level - MDPs and Learned Policies (The DeepRAG Paper)\n",
        "\n",
        "Currently, our Policy and Supervisor Agents use a powerful, general-purpose LLM to make decisions. While highly effective, this can be slow and costly. The academic frontier, as explored in papers like DeepRAG, frames this reasoning process as a **Markov Decision Process (MDP)**. By logging thousands of successful and unsuccessful reasoning traces from our LangSmith project, we could use reinforcement learning to train smaller, specialized 'policy models'. A learned policy could make the `CONTINUE`/`FINISH` decision or the `vector`/`keyword` decision much faster and more cheaply than a full GPT-4o call, while being highly optimized for our specific domain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part7-4-failure-pro",
      "metadata": {
        "id": "part7-4-failure-pro"
      },
      "source": [
        "### 7.4. Handling Failure: Graceful Exits and Fallbacks When No Answer is Found\n",
        "\n",
        "A production system must be robust to failure. What if a sub-question yields no relevant documents? Our current agent simply logs this and moves on. A more advanced implementation would involve:\n",
        "1.  **Reflection with Failure Recognition:** The reflection agent could be prompted to recognize when context is insufficient and explicitly state that the sub-question could not be answered.\n",
        "2.  **`REVISE_PLAN` Path:** The policy agent could have a third option, `REVISE_PLAN`. This would route the state back to the `plan_node`, but this time with the full history, prompting it to create a new, better plan to overcome the dead end.\n",
        "3.  **Graceful Exit:** If re-planning also fails, the graph should route to a final `no_answer_node` that explicitly informs the user that a confident answer could not be constructed from the available documents."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part8-conclusion-pro",
      "metadata": {
        "id": "part8-conclusion-pro"
      },
      "source": [
        "## Part 8: Conclusion and Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part8-1-summary-pro-adv",
      "metadata": {
        "id": "part8-1-summary-pro-adv"
      },
      "source": [
        "### 8.1. Summary of Our Journey\n",
        "\n",
        "In this notebook, we have undertaken a complete journey from a rudimentary RAG pipeline to a sophisticated autonomous reasoning agent. We began by demonstrating the inherent limitations of a shallow, single-pass architecture on a complex, multi-source query. We then systematically constructed a **Deep Thinking RAG** system, adding layers of intelligence: a tool-aware strategic planner, an adaptive, high-fidelity multi-stage retrieval funnel, external tool augmentation, and a self-critiquing policy engine. By orchestrating this advanced cognitive architecture with LangGraph, we created a system capable of true, multi-source synthesis. Our final, rigorous evaluation with RAGAs provided objective, quantitative proof of its dramatic superiority over the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part8-2-principles-pro-adv",
      "metadata": {
        "id": "part8-2-principles-pro-adv"
      },
      "source": [
        "### 8.2. Key Architectural Principles of Advanced RAG Systems\n",
        "\n",
        "1.  **Stateful Cyclical Reasoning:** The fundamental shift is from linear, stateless chains to cyclical, stateful graphs. Intelligence emerges from the ability to iterate, reflect, and refine.\n",
        "2.  **Decomposition is King:** Complex problems must be broken down. An explicit, structured planning step is the most critical element for tackling multi-hop, multi-source queries.\n",
        "3.  **Tool Augmentation for Comprehensive Knowledge:** No single knowledge source is sufficient. Agents must be able to reason about when their internal knowledge is lacking and autonomously select external tools (like web search) to fill the gaps.\n",
        "4.  **Dynamic Strategy Selection:** Rigidity is fragile. Empowering the agent to dynamically adapt its strategies (e.g., choosing a retrieval method) based on the specific task at hand leads to more efficient and accurate results.\n",
        "5.  **Separation of Recall and Precision:** Retrieval is not a single step. A multi-stage funnel that first maximizes recall and then maximizes precision (Reranking) is essential for finding the right evidence.\n",
        "6.  **Explicit Self-Correction:** A dedicated policy or 'judge' component that inspects progress and controls the loop is the key to autonomy and robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "part8-3-future-pro-adv",
      "metadata": {
        "id": "part8-3-future-pro-adv"
      },
      "source": [
        "### 8.3. Future Directions and Further Reading\n",
        "\n",
        "This architecture serves as a powerful and extensible template. Future work could include:\n",
        "-   **Multi-Document Analysis:** Extending the agent to answer questions that require synthesizing information across a *corpus* of documents, not just a single one, by adding a preliminary 'document routing' step.\n",
        "-   **Structured Tool Use:** Empowering the agent with tools to query structured databases (e.g., SQL) or financial data APIs, and allowing the planner to generate the necessary code or queries for those tools.\n",
        "-   **Fine-Tuning a Supervisor Model:** Training a smaller, specialized SLM on traces from LangSmith to perform the Retrieval Supervisor's role, leading to significant cost and latency reductions in production."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56229fd9",
      "metadata": {
        "id": "56229fd9"
      },
      "source": [
        "# Task\n",
        "Execute cell `part4-2-code-pro-adv`, then cell `part4-3-build-pro-adv`, and finally cell `part4-4-viz-pro-adv`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "762c4cd8",
      "metadata": {
        "id": "762c4cd8"
      },
      "source": [
        "## run_part4-2-code-pro-adv\n",
        "\n",
        "### Subtask:\n",
        "Execute cell `part4-2-code-pro-adv` to define the conditional edge logic functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c6ee59",
      "metadata": {
        "id": "75c6ee59"
      },
      "source": [
        "**Reasoning**:\n",
        "The user explicitly asked to execute the cell `part4-2-code-pro-adv` to define the conditional edge logic functions. I will provide the content of this cell in a code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b60a256",
      "metadata": {
        "id": "2b60a256"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the conditional edge logic functions are defined, the next step is to execute cell `part4-3-build-pro-adv` to build the `StateGraph` as per the main task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31a5a1f",
      "metadata": {
        "id": "d31a5a1f"
      },
      "source": [
        "**Reasoning**:\n",
        "The StateGraph has been successfully constructed. The next step, as per the main task, is to compile the graph and attempt to visualize it by executing cell `part4-4-viz-pro-adv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e4a3eb4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4a3eb4b",
        "outputId": "8842d699-6bec-4141-dd41-e62be9718a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph compiled successfully.\n",
            "Graph visualization failed: Install pygraphviz to draw graphs: `pip install pygraphviz`.. Please ensure pygraphviz is installed.\n"
          ]
        }
      ],
      "source": [
        "deep_thinking_rag_graph = graph.compile()\n",
        "print(\"Graph compiled successfully.\")\n",
        "\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    # Correctly call get_graph() before draw_png()\n",
        "    png_image = deep_thinking_rag_graph.get_graph().draw_png()\n",
        "    display(Image(png_image))\n",
        "except Exception as e:\n",
        "    print(f\"Graph visualization failed: {e}. Please ensure pygraphviz is installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a458a67",
      "metadata": {
        "id": "6a458a67"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Conditional Edge Logic Functions Defined**: Two critical conditional edge logic functions, `route_by_tool` and `should_continue_node`, were successfully defined for dynamic graph routing and iteration control.\n",
        "*   **StateGraph Constructed**: The RAG process's `StateGraph` was successfully built, incorporating nodes for planning, retrieval (10k and web), reranking, compression, reflection, and final answer generation, along with a `choose_next_tool` routing point. Edges, both direct and conditional, were established to manage the flow between these nodes.\n",
        "*   **Graph Compilation Successful**: The constructed `StateGraph` was successfully compiled into `deep_thinking_rag_graph`, making it ready for execution.\n",
        "*   **Graph Visualization Failed**: While the graph compiled successfully, its visualization failed due to the absence of the `pygraphviz` library, which is required for rendering the graph diagram.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   To fully understand and debug the flow of the RAG graph, install `pygraphviz` to enable graph visualization.\n",
        "*   The RAG graph is now fully constructed and compiled, ready for execution with a question input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "611fe3ad",
      "metadata": {
        "id": "611fe3ad"
      },
      "source": [
        "# Task\n",
        "Modify cell `part6-4-code-impl-pro-adv` to re-add the import for `RunConfig` and pass `RunConfig()` to the `RagasCompatibleHuggingFaceBgeEmbeddings` constructor to resolve the `ValidationError`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb05aed8",
      "metadata": {
        "id": "fb05aed8"
      },
      "source": [
        "## modify_part6-4-code-impl-pro-adv\n",
        "\n",
        "### Subtask:\n",
        "Re-add the import for RunConfig and pass it to the RagasCompatibleHuggingFaceBgeEmbeddings constructor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a61b065",
      "metadata": {
        "id": "7a61b065"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A `ValidationError` was encountered when initializing `RagasCompatibleHuggingFaceBgeEmbeddings`.\n",
        "*   The resolution involved re-importing `RunConfig` and passing `RunConfig()` as an argument to the `RagasCompatibleHuggingFaceBgeEmbeddings` constructor.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Ensure all necessary imports are present and correctly passed as arguments, especially when dealing with complex object initializations to avoid `ValidationError`s.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01be783453cb4846bc89701fa63453af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c43594c6bd4f27a5d3480216a44ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "024a9c42d31347c9919f3f482c24e368": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02938a029ab9430d8a848b4cc2064519": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03e2cdfab9545828697f3088252e905",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0747656060c4d04a6aa38bf978687e1",
            "value": 743
          }
        },
        "0422649470ed49e7b9557dd4253eadb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04571cada714422c91a9326c7c936854": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63280d99da094e7d8ff8ab8939cf9aef",
            "placeholder": "​",
            "style": "IPY_MODEL_fa699e5c27dd447db656fb1db4dca001",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "0473d30020804414bb18c2346425894d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d1172f5fc5c478cbdbb168888a8b1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d3304af69834c3e8268d0a19ead1a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d4c1b13b3ec426db4b47beec10670b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115e7789a1c04c388eed27ad6431afe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11ff6f0a3c704d618f0c1cd216b796d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129597a76a7d419c9b444e5eeb40467b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "129811a2736c473f8f5792614e2a5eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e226c5557b4fa1bbedd563df2edbcc",
            "placeholder": "​",
            "style": "IPY_MODEL_c781a0c2ec524fd897f24c336bcb8bfb",
            "value": "model.safetensors: 100%"
          }
        },
        "1316e9e2e9b14aefbc03b4e497990658": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134ea9e644d94c9e8cd1d57333852923": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "157638698cd14f5f9654e8ff506f64b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175d85418f6c46f8aa10408e78eff346": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17931a6e1b6a4ff6b157a2c7467b9a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18d761044ac347b7910d99da20a18380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc149187eb94c6ab02b2bb688895acb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1caa66a89fcd47ceb29b0e83f50ff725": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbe22838b6c4e97acff7b35429cbc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff34a9f56ab4865b3aff98e8e83bea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26099d0292d640539be65aa77fcb2321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278b4fdc98ff42cdb670ac512a3b6e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8420154d5e483b913e9f3b7a4e14dd",
            "placeholder": "​",
            "style": "IPY_MODEL_0d1172f5fc5c478cbdbb168888a8b1cf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "29d2ee7037ce4fcebaace5953afddb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a6edb2dee4a4fd094c39841dc64a095": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2acd8fa4302a454db864c9aed5858456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c964ebf43144ecfad1f445da0c77d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d23157cd4ce4db48808ac9872224845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f07aef43fc84fffb1eba45bf3d1c9ce",
              "IPY_MODEL_58c12ba8fadb47eca8c5ab9a3199d3b0",
              "IPY_MODEL_8bd5479d817642e8b71490da5c1a8c03"
            ],
            "layout": "IPY_MODEL_663957a430fa421cb01567055235fdf3"
          }
        },
        "2f07aef43fc84fffb1eba45bf3d1c9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1fb6c3002e54e54aecc0a41990655e4",
            "placeholder": "​",
            "style": "IPY_MODEL_29d2ee7037ce4fcebaace5953afddb23",
            "value": "config.json: 100%"
          }
        },
        "2fa03023ccb34a08b7c5e8610cfda8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63496ad0475d47ce804c32e9d59ac97e",
              "IPY_MODEL_a06f2c0a708748b5a15c8d8a387cc1cd",
              "IPY_MODEL_42c8e92da89548088144506467b64a92"
            ],
            "layout": "IPY_MODEL_fa254953ce2b44e1b3b4dc54725099d6"
          }
        },
        "2ff9d71c41824519b104d0b55dab3d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1957061d51d4250b7e416f2266ea1c8",
            "placeholder": "​",
            "style": "IPY_MODEL_7879c05fcd8a43fd9e1fdc80be7add9a",
            "value": " 52.0/52.0 [00:00&lt;00:00, 918B/s]"
          }
        },
        "30271ed7d4cb4c8784e4a21e8501ca8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa38683265344c33833bed6a5b5b74ec",
              "IPY_MODEL_820d45c64aef405e877f84710fff37d3",
              "IPY_MODEL_c934d35cc81041de9de8294aedaef29e"
            ],
            "layout": "IPY_MODEL_b74af6f60e374e61a1205aa306954b5f"
          }
        },
        "32f3f43aecd74dce9cae87e234f81040": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333e9d45467040ceb652851f477fcc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847b23a36b584711bfe94d232ec4682d",
            "placeholder": "​",
            "style": "IPY_MODEL_591c2425aa8c4bf38c3e86b4dbf39c49",
            "value": "README.md: "
          }
        },
        "3399c110df2e456f8e99074160d0df93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_838d6734539040a4a90813c528dd7d9a",
              "IPY_MODEL_02938a029ab9430d8a848b4cc2064519",
              "IPY_MODEL_bdf77c79187842c688a320129efb8f20"
            ],
            "layout": "IPY_MODEL_1bc149187eb94c6ab02b2bb688895acb"
          }
        },
        "350210c421d54355b1147dab0a764ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36966127998f4b0d936e8e9c9469b20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8c9d84fb654cb0b42dbdda35fe19c5",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8b1891f74ba47339d26a44bb3ca81bd",
            "value": 133466304
          }
        },
        "3778dbc947094e1181554937ebd8c62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e3c21573a84343ac6ecb9f1deda914",
            "placeholder": "​",
            "style": "IPY_MODEL_cd671fd928d24292bcc0091929796d35",
            "value": " 711k/? [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "3787f1a3486e4e1d9684c1735b5a83d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f37c2ef94b7c4471ac5d88c439d57c29",
              "IPY_MODEL_5e4cdaf98a644710a2b52b6750ca80a1",
              "IPY_MODEL_5e61e7626bc8423facc4e39adf9bbd8e"
            ],
            "layout": "IPY_MODEL_8bcc30595a2646cdb46250accb82ecaf"
          }
        },
        "38da0df867994120b261b11b49edeeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d23ad664db46dd8e0a7f36385bda3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5856b69826b9450d97a1a5fb56ac7a35",
              "IPY_MODEL_c5b916b553664de2906e90bc9a303dc1",
              "IPY_MODEL_9c562baea6b0417d8f7b25bc351ede8f"
            ],
            "layout": "IPY_MODEL_d31fcf233c0c4f9db432d3b1a1173f7f"
          }
        },
        "3b47fd2ca2ee4932a50ae03dcbef18a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dcf0e83926c476993223317afdaa84f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eee5f3bbaf14eadab13589ac94039af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f8c1329c9f74767b946b942e3254392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56d8ca84d9e439d99e7cd504faf49a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe420ced4fcd49fba88914134dca37f1",
            "value": 1
          }
        },
        "413298a91dba45cb9aee06b5d9744dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42068f42b5ca4fa7bab7aab80abd377a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7e97f93237424190e344e3474767d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_129597a76a7d419c9b444e5eeb40467b",
            "value": 1
          }
        },
        "42c8e92da89548088144506467b64a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbd84082ea840d1ad83270601c9022e",
            "placeholder": "​",
            "style": "IPY_MODEL_e11661d1dce24af695fb8c92a91de7e0",
            "value": " 132/132 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "439df160977c4376a4e7b9008f4e5c45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e725a6640e4ad69da5786f4a50cf39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45692e9d397544c3844ceb465acb5677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479f0d8d39d747308264dba917656217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3b7abec0e545d1bd0f237fa631550f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f494d9a290714a67ac81f9b4214e122f",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4de99c0d1aa49029a3a2e93e3c361d3",
            "value": 52
          }
        },
        "4be84eec4e074e2692d9973bf035f983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bed465460ce409baffc227a3a381f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_752a66111b0b48f4ad2bd022def2ac3b",
              "IPY_MODEL_e9167b7f45714d019ea9df780b5ff982",
              "IPY_MODEL_6659da1f90f34a33a1280b29e99be124"
            ],
            "layout": "IPY_MODEL_bda183142f1846bbb71962651634641f"
          }
        },
        "4eb3c019e2f746daac8bc4e5164da4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4fa45a8fbde844f28b0191aa97892e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "504afb32726b4678bc91376659170b78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518847d2fc114e08bf4e9583ae9cbc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "540309d0f7a343068b82836e032b4236": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5683517580b14d6c9e4dc594d1f4f682": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d20392c7947e4911960ebe1cbc17540d",
              "IPY_MODEL_42068f42b5ca4fa7bab7aab80abd377a",
              "IPY_MODEL_77b63ca1007b4b7090e88eddd5a3cf47"
            ],
            "layout": "IPY_MODEL_0422649470ed49e7b9557dd4253eadb4"
          }
        },
        "56abcbeef18d4163b41b5cd774798a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5856b69826b9450d97a1a5fb56ac7a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2be5c93c2a742eaa89c621dbcb33ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_d982a0ef48134faa9a2e6ebe01ce9f50",
            "value": "README.md: "
          }
        },
        "58be876de60143f4a98444ea61247dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58c12ba8fadb47eca8c5ab9a3199d3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a53fb4d83c481b927691986d20844b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d3304af69834c3e8268d0a19ead1a86",
            "value": 190
          }
        },
        "58de3427f73a4cadb0a990c1f4586f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "591c2425aa8c4bf38c3e86b4dbf39c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c8c9d84fb654cb0b42dbdda35fe19c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d2534658e844d26becdc77b98599cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dacc5ca9dc145a59d7b28ab1ced3943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e0f038825184ddf8791da9dd55d26b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4cdaf98a644710a2b52b6750ca80a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e448eac9817c4fe4baf175009d7e8c3d",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd44f69fdb59429db70e4a50afe99d23",
            "value": 349
          }
        },
        "5e61e7626bc8423facc4e39adf9bbd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50e4839d6ca40528c0c804d2e1b65f9",
            "placeholder": "​",
            "style": "IPY_MODEL_45692e9d397544c3844ceb465acb5677",
            "value": " 349/349 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "5e82dd89cff346d2ba16ee91e8cf71e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fad01f22b484cd584442f1946e1f8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609dc5290a6e4d09aab88b06bc08ea14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63280d99da094e7d8ff8ab8939cf9aef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63496ad0475d47ce804c32e9d59ac97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175d85418f6c46f8aa10408e78eff346",
            "placeholder": "​",
            "style": "IPY_MODEL_ba655a3ab2fa4f35ae0988def09a85e0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "656d63ac472749fdb6802677d2ef3684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e81fdafc5c5c443f93b3aef1f8cc490c",
            "placeholder": "​",
            "style": "IPY_MODEL_58be876de60143f4a98444ea61247dd3",
            "value": " 124/124 [00:00&lt;00:00, 5.15kB/s]"
          }
        },
        "65c033f377714e5a81a8178b4121f9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_669e42203560435db2962790387673f6",
              "IPY_MODEL_df98353095ae4e2295ef4cc5ad9253a5",
              "IPY_MODEL_7120dba3bbde40359702841bb0e30059"
            ],
            "layout": "IPY_MODEL_024a9c42d31347c9919f3f482c24e368"
          }
        },
        "66316808d94f45adb8842f20b2555c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663957a430fa421cb01567055235fdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665277e22a72446980425172c8ed4fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6659da1f90f34a33a1280b29e99be124": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eee5f3bbaf14eadab13589ac94039af",
            "placeholder": "​",
            "style": "IPY_MODEL_93fbf639cf9b49deabf4b81f06f6001e",
            "value": " 8/8 [00:27&lt;00:00,  4.49s/it]"
          }
        },
        "669e42203560435db2962790387673f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e725a6640e4ad69da5786f4a50cf39",
            "placeholder": "​",
            "style": "IPY_MODEL_d187c12c60224281809fc378c55b2e2e",
            "value": "tokenizer_config.json: "
          }
        },
        "69224cfb3bad4fe69b1eeec23671827c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69491ca4e8e142508a845408e88fd3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69527922f7ef4b26929dd2b58ede351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69876fde64b54b64a8651f49d28760d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c713b9da04e493fab7aa1accc4c52ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8baaa930542b4f5e83cc5d9b4cd5edbf",
              "IPY_MODEL_a3cdbcdebf3c42498a70254e80e44ae4",
              "IPY_MODEL_7fd57b19bbb64023b598d8a667072054"
            ],
            "layout": "IPY_MODEL_609dc5290a6e4d09aab88b06bc08ea14"
          }
        },
        "6ec3b4d3b69f4ed3b16d72a873f4eeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8dcf5cda3dd406aa2a5221c97675a09",
              "IPY_MODEL_aa9070e0093040749e334438b5bc92ae",
              "IPY_MODEL_a25ca01b1a9d4364b0021f1ba4718c21"
            ],
            "layout": "IPY_MODEL_350210c421d54355b1147dab0a764ccb"
          }
        },
        "703a94e7e3644809a5a849346be762eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7120dba3bbde40359702841bb0e30059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780d4e532e4d40faa2288a36fba29a35",
            "placeholder": "​",
            "style": "IPY_MODEL_c2eb23b29c1b466588c68ac38b1d5a6a",
            "value": " 1.33k/? [00:00&lt;00:00, 105kB/s]"
          }
        },
        "71726d43b8d24e3494ade9f096510a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752a66111b0b48f4ad2bd022def2ac3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac5acf3e76d461190857b8ee617360b",
            "placeholder": "​",
            "style": "IPY_MODEL_87e90c8ccd164f30926d196575f387a6",
            "value": "Evaluating: 100%"
          }
        },
        "77b63ca1007b4b7090e88eddd5a3cf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504afb32726b4678bc91376659170b78",
            "placeholder": "​",
            "style": "IPY_MODEL_a0fba7d36d9841ba8db3b2f4e7437e20",
            "value": " 711k/? [00:00&lt;00:00, 1.83MB/s]"
          }
        },
        "780d4e532e4d40faa2288a36fba29a35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7879c05fcd8a43fd9e1fdc80be7add9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78fa54a532934e09b6286cf24b5dfa19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7afed18023644c08814a721311463ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95b9207f1b448f5b3f43256f71b1a75",
            "placeholder": "​",
            "style": "IPY_MODEL_5fad01f22b484cd584442f1946e1f8da",
            "value": " 133M/133M [00:01&lt;00:00, 61.2MB/s]"
          }
        },
        "7d7afca7e7334a65ad66c60340a06216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e0f038825184ddf8791da9dd55d26b1",
            "placeholder": "​",
            "style": "IPY_MODEL_bb820426ae454a6aa22de5ddb2decb66",
            "value": " 232k/? [00:00&lt;00:00, 7.13MB/s]"
          }
        },
        "7e103ab49a904c09b582f887d1deee07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9528ef2fa06041a78db2dfb43db053ab",
            "max": 90870598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38da0df867994120b261b11b49edeeb9",
            "value": 90870598
          }
        },
        "7fd57b19bbb64023b598d8a667072054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665277e22a72446980425172c8ed4fdb",
            "placeholder": "​",
            "style": "IPY_MODEL_3b47fd2ca2ee4932a50ae03dcbef18a5",
            "value": " 125/125 [00:00&lt;00:00, 2.39kB/s]"
          }
        },
        "7ff946aa385a4c3686e64ef3a25c6ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820d45c64aef405e877f84710fff37d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b18fa14e16cc43b683412f7d789e490d",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dacc5ca9dc145a59d7b28ab1ced3943",
            "value": 794
          }
        },
        "838d6734539040a4a90813c528dd7d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d3b5db870fe4981a9eef170d54278d2",
            "placeholder": "​",
            "style": "IPY_MODEL_0d4c1b13b3ec426db4b47beec10670b5",
            "value": "config.json: 100%"
          }
        },
        "847b23a36b584711bfe94d232ec4682d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e90c8ccd164f30926d196575f387a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8baaa930542b4f5e83cc5d9b4cd5edbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9d06436c3640acba5010e9e637c67c",
            "placeholder": "​",
            "style": "IPY_MODEL_4fa45a8fbde844f28b0191aa97892e9f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8bcc30595a2646cdb46250accb82ecaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd5479d817642e8b71490da5c1a8c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_540309d0f7a343068b82836e032b4236",
            "placeholder": "​",
            "style": "IPY_MODEL_aa318d218c734e039c4b096ac7fc1c1a",
            "value": " 190/190 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "8d3b5db870fe4981a9eef170d54278d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb9ecd12ede4859addf1e600108d36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1316e9e2e9b14aefbc03b4e497990658",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bf4007387b24b03a64edaa8130f63cc",
            "value": 366
          }
        },
        "900dbc61cd014778b536739d06e99853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93e96fd552b4416e82bf7b24bb6ed58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1caa66a89fcd47ceb29b0e83f50ff725",
            "placeholder": "​",
            "style": "IPY_MODEL_518847d2fc114e08bf4e9583ae9cbc56",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "93fbf639cf9b49deabf4b81f06f6001e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94a79854e97040df8d68255c9b24d812": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9528ef2fa06041a78db2dfb43db053ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f05514ab6241c199aae2ba0214b04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_333e9d45467040ceb652851f477fcc26",
              "IPY_MODEL_bd7127eaadcb4df0a7f64bc4905bb9b7",
              "IPY_MODEL_9d15fdcad7e149e8a0cefa35279576d0"
            ],
            "layout": "IPY_MODEL_157638698cd14f5f9654e8ff506f64b8"
          }
        },
        "9acccc0015764220ab99395679080319": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9b7b3a7f4cbb4dde950f3bc7a73e5cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf4007387b24b03a64edaa8130f63cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c33feb267ae454791c2d3a60657e304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1df53c2d1944f8db242e04b81b4a763",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69527922f7ef4b26929dd2b58ede351c",
            "value": 1
          }
        },
        "9c562baea6b0417d8f7b25bc351ede8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21e2030a0a0449abcb0a2f1fbd0e271",
            "placeholder": "​",
            "style": "IPY_MODEL_4be84eec4e074e2692d9973bf035f983",
            "value": " 3.67k/? [00:00&lt;00:00, 232kB/s]"
          }
        },
        "9d15fdcad7e149e8a0cefa35279576d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd83d84bb282404a81107ac210d40b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_69876fde64b54b64a8651f49d28760d0",
            "value": " 94.8k/? [00:00&lt;00:00, 1.03MB/s]"
          }
        },
        "9f4a22e27d5c44c7b21e0f8cfad710d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03e2cdfab9545828697f3088252e905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06f2c0a708748b5a15c8d8a387cc1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcaf2c0464b2448f9f0883bd32f19741",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d2534658e844d26becdc77b98599cc9",
            "value": 132
          }
        },
        "a0fba7d36d9841ba8db3b2f4e7437e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a25ca01b1a9d4364b0021f1ba4718c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479f0d8d39d747308264dba917656217",
            "placeholder": "​",
            "style": "IPY_MODEL_e72b748edd3e4cc497ceddfa573598d4",
            "value": " 232k/? [00:00&lt;00:00, 4.15MB/s]"
          }
        },
        "a2be5c93c2a742eaa89c621dbcb33ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3cdbcdebf3c42498a70254e80e44ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2cf71c20d6043ccb55e61b8aac21846",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0473d30020804414bb18c2346425894d",
            "value": 125
          }
        },
        "a4de99c0d1aa49029a3a2e93e3c361d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5e226c5557b4fa1bbedd563df2edbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7cd00e35e23451796d7f4be353ab714": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e3c21573a84343ac6ecb9f1deda914": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa318d218c734e039c4b096ac7fc1c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa9070e0093040749e334438b5bc92ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69491ca4e8e142508a845408e88fd3c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01c43594c6bd4f27a5d3480216a44ec6",
            "value": 1
          }
        },
        "aabee24f843b488c85c1410e035a8e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aac5acf3e76d461190857b8ee617360b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0ed0de9851475285eaafa2be37a8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_278b4fdc98ff42cdb670ac512a3b6e92",
              "IPY_MODEL_8fb9ecd12ede4859addf1e600108d36d",
              "IPY_MODEL_ef32ffea621048e7ae0f0874df6c1428"
            ],
            "layout": "IPY_MODEL_e1d8f1ef65964eedb4e43565d08efed9"
          }
        },
        "ad1aa52287854440a527c6bca383b311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aefceb78ed014e16a946ca100dc270e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b155d390f25f4cbb82f7a23466df45e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93e96fd552b4416e82bf7b24bb6ed58e",
              "IPY_MODEL_c0fd41db72624b5c979ccb1b255d1c17",
              "IPY_MODEL_656d63ac472749fdb6802677d2ef3684"
            ],
            "layout": "IPY_MODEL_78fa54a532934e09b6286cf24b5dfa19"
          }
        },
        "b18fa14e16cc43b683412f7d789e490d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1957061d51d4250b7e416f2266ea1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74af6f60e374e61a1205aa306954b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba655a3ab2fa4f35ae0988def09a85e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba7e97f93237424190e344e3474767d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "baa0ca00ac8f4f1b896891afa56769d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fbe22838b6c4e97acff7b35429cbc8b",
            "placeholder": "​",
            "style": "IPY_MODEL_aefceb78ed014e16a946ca100dc270e8",
            "value": "model.safetensors: 100%"
          }
        },
        "bb820426ae454a6aa22de5ddb2decb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcaf2c0464b2448f9f0883bd32f19741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7127eaadcb4df0a7f64bc4905bb9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9acccc0015764220ab99395679080319",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17931a6e1b6a4ff6b157a2c7467b9a01",
            "value": 1
          }
        },
        "bda183142f1846bbb71962651634641f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf77c79187842c688a320129efb8f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a79854e97040df8d68255c9b24d812",
            "placeholder": "​",
            "style": "IPY_MODEL_900dbc61cd014778b536739d06e99853",
            "value": " 743/743 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "bfbd84082ea840d1ad83270601c9022e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c008babef3484f0fa9a682f514c5166d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7cd00e35e23451796d7f4be353ab714",
            "placeholder": "​",
            "style": "IPY_MODEL_9b7b3a7f4cbb4dde950f3bc7a73e5cf6",
            "value": "tokenizer.json: "
          }
        },
        "c0fd41db72624b5c979ccb1b255d1c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11ff6f0a3c704d618f0c1cd216b796d9",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aabee24f843b488c85c1410e035a8e8b",
            "value": 124
          }
        },
        "c2cf71c20d6043ccb55e61b8aac21846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2eb23b29c1b466588c68ac38b1d5a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50e4839d6ca40528c0c804d2e1b65f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b916b553664de2906e90bc9a303dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb3c019e2f746daac8bc4e5164da4fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf0e108f46144e109197337986889467",
            "value": 1
          }
        },
        "c781a0c2ec524fd897f24c336bcb8bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c934d35cc81041de9de8294aedaef29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71726d43b8d24e3494ade9f096510a2a",
            "placeholder": "​",
            "style": "IPY_MODEL_58de3427f73a4cadb0a990c1f4586f51",
            "value": " 794/794 [00:00&lt;00:00, 67.9kB/s]"
          }
        },
        "cd44f69fdb59429db70e4a50afe99d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd671fd928d24292bcc0091929796d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf0e108f46144e109197337986889467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d187c12c60224281809fc378c55b2e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1df53c2d1944f8db242e04b81b4a763": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d20392c7947e4911960ebe1cbc17540d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413298a91dba45cb9aee06b5d9744dd6",
            "placeholder": "​",
            "style": "IPY_MODEL_d225d8daa8104d90a816e4b0abc0988e",
            "value": "tokenizer.json: "
          }
        },
        "d225d8daa8104d90a816e4b0abc0988e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2a53fb4d83c481b927691986d20844b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31fcf233c0c4f9db432d3b1a1173f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3cee3e71d904d378803a1656828767b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d56d8ca84d9e439d99e7cd504faf49a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d79e2f86d08846a08c0e2d9a44915777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_129811a2736c473f8f5792614e2a5eb3",
              "IPY_MODEL_7e103ab49a904c09b582f887d1deee07",
              "IPY_MODEL_e51f5537759a44db9cc15ce9ff05a3cd"
            ],
            "layout": "IPY_MODEL_5e82dd89cff346d2ba16ee91e8cf71e2"
          }
        },
        "d95b9207f1b448f5b3f43256f71b1a75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95f1dbec51543b4a27c610fb5853d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c008babef3484f0fa9a682f514c5166d",
              "IPY_MODEL_3f8c1329c9f74767b946b942e3254392",
              "IPY_MODEL_3778dbc947094e1181554937ebd8c62e"
            ],
            "layout": "IPY_MODEL_134ea9e644d94c9e8cd1d57333852923"
          }
        },
        "d982a0ef48134faa9a2e6ebe01ce9f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8420154d5e483b913e9f3b7a4e14dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df98353095ae4e2295ef4cc5ad9253a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703a94e7e3644809a5a849346be762eb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a6edb2dee4a4fd094c39841dc64a095",
            "value": 1
          }
        },
        "dfb12ed69cc04b3abeff03df2efa2d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56abcbeef18d4163b41b5cd774798a29",
            "placeholder": "​",
            "style": "IPY_MODEL_115e7789a1c04c388eed27ad6431afe3",
            "value": "vocab.txt: "
          }
        },
        "e11661d1dce24af695fb8c92a91de7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1d8f1ef65964eedb4e43565d08efed9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fb6c3002e54e54aecc0a41990655e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21e2030a0a0449abcb0a2f1fbd0e271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e448eac9817c4fe4baf175009d7e8c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51f5537759a44db9cc15ce9ff05a3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26099d0292d640539be65aa77fcb2321",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1aa52287854440a527c6bca383b311",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 137MB/s]"
          }
        },
        "e72b748edd3e4cc497ceddfa573598d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81fdafc5c5c443f93b3aef1f8cc490c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88a31b73e3348efa7023aafacb66a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04571cada714422c91a9326c7c936854",
              "IPY_MODEL_4b3b7abec0e545d1bd0f237fa631550f",
              "IPY_MODEL_2ff9d71c41824519b104d0b55dab3d4d"
            ],
            "layout": "IPY_MODEL_2acd8fa4302a454db864c9aed5858456"
          }
        },
        "e8b1891f74ba47339d26a44bb3ca81bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8dcf5cda3dd406aa2a5221c97675a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01be783453cb4846bc89701fa63453af",
            "placeholder": "​",
            "style": "IPY_MODEL_9f4a22e27d5c44c7b21e0f8cfad710d2",
            "value": "vocab.txt: "
          }
        },
        "e9167b7f45714d019ea9df780b5ff982": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcf0e83926c476993223317afdaa84f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ff34a9f56ab4865b3aff98e8e83bea4",
            "value": 8
          }
        },
        "ef32ffea621048e7ae0f0874df6c1428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c964ebf43144ecfad1f445da0c77d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_d3cee3e71d904d378803a1656828767b",
            "value": " 366/366 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "f0747656060c4d04a6aa38bf978687e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f37c2ef94b7c4471ac5d88c439d57c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69224cfb3bad4fe69b1eeec23671827c",
            "placeholder": "​",
            "style": "IPY_MODEL_7ff946aa385a4c3686e64ef3a25c6ef1",
            "value": "modules.json: 100%"
          }
        },
        "f494d9a290714a67ac81f9b4214e122f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8404775a442404890e48fb6466fbfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baa0ca00ac8f4f1b896891afa56769d6",
              "IPY_MODEL_36966127998f4b0d936e8e9c9469b20d",
              "IPY_MODEL_7afed18023644c08814a721311463ef0"
            ],
            "layout": "IPY_MODEL_32f3f43aecd74dce9cae87e234f81040"
          }
        },
        "fa254953ce2b44e1b3b4dc54725099d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa38683265344c33833bed6a5b5b74ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66316808d94f45adb8842f20b2555c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_18d761044ac347b7910d99da20a18380",
            "value": "config.json: 100%"
          }
        },
        "fa699e5c27dd447db656fb1db4dca001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd83d84bb282404a81107ac210d40b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9d06436c3640acba5010e9e637c67c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe420ced4fcd49fba88914134dca37f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9f24d8462a4a189878c526ebaf8e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfb12ed69cc04b3abeff03df2efa2d8e",
              "IPY_MODEL_9c33feb267ae454791c2d3a60657e304",
              "IPY_MODEL_7d7afca7e7334a65ad66c60340a06216"
            ],
            "layout": "IPY_MODEL_439df160977c4376a4e7b9008f4e5c45"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
